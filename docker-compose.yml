version: '3.8'

networks:
  ai-platform:
    driver: bridge
    name: ai-platform

volumes:
  ollama_data:
  anythingllm_data:
  litellm_data:
  dify_postgres:
  dify_redis:
  dify_weaviate:
  n8n_data:
  signal_data:
  nginx_ssl:

services:
  # ==========================================================================
  # NGINX REVERSE PROXY
  # ==========================================================================
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:80:80"
      - "${TAILSCALE_IP}:443:443"
      - "${TAILSCALE_IP}:${NGINX_PORT}:8443"
    volumes:
      - ${PROJECT_ROOT}/config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ${PROJECT_ROOT}/config/nginx/ssl:/etc/nginx/ssl:ro
      - ${PROJECT_ROOT}/public:/usr/share/nginx/html:ro
      - nginx_ssl:/etc/nginx/certs
    networks:
      - ai-platform
    depends_on:
      - anythingllm
      - dify-web
      - n8n
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # OLLAMA - Local LLM Engine
  # ==========================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${OLLAMA_PORT}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    networks:
      - ai-platform
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ==========================================================================
  # LITELLM - LLM Proxy & Load Balancer
  # ==========================================================================
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${LITELLM_PORT}:4000"
    volumes:
      - ${PROJECT_ROOT}/config/litellm/config.yaml:/app/config.yaml:ro
      - litellm_data:/app/data
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - LITELLM_SALT_KEY=${LITELLM_MASTER_KEY}
      - DATABASE_URL=sqlite:////app/data/litellm.db
    command: ["--config", "/app/config.yaml", "--port", "4000", "--num_workers", "4"]
    networks:
      - ai-platform
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # ANYTHINGLLM - Document Intelligence
  # ==========================================================================
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${ANYTHINGLLM_PORT}:3001"
    volumes:
      - anythingllm_data:/app/server/storage
      - ${PROJECT_ROOT}/data/documents:/app/server/storage/documents
    environment:
      - STORAGE_DIR=/app/server/storage
      - JWT_SECRET=${JWT_SECRET}
      - DISABLE_TELEMETRY=true
      - LLM_PROVIDER=ollama
      - OLLAMA_BASE_PATH=http://ollama:11434
      - EMBEDDING_PROVIDER=ollama
      - EMBEDDING_MODEL_PREF=nomic-embed-text
      - VECTOR_DB=lancedb
    networks:
      - ai-platform
    depends_on:
      - ollama
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3001/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # DIFY - LLM Application Platform
  # ==========================================================================
  dify-db:
    image: postgres:15-alpine
    container_name: dify-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: dify
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: dify
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - dify_postgres:/var/lib/postgresql/data
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "dify"]
      interval: 10s
      timeout: 5s
      retries: 5

  dify-redis:
    image: redis:7-alpine
    container_name: dify-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - dify_redis:/data
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  dify-weaviate:
    image: semitechnologies/weaviate:1.19.0
    container_name: dify-weaviate
    restart: unless-stopped
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      CLUSTER_HOSTNAME: 'node1'
    volumes:
      - dify_weaviate:/var/lib/weaviate
    networks:
      - ai-platform

  dify-api:
    image: langgenius/dify-api:latest
    container_name: dify-api
    restart: unless-stopped
    environment:
      MODE: api
      SECRET_KEY: ${SECRET_KEY}
      DB_USERNAME: dify
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_HOST: dify-db
      DB_PORT: 5432
      DB_DATABASE: dify
      REDIS_HOST: dify-redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@dify-redis:6379/1
      VECTOR_STORE: weaviate
      WEAVIATE_ENDPOINT: http://dify-weaviate:8080
      MIGRATION_ENABLED: 'true'
    networks:
      - ai-platform
    depends_on:
      - dify-db
      - dify-redis
      - dify-weaviate

  dify-worker:
    image: langgenius/dify-api:latest
    container_name: dify-worker
    restart: unless-stopped
    environment:
      MODE: worker
      SECRET_KEY: ${SECRET_KEY}
      DB_USERNAME: dify
      DB_PASSWORD: ${POSTGRES_PASSWORD}
      DB_HOST: dify-db
      DB_PORT: 5432
      DB_DATABASE: dify
      REDIS_HOST: dify-redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@dify-redis:6379/1
      VECTOR_STORE: weaviate
      WEAVIATE_ENDPOINT: http://dify-weaviate:8080
    networks:
      - ai-platform
    depends_on:
      - dify-db
      - dify-redis
      - dify-weaviate

  dify-web:
    image: langgenius/dify-web:latest
    container_name: dify-web
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${DIFY_WEB_PORT}:3000"
    environment:
      CONSOLE_API_URL: http://dify-api:5001
      APP_API_URL: http://dify-api:5001
    networks:
      - ai-platform
    depends_on:
      - dify-api

  # ==========================================================================
  # N8N - Workflow Automation
  # ==========================================================================
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${N8N_PORT}:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    environment:
      - N8N_HOST=${TAILSCALE_IP}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
      - WEBHOOK_URL=${WEBHOOK_URL}
      - GENERIC_TIMEZONE=${TZ}
      - N8N_METRICS=true
      - N8N_LOG_LEVEL=info
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # SIGNAL API - Messaging Backend
  # ==========================================================================
  signal-api:
    image: bbernhard/signal-cli-rest-api:latest
    container_name: signal-api
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${SIGNAL_PORT}:8080"
    volumes:
      - signal_data:/home/.local/share/signal-cli
    environment:
      - MODE=normal
      - AUTO_RECEIVE_SCHEDULE=0 */1 * * * *
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # CLAWDBOT - Signal Bot with Claude
  # ==========================================================================
  clawdbot:
    build:
      context: ${PROJECT_ROOT}
      dockerfile: ${PROJECT_ROOT}/config/clawdbot/Dockerfile
    container_name: clawdbot
    restart: unless-stopped
    ports:
      - "${TAILSCALE_IP}:${CLAWDBOT_PORT}:8000"
    volumes:
      - ${PROJECT_ROOT}/data/clawdbot:/app/data
      - ${PROJECT_ROOT}/config/clawdbot:/app/config:ro
    environment:
      - SIGNAL_API_URL=http://signal-api:8080
      - LITELLM_URL=http://litellm:4000
      - LITELLM_API_KEY=${LITELLM_MASTER_KEY}
      - ADMIN_PASSWORD=${CLAWDBOT_ADMIN_PASSWORD}
      - PORT=8000
    networks:
      - ai-platform
    depends_on:
      - signal-api
      - litellm

  # ==========================================================================
  # GDRIVE SYNC - Automatic Cloud Backup
  # ==========================================================================
  gdrive-sync:
    image: rclone/rclone:latest
    container_name: gdrive-sync
    restart: unless-stopped
    volumes:
      - ${PROJECT_ROOT}/data:/data:ro
      - ${PROJECT_ROOT}/config/rclone:/config/rclone
    environment:
      - TZ=${TZ}
    command: >
      rcd
      --rc-no-auth
      --rc-addr :5572
      --config /config/rclone/rclone.conf
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "rclone", "rc", "core/version"]
      interval: 60s
      timeout: 10s
      retries: 3
