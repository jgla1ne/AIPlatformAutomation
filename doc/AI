# AI PLATFORM DEPLOYMENT â€” COMPLETE REFERENCE v76.1.0

> **Document Version:** 76.1.0
> **Date:** 2025-07-11
> **Status:** Living Document â€” Script 0 (tested âœ…), Script 1 (in progress ğŸ”§), Scripts 2â€“4 (projected ğŸ“)
> **Repository:** [github.com/jgla1ne/AIPlatformAutomation](https://github.com/jgla1ne/AIPlatformAutomation)
> **Previous Version:** AI-PLATFORM-DEPLOYMENT-GUIDE-75.2.md â†’ v76.0.0 â†’ this document
> **Domain:** `${DOMAIN_NAME}` â€” currently `ai.datasquiz.net`

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [System Architecture Overview](#2-system-architecture-overview)
3. [Repository & Folder Structure](#3-repository--folder-structure)
4. [Service Inventory & Port Map](#4-service-inventory--port-map)
5. [Storage Architecture](#5-storage-architecture)
6. [Network & Access Architecture](#6-network--access-architecture)
7. [LLM Model Inventory â€” Local (Ollama)](#7-llm-model-inventory--local-ollama)
8. [LLM Model Inventory â€” External (Cloud APIs)](#8-llm-model-inventory--external-cloud-apis)
9. [LiteLLM Routing Strategy](#9-litellm-routing-strategy)
10. [Vector Database Selection & OpenClaw Integration](#10-vector-database-selection--openclaw-integration)
11. [Google Drive Rsync â€” Authentication Methods](#11-google-drive-rsync--authentication-methods)
12. [Script Pipeline â€” Overview](#12-script-pipeline--overview)
13. [Script 0 â€” Nuclear Clean (Tested âœ…)](#13-script-0--nuclear-clean)
14. [Script 1 â€” System Setup (In Progress ğŸ”§)](#14-script-1--system-setup)
15. [Script 2 â€” Deploy Services (Projected ğŸ“)](#15-script-2--deploy-services)
16. [Script 3 â€” Configure Services (Projected ğŸ“)](#16-script-3--configure-services)
17. [Script 4 â€” Add Service (Projected ğŸ“)](#17-script-4--add-service)
18. [Environment Variables, Credentials & Secrets](#18-environment-variables-credentials--secrets)
19. [Per-Service Configuration Architecture](#19-per-service-configuration-architecture)
20. [Security Model](#20-security-model)
21. [Monitoring & Observability](#21-monitoring--observability)
22. [Backup & Disaster Recovery](#22-backup--disaster-recovery)
23. [Reverse Proxy â€” Caddy (Fluid Selection)](#23-reverse-proxy--caddy-fluid-selection)
24. [Lessons Learnt, Expectations & No-Go's](#24-lessons-learnt-expectations--no-gos)
25. [Maintenance Runbook](#25-maintenance-runbook)
26. [Appendices](#26-appendices)

---

## 1. Executive Summary

This document is the **single source of truth** for deploying a self-hosted, GPU-accelerated AI platform on Hetzner dedicated hardware (AX102 or equivalent).

### What This Platform Provides

| Capability | Implementation |
|---|---|
| **Unified LLM Gateway** | LiteLLM proxies all requests â€” local Ollama models and cloud APIs (OpenAI, Anthropic, Google Gemini, Groq, Mistral, DeepSeek, Cohere, and others) through a single OpenAI-compatible endpoint |
| **Local Model Hosting** | Ollama runs on GPU with dynamically selected models (user chooses by number at deploy time) |
| **RAG / Knowledge Base** | Dify + Anything LLM + fluid vector DB selection (Qdrant, Weaviate, Chroma, or all) |
| **Workflow Automation** | n8n + Flowise for visual AI pipeline orchestration |
| **AI-Powered Communication** | OpenClaw connected to selected vector DB for context-aware Signal messaging |
| **Chat Interface** | Open WebUI providing multi-model chat via LiteLLM |
| **Observability** | Prometheus + Grafana + per-service exporters |
| **Storage & Backup** | MinIO (S3-compatible), rsync to Hetzner Storage Box, Google Drive sync (multiple auth methods) |
| **Zero-Trust Networking** | Tailscale (VPN) + Hetzner Cloud Firewall + fluid reverse proxy selection (Caddy default) |
| **Modular Deployment** | 5-script pipeline, per-service directories, independent docker-compose per service |

### Key Design Principles

1. **Everything is a variable** â€” domain, ports, models, vector DBs, proxy â€” all user-selectable
2. **Per-service isolation** â€” each service gets its own folder, docker-compose.yml, .env, config files
3. **Data lives on data disk** â€” `/mnt/data/` for all runtime data; Git repo has only scripts, docs, changelogs
4. **Scripts are idempotent** â€” safe to re-run; they detect existing state and skip/update accordingly
5. **Fail fast, fail loud** â€” `set -euo pipefail`, health checks after every major step
6. **No UFW** â€” Docker bypasses it; Hetzner Cloud Firewall + Tailscale + port binding replaces it entirely
7. **Secrets auto-generated but confirmed** â€” every credential is generated, displayed, and the user confirms or overrides

---

## 2. System Architecture Overview

### 2.1 Hardware (Hetzner AX102)

| Component | Specification |
|---|---|
| CPU | AMD EPYC 9454P (48 cores / 96 threads) |
| RAM | 128 GB DDR5 ECC |
| OS Disk | 2Ã— 960 GB NVMe SSD (RAID-1, hardware) |
| Data Disk | 1Ã— 3.84 TB NVMe SSD (separate, unpartitioned at delivery) |
| GPU | NVIDIA L40S 48 GB VRAM |
| Network | 1 Gbit/s public uplink |
| OS | Ubuntu 24.04 LTS (Hetzner minimal image) |
| External Storage | Hetzner Storage Box (BX, accessed via rsync over SSH port 23) |

### 2.2 Deployment Tier Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIER 0 â€” SYSTEM FOUNDATION                       â”‚
â”‚  Ubuntu 24.04 Â· NVIDIA Drivers Â· Docker Â· Tailscale Â· Ollama       â”‚
â”‚  AppArmor (managed, not disabled) Â· /mnt/data mounted Â· fstab      â”‚
â”‚  [Script 0 cleans Â· Script 1 builds]                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 1 â€” DATA INFRASTRUCTURE                     â”‚
â”‚  PostgreSQL 16 Â· Redis 7 Â· MinIO                                    â”‚
â”‚  [Script 2, phase 1]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 2 â€” AI CORE                                  â”‚
â”‚  Ollama (verify) Â· LiteLLM (routing + config.yaml)                  â”‚
â”‚  [Script 2, phase 2]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 3 â€” VECTOR DATABASES (fluid selection)       â”‚
â”‚  Qdrant Â· Weaviate Â· Chroma  (one, multiple, or all)               â”‚
â”‚  [Script 2, phase 3]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 4 â€” AI APPLICATIONS                         â”‚
â”‚  Dify Â· Open WebUI Â· Anything LLM Â· OpenClaw                       â”‚
â”‚  [Script 2, phase 4]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 5 â€” AUTOMATION                               â”‚
â”‚  n8n Â· Flowise                                                      â”‚
â”‚  [Script 2, phase 5]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 6 â€” OBSERVABILITY                            â”‚
â”‚  Prometheus Â· Grafana Â· Node Exporter Â· cAdvisor                    â”‚
â”‚  Redis Exporter Â· PostgreSQL Exporter                               â”‚
â”‚  [Script 2, phase 6]                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    TIER 7 â€” REVERSE PROXY (fluid selection)          â”‚
â”‚  Caddy (default) Â· Nginx Â· Traefik (user selects)                  â”‚
â”‚  [Script 2, phase 7]                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 2.3 Network Flow
Internet
  â”‚
  â”œâ”€â”€â†’ Hetzner Cloud Firewall (external, immutable from server)
  â”‚      â”œâ”€â”€ Allow TCP 22 (SSH â€” restricted IPs)
  â”‚      â”œâ”€â”€ Allow TCP 80, 443 (HTTP/S)
  â”‚      â”œâ”€â”€ Allow UDP 41641 (Tailscale WireGuard)
  â”‚      â””â”€â”€ DENY ALL other inbound
  â”‚
  â”œâ”€â”€â†’ Server Public IP
  â”‚      â”œâ”€â”€â†’ :80/:443 â†’ Reverse Proxy (Caddy/Nginx/Traefik)
  â”‚      â”‚                  â”œâ”€â”€â†’ *.${DOMAIN_NAME} â†’ internal services (127.0.0.1:PORT)
  â”‚      â”‚                  â””â”€â”€â†’ TLS termination (auto Let's Encrypt)
  â”‚      â”œâ”€â”€â†’ :22 â†’ SSH (direct, or Tailscale SSH preferred)
  â”‚      â””â”€â”€â†’ :41641/udp â†’ Tailscale WireGuard tunnel
  â”‚
  â””â”€â”€â†’ Tailscale VPN (100.x.x.x)
         â”œâ”€â”€â†’ Tailscale SSH (direct node access, MagicDNS)
         â”œâ”€â”€â†’ ${TAILSCALE_IP}:18789 â†’ OpenClaw (ONLY via Tailscale)
         â””â”€â”€â†’ Admin access to all services via HTTPS
---

## 3. Repository & Folder Structure

### 3.1 Git Repository (OS Disk)

The repository lives on the OS disk. It contains **only** scripts, documentation, and changelogs.
**No runtime data. No secrets. No Docker volumes.**
~/AIPlatformAutomation/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ script0_nuclear_clean.sh          # Tested âœ…
â”‚   â”œâ”€â”€ script1_system_setup.sh           # In progress ğŸ”§
â”‚   â”œâ”€â”€ script2_deploy_services.sh        # Projected ğŸ“
â”‚   â”œâ”€â”€ script3_configure_services.sh     # Projected ğŸ“
â”‚   â”œâ”€â”€ script4_add_service.sh            # Projected ğŸ“
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ common.sh                     # Shared functions (logging, wait_for, colors)
â”‚       â”œâ”€â”€ detect_gpu.sh                 # GPU detection and driver selection
â”‚       â”œâ”€â”€ port_manager.sh               # Port allocation, conflict detection
â”‚       â”œâ”€â”€ credential_generator.sh       # Password/key generation
â”‚       â””â”€â”€ health_check.sh              # Per-service health check functions
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AI-PLATFORM-DEPLOYMENT-GUIDE.md   # THIS DOCUMENT
â”‚   â”œâ”€â”€ CHANGELOG.md                      # Per-commit changelog
â”‚   â””â”€â”€ DECISIONS.md                      # Architecture decision records
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ docker-compose/                   # Template compose files per service
â”‚   â”‚   â”œâ”€â”€ postgresql.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ redis.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ litellm.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ dify.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ open-webui.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ anythingllm.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ openclaw.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ n8n.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ flowise.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ qdrant.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ weaviate.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ chroma.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ minio.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ caddy.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ prometheus.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ grafana.yml.tmpl
â”‚   â”‚   â””â”€â”€ monitoring-exporters.yml.tmpl
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                           # Template config files
â”‚   â”‚   â”œâ”€â”€ litellm-config.yaml.tmpl
â”‚   â”‚   â”œâ”€â”€ prometheus.yml.tmpl
â”‚   â”‚   â”œâ”€â”€ Caddyfile.tmpl
â”‚   â”‚   â””â”€â”€ grafana-datasources.yml.tmpl
â”‚   â”‚
â”‚   â””â”€â”€ env/                              # Template .env files (NO real secrets)
â”‚       â”œâ”€â”€ postgresql.env.tmpl
â”‚       â”œâ”€â”€ litellm.env.tmpl
â”‚       â”œâ”€â”€ dify.env.tmpl
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ .gitignore                            # Excludes: *.env, credentials/, *.key, *.pem
â””â”€â”€ README.md

### 3.2 Data Disk (`/mnt/data/`) â€” Runtime Only

All Docker volumes, runtime configs, credentials, and service data live here.
**This is NOT in Git. This is what gets backed up to Hetzner Storage Box.**
/mnt/data/
â”œâ”€â”€ ai-platform/
â”‚   â”œâ”€â”€ credentials/                      # chmod 700 â€” master credential store
â”‚   â”‚   â”œâ”€â”€ master.env                    # All generated passwords/keys (chmod 600)
â”‚   â”‚   â”œâ”€â”€ storagebox_rsa                # SSH key for Hetzner Storage Box (chmod 600)
â”‚   â”‚   â”œâ”€â”€ storagebox_rsa.pub
â”‚   â”‚   â”œâ”€â”€ gdrive_service_account.json   # Google Drive service account key (chmod 600)
â”‚   â”‚   â””â”€â”€ tailscale_authkey.txt         # Tailscale auth key (chmod 600)
â”‚   â”‚
â”‚   â”œâ”€â”€ postgresql/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env                          # (chmod 600)
â”‚   â”‚   â””â”€â”€ data/                         # PostgreSQL data directory
â”‚   â”‚
â”‚   â”œâ”€â”€ redis/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ minio/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ ollama/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml            # (if running as container; native install also supported)
â”‚   â”‚   â””â”€â”€ models/                       # Model weights â€” LARGE, excluded from backup
â”‚   â”‚
â”‚   â”œâ”€â”€ litellm/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ config.yaml                   # Model routing configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ qdrant/                           # (if selected)
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ weaviate/                         # (if selected)
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ chroma/                           # (if selected)
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ dify/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â”œâ”€â”€ storage/                  # File uploads
â”‚   â”‚       â””â”€â”€ sandbox/
â”‚   â”‚
â”‚   â”œâ”€â”€ open-webui/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ anythingllm/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â”œâ”€â”€ storage/
â”‚   â”‚       â””â”€â”€ vector-cache/
â”‚   â”‚
â”‚   â”œâ”€â”€ openclaw/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â”œâ”€â”€ signal-data/              # Signal protocol state
â”‚   â”‚       â””â”€â”€ config/
â”‚   â”‚
â”‚   â”œâ”€â”€ n8n/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ flowise/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ caddy/                            # (or nginx/ or traefik/ â€” fluid selection)
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ Caddyfile
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â”œâ”€â”€ certs/                    # TLS certificates (auto-managed)
â”‚   â”‚       â””â”€â”€ config/
â”‚   â”‚
â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ prometheus.yml                # Scrape config
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”‚   â”œâ”€â”€ .env
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â””â”€â”€ provisioning/
â”‚   â”‚           â”œâ”€â”€ datasources/
â”‚   â”‚           â””â”€â”€ dashboards/
â”‚   â”‚
â”‚   â”œâ”€â”€ exporters/
â”‚   â”‚   â””â”€â”€ docker-compose.yml            # node-exporter, cadvisor, redis-exporter, pg-exporter
â”‚   â”‚
â”‚   â””â”€â”€ backups/
â”‚       â”œâ”€â”€ scripts/
â”‚       â”‚   â”œâ”€â”€ backup_to_storagebox.sh
â”‚       â”‚   â”œâ”€â”€ backup_to_gdrive.sh
â”‚       â”‚   â””â”€â”€ restore_from_storagebox.sh
â”‚       â””â”€â”€ logs/
â”‚           â””â”€â”€ backup_YYYYMMDD.log
â”‚
â””â”€â”€ docker/                               # Docker root moved here by Script 1
    â”œâ”€â”€ overlay2/                          # Docker storage driver data
    â”œâ”€â”€ containers/
    â”œâ”€â”€ volumes/
    â””â”€â”€ ...

---

## 4. Service Inventory & Port Map

### 4.1 Complete Port Allocation

All ports are **user-configurable** at Script 1 runtime. The values below are **defaults**.
Script 1 checks for port conflicts using `ss -tlnp` before finalizing.

| Service | Container Name | Default Port | Bind Address | Protocol | Subdomain (default) | Tier |
|---|---|---|---|---|---|---|
| **PostgreSQL** | `postgres` | `5432` | `127.0.0.1` | TCP | â€” (no web UI) | 1 |
| **Redis** | `redis` | `6379` | `127.0.0.1` | TCP | â€” (no web UI) | 1 |
| **MinIO API** | `minio` | `9000` | `127.0.0.1` | HTTP | `minio.${DOMAIN_NAME}` | 1 |
| **MinIO Console** | `minio` | `9001` | `127.0.0.1` | HTTP | `minio-console.${DOMAIN_NAME}` | 1 |
| **Ollama API** | `ollama` / systemd | `11434` | `127.0.0.1` | HTTP | â€” (internal only) | 2 |
| **LiteLLM Proxy** | `litellm` | `4000` | `127.0.0.1` | HTTP | `llm.${DOMAIN_NAME}` | 2 |
| **Qdrant HTTP** | `qdrant` | `6333` | `127.0.0.1` | HTTP | â€” (internal) | 3 |
| **Qdrant gRPC** | `qdrant` | `6334` | `127.0.0.1` | gRPC | â€” (internal) | 3 |
| **Weaviate** | `weaviate` | `8080` | `127.0.0.1` | HTTP | â€” (internal) | 3 |
| **Chroma** | `chroma` | `8000` | `127.0.0.1` | HTTP | â€” (internal) | 3 |
| **Dify Web** | `dify-web` | `3001` | `127.0.0.1` | HTTP | `dify.${DOMAIN_NAME}` | 4 |
| **Dify API** | `dify-api` | `5001` | `127.0.0.1` | HTTP | `dify-api.${DOMAIN_NAME}` | 4 |
| **Open WebUI** | `open-webui` | `3003` | `127.0.0.1` | HTTP | `chat.${DOMAIN_NAME}` | 4 |
| **Anything LLM** | `anythingllm` | `3004` | `127.0.0.1` | HTTP | `anythingllm.${DOMAIN_NAME}` | 4 |
| **OpenClaw** | `openclaw` | `18789` | `${TAILSCALE_IP}` | HTTP | â€” (Tailscale only) | 4 |
| **n8n** | `n8n` | `5678` | `127.0.0.1` | HTTP | `n8n.${DOMAIN_NAME}` | 5 |
| **Flowise** | `flowise` | `3005` | `127.0.0.1` | HTTP | `flowise.${DOMAIN_NAME}` | 5 |
| **Prometheus** | `prometheus` | `9090` | `127.0.0.1` | HTTP | `prometheus.${DOMAIN_NAME}` | 6 |
| **Grafana** | `grafana` | `3006` | `127.0.0.1` | HTTP | `grafana.${DOMAIN_NAME}` | 6 |
| **Node Exporter** | `node-exporter` | `9100` | `127.0.0.1` | HTTP | â€” (internal) | 6 |
| **cAdvisor** | `cadvisor` | `9180` | `127.0.0.1` | HTTP | â€” (internal) | 6 |
| **Redis Exporter** | `redis-exporter` | `9121` | `127.0.0.1` | HTTP | â€” (internal) | 6 |
| **PG Exporter** | `postgres-exporter` | `9187` | `127.0.0.1` | HTTP | â€” (internal) | 6 |
| **Caddy HTTP** | `caddy` | `80` | `0.0.0.0` | HTTP | â€” (redirect to 443) | 7 |
| **Caddy HTTPS** | `caddy` | `443` | `0.0.0.0` | HTTPS | `*.${DOMAIN_NAME}` | 7 |

### 4.2 Port Selection Rules

1. **Only ports 22, 80, 443, 41641 are exposed to the internet** (via Hetzner Cloud Firewall)
2. **All service ports bind to `127.0.0.1`** â€” accessible only via reverse proxy or Tailscale
3. **OpenClaw binds ONLY to Tailscale IP** (`${TAILSCALE_IP}`) â€” not accessible from public internet
4. **Port conflicts are checked at Script 1 runtime** using `ss -tlnp`
5. **User can override any default** during interactive prompts

### 4.3 DNS Records Required

All A records point to the server's public IP. Wildcard recommended.
Type  Name                          Value              TTL
A     ${DOMAIN_NAME}                ${PUBLIC_IP}       300
A     *.${DOMAIN_NAME}              ${PUBLIC_IP}       300

| Subdomain | Service | Notes |
|---|---|---|
| `dify.${DOMAIN_NAME}` | Dify | Main AI workspace |
| `chat.${DOMAIN_NAME}` | Open WebUI | Chat interface |
| `llm.${DOMAIN_NAME}` | LiteLLM | API gateway |
| `n8n.${DOMAIN_NAME}` | n8n | Workflow automation |
| `flowise.${DOMAIN_NAME}` | Flowise | AI flow builder |
| `anythingllm.${DOMAIN_NAME}` | Anything LLM | RAG workspace |
| `minio.${DOMAIN_NAME}` | MinIO API | S3-compatible storage |
| `minio-console.${DOMAIN_NAME}` | MinIO Console | Storage admin UI |
| `grafana.${DOMAIN_NAME}` | Grafana | Monitoring dashboards |
| `prometheus.${DOMAIN_NAME}` | Prometheus | Metrics (admin only) |
---

## 5. Storage Architecture

### 5.1 Disk Layout

| Disk | Mount Point | Size | Purpose | Filesystem |
|---|---|---|---|---|
| OS Disk | `/` | 80 GB | Operating system, git repo, system packages | ext4 |
| Data Disk | `/mnt/data` | 200+ GB | All Docker data, volumes, models, backups | ext4 |

### 5.2 Why Two Disks

1. **OS disk is disposable** â€” Script 0 + Script 1 rebuild it from scratch in minutes
2. **Data disk survives OS reinstall** â€” detach, reinstall OS, reattach, re-run scripts
3. **Data disk can be resized** independently via Hetzner Cloud console
4. **Data disk can be snapshotted** independently for point-in-time backup
5. **Docker root moved to data disk** â€” prevents OS disk from filling up with images/layers

### 5.3 Data Disk Setup (Script 1)

```bash
# Script 1 performs these steps:
# 1. Detect data disk (usually /dev/sdb or /dev/disk/by-id/...)
# 2. Check if already formatted (blkid)
# 3. If unformatted: mkfs.ext4 (with user confirmation)
# 4. If formatted: mount as-is (preserves existing data)
# 5. Add to /etc/fstab with nofail,defaults
# 6. Create directory structure under /mnt/data/ai-platform/
# 7. Move Docker root: /etc/docker/daemon.json â†’ "data-root": "/mnt/data/docker"
5.4 Storage Budget Estimation
Copy table


Category
Estimated Size
Location
Backed Up?



Docker images (all services)
15â€“25 GB
/mnt/data/docker/
No (re-pulled)


Ollama models (3â€“5 models)
20â€“50 GB
/mnt/data/ai-platform/ollama/models/
No (re-pulled)


PostgreSQL databases
2â€“10 GB
/mnt/data/ai-platform/postgresql/data/
Yes


Redis data
< 500 MB
/mnt/data/ai-platform/redis/data/
Yes


MinIO object storage
5â€“50 GB
/mnt/data/ai-platform/minio/data/
Yes


Vector DB collections
2â€“20 GB
/mnt/data/ai-platform/{qdrant,weaviate,chroma}/data/
Yes


Dify file uploads
1â€“10 GB
/mnt/data/ai-platform/dify/data/storage/
Yes


AnythingLLM documents
1â€“5 GB
/mnt/data/ai-platform/anythingllm/data/
Yes


Grafana dashboards/data
< 500 MB
/mnt/data/ai-platform/grafana/data/
Yes


Prometheus metrics (30d)
2â€“5 GB
/mnt/data/ai-platform/prometheus/data/
Optional


TLS certificates (Caddy)
< 10 MB
/mnt/data/ai-platform/caddy/data/certs/
Yes


Credentials
< 1 MB
/mnt/data/ai-platform/credentials/
Yes (encrypted)


TOTAL
50â€“180 GB




5.5 External Storage â€” Hetzner Storage Box
Copy table


Setting
Value



Product
Hetzner Storage Box BX11+


Protocol
SFTP over SSH (port 23)


Authentication
SSH key (storagebox_rsa) â€” created by Script 1


Mount point
Not mounted â€” rsync push only


Backup schedule
Daily 02:00 UTC via cron


Retention
7 daily + 4 weekly + 3 monthly


Encryption
At-rest via age or gpg before transfer


Backup rsync command pattern:
rsync -avz --progress \
  -e "ssh -p 23 -i /mnt/data/ai-platform/credentials/storagebox_rsa" \
  /mnt/data/ai-platform/backups/latest/ \
  ${STORAGEBOX_USER}@${STORAGEBOX_HOST}:./backups/$(date +%Y%m%d)/
5.6 External Storage â€” Google Drive (rclone)
See Section 11: Google Drive Rsync â€” Authentication Methods for detailed auth setup.
Copy table


Setting
Value



Tool
rclone


Auth method
Service Account (preferred) or OAuth2


Destination
Shared Drive or specific folder by ID


Backup schedule
Daily 03:00 UTC via cron (after Storage Box backup completes)


What gets backed up
Same as Storage Box, secondary copy



6. Network & Access Architecture
6.1 Docker Networks
Script 2 creates isolated Docker bridge networks per functional group.
Services only join networks they need â€” principle of least connectivity.
Copy table


Network Name
Purpose
Services



ai-db
Database access
postgresql, redis, dify-api, dify-worker, n8n, litellm, grafana-exporters


ai-llm
LLM routing
ollama, litellm, dify-api, dify-worker, open-webui, anythingllm, flowise


ai-vector
Vector DB access
qdrant/weaviate/chroma, dify-api, dify-worker, anythingllm, openclaw


ai-storage
Object storage
minio, dify-api, dify-worker, anythingllm


ai-web
Reverse proxy to services
caddy/nginx/traefik, dify-web, dify-api, open-webui, anythingllm, n8n, flowise, grafana, litellm, minio


ai-monitor
Monitoring scraping
prometheus, grafana, node-exporter, cadvisor, redis-exporter, postgres-exporter


6.2 Network Creation Pattern (Script 2)
create_network_if_missing() {
    local network_name=" $ 1"
    if ! docker network inspect " $ network_name" &>/dev/null; then
        docker network create \
            --driver bridge \
            --opt com.docker.network.bridge.name="br-${network_name}" \
            "$network_name"
        log_success "Created Docker network: $network_name"
    else
        log_info "Docker network already exists:  $ network_name"
    fi
}

for net in ai-db ai-llm ai-vector ai-storage ai-web ai-monitor; do
    create_network_if_missing " $ net"
done
6.3 Why No UFW
Copy table


Reason
Detail



Docker bypasses UFW
Docker modifies iptables directly via DOCKER-USER chain. UFW rules are ignored for container traffic. This is a well-documented Docker/UFW conflict.


Hetzner Cloud Firewall is superior
Operates at hypervisor level, cannot be bypassed from within the VM. Stateful. Free.


UFW creates false sense of security
Admin thinks port is blocked, Docker has it wide open. Worse than no firewall.


Script 0 removes UFW
apt-get purge -y ufw â€” clean removal, no residual rules


6.4 Firewall Architecture (Layered)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1 â€” Hetzner Cloud Firewall (hypervisor level)    â”‚
â”‚  â”œâ”€â”€ ALLOW TCP 22 inbound (from admin IPs only)         â”‚
â”‚  â”œâ”€â”€ ALLOW TCP 80 inbound (HTTP â†’ redirect to 443)      â”‚
â”‚  â”œâ”€â”€ ALLOW TCP 443 inbound (HTTPS â†’ reverse proxy)      â”‚
â”‚  â”œâ”€â”€ ALLOW UDP 41641 inbound (Tailscale WireGuard)      â”‚
â”‚  â””â”€â”€ DENY ALL other inbound                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 2 â€” Docker bind address (application level)      â”‚
â”‚  â”œâ”€â”€ All services bind 127.0.0.1:PORT                   â”‚
â”‚  â”œâ”€â”€ OpenClaw binds ${TAILSCALE_IP}:18789 only          â”‚
â”‚  â””â”€â”€ Only Caddy binds 0.0.0.0:80 and 0.0.0.0:443       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 3 â€” Tailscale ACLs (overlay network)             â”‚
â”‚  â”œâ”€â”€ Admin devices â†’ full access                        â”‚
â”‚  â”œâ”€â”€ Tagged nodes â†’ restricted per-port access          â”‚
â”‚  â””â”€â”€ MagicDNS for internal name resolution              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  LAYER 4 â€” Reverse proxy auth (application level)       â”‚
â”‚  â”œâ”€â”€ Caddy basicauth or forward_auth for admin UIs      â”‚
â”‚  â”œâ”€â”€ Per-service authentication (built-in)              â”‚
â”‚  â””â”€â”€ API key validation (LiteLLM, n8n webhooks)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
6.5 Tailscale Integration
Copy table


Setting
Value



Install method
Official apt repo (Script 1)


Auth
Auth key from tailscale_authkey.txt or interactive tailscale up


SSH
tailscale up --ssh enables Tailscale SSH (optional, user-prompted)


Exit node
Not configured (server is not an exit node)


MagicDNS
Enabled â€” access server as hostname.tailnet-name.ts.net


Subnet routes
Not advertised (single server, no LAN routing needed)


ACL tags
tag:ai-server for this node


6.6 SSH Hardening (Script 1)
# Script 1 applies these sshd_config changes:
PermitRootLogin               prohibit-password    # Key only, no password
PasswordAuthentication         no                   # Key only
PubkeyAuthentication           yes
MaxAuthTries                   3
ClientAliveInterval            300
ClientAliveCountMax            2
X11Forwarding                  no
AllowAgentForwarding           no
# Port remains 22 (Hetzner firewall restricts source IPs)
---

## 7. LLM Model Inventory â€” Local (Ollama)

### 7.1 Overview

Ollama runs as a Docker container with GPU passthrough (if available).
Models are stored on the data disk at `/mnt/data/ai-platform/ollama/models/`.
All local models are accessed exclusively through LiteLLM â€” no direct Ollama access from application services.

### 7.2 Model Selection (Interactive â€” Script 2)

Script 2 presents an interactive menu. User selects which models to pull.
Selection is stored in `/mnt/data/ai-platform/credentials/ollama_models.list`.

### 7.3 Available Local Models

| Model | Ollama Tag | Size | VRAM Required | Use Case | Default? |
|---|---|---|---|---|---|
| Llama 3.1 8B | `llama3.1:8b` | 4.7 GB | 6 GB | General chat, coding, reasoning | âœ… |
| Llama 3.1 70B | `llama3.1:70b` | 40 GB | 48 GB | Advanced reasoning (large GPU only) | âŒ |
| Llama 3.3 70B | `llama3.3:70b` | 40 GB | 48 GB | Latest Llama, multilingual | âŒ |
| Mistral 7B | `mistral:7b` | 4.1 GB | 6 GB | Fast general-purpose | âœ… |
| Mixtral 8x7B | `mixtral:8x7b` | 26 GB | 32 GB | MoE, high quality | âŒ |
| Mixtral 8x22B | `mixtral:8x22b` | 80 GB | 96 GB | Largest MoE (multi-GPU only) | âŒ |
| CodeLlama 13B | `codellama:13b` | 7.4 GB | 10 GB | Code generation/analysis | âŒ |
| DeepSeek Coder V2 | `deepseek-coder-v2:16b` | 9.1 GB | 12 GB | Code generation, fill-in-middle | âŒ |
| DeepSeek R1 7B | `deepseek-r1:7b` | 4.7 GB | 6 GB | Reasoning, chain-of-thought | âŒ |
| DeepSeek R1 70B | `deepseek-r1:70b` | 40 GB | 48 GB | Advanced reasoning | âŒ |
| Phi-3 Mini 3.8B | `phi3:mini` | 2.2 GB | 4 GB | Small, fast, surprisingly capable | âœ… |
| Phi-3 Medium 14B | `phi3:medium` | 8.2 GB | 10 GB | Strong reasoning for size | âŒ |
| Gemma 2 9B | `gemma2:9b` | 5.4 GB | 8 GB | Google's open model | âŒ |
| Gemma 2 27B | `gemma2:27b` | 16 GB | 20 GB | Larger Gemma variant | âŒ |
| Qwen 2.5 7B | `qwen2.5:7b` | 4.4 GB | 6 GB | Alibaba, strong multilingual | âŒ |
| Qwen 2.5 72B | `qwen2.5:72b` | 41 GB | 48 GB | Top-tier open model | âŒ |
| Command R 35B | `command-r:35b` | 20 GB | 24 GB | RAG-optimized (Cohere open) | âŒ |
| Nomic Embed Text | `nomic-embed-text` | 274 MB | 1 GB | Text embeddings (vector DB) | âœ… |
| MxBai Embed Large | `mxbai-embed-large` | 670 MB | 2 GB | High-quality embeddings | âŒ |
| All-MiniLM-L6 | `all-minilm:l6-v2` | 46 MB | <1 GB | Lightweight embeddings | âŒ |

### 7.4 GPU Detection Logic (Script 1 â†’ Script 2)

```bash
detect_gpu() {
    GPU_TYPE="none"
    GPU_VRAM_MB=0

    if command -v nvidia-smi &>/dev/null; then
        GPU_TYPE="nvidia"
        GPU_VRAM_MB= $ (nvidia-smi --query-gpu=memory.total \
            --format=csv,noheader,nounits | head -1 | tr -d ' ')
    elif [ -d /sys/class/drm ] && ls /sys/class/drm/card*/device/vendor 2>/dev/null | \
         xargs grep -l "0x1002" &>/dev/null; then
        GPU_TYPE="amd"
        # AMD VRAM detection via rocm-smi or /sys
        if command -v rocm-smi &>/dev/null; then
            GPU_VRAM_MB= $ (rocm-smi --showmeminfo vram --csv | tail -1 | cut -d',' -f2)
            GPU_VRAM_MB= $ ((GPU_VRAM_MB / 1048576))  # bytes to MB
        fi
    fi

    export GPU_TYPE GPU_VRAM_MB
    log_info "GPU detected: type= $ {GPU_TYPE}, VRAM=${GPU_VRAM_MB}MB"
}

suggest_models_for_vram() {
    local vram_mb=" $ 1"
    if [ " $ vram_mb" -ge 48000 ]; then
        echo "llama3.1:70b mixtral:8x7b deepseek-r1:70b qwen2.5:72b"
    elif [ " $ vram_mb" -ge 24000 ]; then
        echo "llama3.1:8b mistral:7b command-r:35b phi3:medium gemma2:27b"
    elif [ " $ vram_mb" -ge 8000 ]; then
        echo "llama3.1:8b mistral:7b phi3:mini deepseek-coder-v2:16b gemma2:9b qwen2.5:7b"
    elif [ "$vram_mb" -ge 4000 ]; then
        echo "phi3:mini mistral:7b"
    else
        # CPU only
        echo "phi3:mini all-minilm:l6-v2"
    fi
}

8. LLM Model Inventory â€” External (Cloud APIs)
8.1 Overview
External models are accessed via LiteLLM proxy. User provides API keys during Script 2 interactive prompts. All keys are stored in /mnt/data/ai-platform/credentials/api_keys.env.
Selection is fluid â€” user enables/disables providers at any time by:

Re-running the provider selection menu in Script 4
Editing /mnt/data/ai-platform/litellm/config.yaml + restarting LiteLLM container
Using LiteLLM admin API at llm.${DOMAIN_NAME}/model/new

8.2 Supported External Providers & Models
8.2.1 OpenAI
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



GPT-4o
openai/gpt-4o
128K
$2.50 in / $10.00 out
Best all-round


GPT-4o Mini
openai/gpt-4o-mini
128K
$0.15 in / $0.60 out
Fast, cheap


GPT-4 Turbo
openai/gpt-4-turbo
128K
$10.00 in / $30.00 out
Legacy


GPT-4.1
openai/gpt-4.1
1M
$2.00 in / $8.00 out
Latest (2025)


GPT-4.1 Mini
openai/gpt-4.1-mini
1M
$0.40 in / $1.60 out
Latest mini


GPT-4.1 Nano
openai/gpt-4.1-nano
1M
$0.10 in / $0.40 out
Ultra cheap


o1
openai/o1
200K
$15.00 in / $60.00 out
Reasoning


o1-mini
openai/o1-mini
128K
$3.00 in / $12.00 out
Reasoning (small)


o3
openai/o3
200K
$10.00 in / $40.00 out
Latest reasoning (2025)


o3-mini
openai/o3-mini
200K
$1.10 in / $4.40 out
Reasoning, efficient


o4-mini
openai/o4-mini
200K
$1.10 in / $4.40 out
Latest reasoning (2025)


text-embedding-3-large
openai/text-embedding-3-large
8K
$0.13 in
Embeddings


text-embedding-3-small
openai/text-embedding-3-small
8K
$0.02 in
Embeddings (cheap)


Env var: OPENAI_API_KEY
8.2.2 Anthropic (Claude)
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Claude 4 Sonnet
anthropic/claude-sonnet-4-20250514
200K
$3.00 in / $15.00 out
Latest (2025)


Claude 4 Opus
anthropic/claude-opus-4-20250514
200K
$15.00 in / $75.00 out
Flagship (2025)


Claude 3.5 Sonnet
anthropic/claude-3-5-sonnet-20241022
200K
$3.00 in / $15.00 out
Previous best


Claude 3.5 Haiku
anthropic/claude-3-5-haiku-20241022
200K
$0.80 in / $4.00 out
Fast, cheap


Claude 3 Opus
anthropic/claude-3-opus-20240229
200K
$15.00 in / $75.00 out
Legacy flagship


Env var: ANTHROPIC_API_KEY
8.2.3 Google (Gemini)
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Gemini 2.5 Pro
gemini/gemini-2.5-pro-preview-06-05
1M
$1.25 in / $10.00 out
Latest, massive context


Gemini 2.5 Flash
gemini/gemini-2.5-flash-preview-05-20
1M
$0.15 in / $0.60 out
Fast, cheap, huge context


Gemini 2.0 Flash
gemini/gemini-2.0-flash
1M
$0.10 in / $0.40 out
Production stable


Gemini 1.5 Pro
gemini/gemini-1.5-pro
2M
$1.25 in / $5.00 out
2M context window


Gemini 1.5 Flash
gemini/gemini-1.5-flash
1M
$0.075 in / $0.30 out
Budget option


Gemini Embedding
gemini/text-embedding-004
2K
$0.00 (free tier)
Embeddings


Env var: GEMINI_API_KEY
LiteLLM prefix: gemini/ (uses Google AI Studio API, not Vertex)
8.2.4 Google (Vertex AI)
For enterprise / GCP-authenticated access:
Copy table


Model ID
LiteLLM Model String
Notes



Gemini 2.5 Pro (Vertex)
vertex_ai/gemini-2.5-pro-preview-06-05
Requires GCP service account


Gemini 2.5 Flash (Vertex)
vertex_ai/gemini-2.5-flash-preview-05-20
Requires GCP service account


Claude 3.5 Sonnet (Vertex)
vertex_ai/claude-3-5-sonnet-v2@20241022
Anthropic via Vertex


Env vars: GOOGLE_APPLICATION_CREDENTIALS (path to service account JSON), VERTEXAI_PROJECT, VERTEXAI_LOCATION
8.2.5 Mistral AI
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Mistral Large 2
mistral/mistral-large-latest
128K
$2.00 in / $6.00 out
Flagship


Mistral Medium
mistral/mistral-medium-latest
128K
$2.70 in / $8.10 out
Balanced


Mistral Small
mistral/mistral-small-latest
128K
$0.20 in / $0.60 out
Fast, cheap


Codestral
mistral/codestral-latest
32K
$0.20 in / $0.60 out
Code specialist


Mistral Embed
mistral/mistral-embed
8K
$0.10 in
Embeddings


Env var: MISTRAL_API_KEY
8.2.6 Cohere
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Command R+
cohere/command-r-plus
128K
$2.50 in / $10.00 out
RAG-optimized flagship


Command R
cohere/command-r
128K
$0.15 in / $0.60 out
RAG-optimized efficient


Embed English v3
cohere/embed-english-v3.0
512
$0.10 in
English embeddings


Embed Multilingual v3
cohere/embed-multilingual-v3.0
512
$0.10 in
Multi-language embeddings


Rerank English v3
cohere/rerank-english-v3.0
â€”
$1.00 per 1K searches
Reranking


Env var: COHERE_API_KEY
8.2.7 Groq (Inference-as-a-Service)
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Llama 3.1 70B (Groq)
groq/llama-3.1-70b-versatile
128K
$0.59 in / $0.79 out
Ultra-fast inference


Llama 3.1 8B (Groq)
groq/llama-3.1-8b-instant
128K
$0.05 in / $0.08 out
Fastest available


Mixtral 8x7B (Groq)
groq/mixtral-8x7b-32768
32K
$0.24 in / $0.24 out
Fast MoE


Gemma 2 9B (Groq)
groq/gemma2-9b-it
8K
$0.20 in / $0.20 out
Google via Groq


Env var: GROQ_API_KEY
8.2.8 OpenRouter (Meta-Router)
Copy table


Model ID
LiteLLM Model String
Notes



Any model on OpenRouter
openrouter/<provider>/<model>
Single API key, hundreds of models


Example: Claude 3.5 Sonnet
openrouter/anthropic/claude-3.5-sonnet
Prices vary by model


Example: Llama 3.1 405B
openrouter/meta-llama/llama-3.1-405b-instruct
Access to huge models


Env var: OPENROUTER_API_KEY
8.2.9 Together AI
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Llama 3.1 405B
together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
128K
$3.50 in / $3.50 out
Largest Llama


Llama 3.1 70B
together_ai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
128K
$0.88 in / $0.88 out
Fast 70B


DeepSeek R1 671B
together_ai/deepseek-ai/DeepSeek-R1
64K
$3.00 in / $7.00 out
Reasoning giant


Qwen 2.5 72B
together_ai/Qwen/Qwen2.5-72B-Instruct-Turbo
128K
$1.20 in / $1.20 out
Top-tier open


Env var: TOGETHERAI_API_KEY
8.2.10 AWS Bedrock
Copy table


Model ID
LiteLLM Model String
Notes



Claude 3.5 Sonnet (Bedrock)
bedrock/anthropic.claude-3-5-sonnet-20241022-v2:0
AWS auth


Claude 3 Haiku (Bedrock)
bedrock/anthropic.claude-3-haiku-20240307-v1:0
AWS auth


Llama 3.1 70B (Bedrock)
bedrock/meta.llama3-1-70b-instruct-v1:0
AWS auth


Titan Embed v2
bedrock/amazon.titan-embed-text-v2:0
Embeddings


Env vars: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION_NAME
8.2.11 Azure OpenAI
Copy table


Model ID
LiteLLM Model String
Notes



GPT-4o (Azure)
azure/gpt-4o
Requires deployment name


GPT-4 Turbo (Azure)
azure/gpt-4-turbo
Requires deployment name


Embedding (Azure)
azure/text-embedding-3-large
Requires deployment name


Env vars: AZURE_API_KEY, AZURE_API_BASE, AZURE_API_VERSION
8.2.12 Perplexity
Copy table


Model ID
LiteLLM Model String
Context Window
Notes



Sonar Pro
perplexity/sonar-pro
200K
Search-grounded, citations


Sonar
perplexity/sonar
128K
Fast search-grounded


Sonar Deep Research
perplexity/sonar-deep-research
128K
Deep web research


Env var: PERPLEXITYAI_API_KEY
8.2.13 xAI (Grok)
Copy table


Model ID
LiteLLM Model String
Context Window
Pricing (per 1M tokens)
Notes



Grok 3
xai/grok-3
128K
$3.00 in / $15.00 out
Flagship


Grok 3 Mini
xai/grok-3-mini
128K
$0.30 in / $0.50 out
Fast reasoning


Env var: XAI_API_KEY
8.3 Provider Selection Flow (Script 2 â€” Interactive)
select_external_providers() {
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  EXTERNAL LLM PROVIDER SELECTION"
    echo "  Select providers you have API keys for."
    echo "  You can add/remove providers later via Script 4."
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    local providers=(
        "OpenAI"
        "Anthropic (Claude)"
        "Google Gemini"
        "Google Vertex AI"
        "Mistral AI"
        "Cohere"
        "Groq"
        "OpenRouter"
        "Together AI"
        "AWS Bedrock"
        "Azure OpenAI"
        "Perplexity"
        "xAI (Grok)"
    )

    SELECTED_PROVIDERS=()
    for i in "${!providers[@]}"; do
        read -rp "  Enable ${providers[ $ i]}? [y/N]: " yn
        if [[ " $ yn" =~ ^[Yy] ]]; then
            SELECTED_PROVIDERS+=("${providers[ $ i]}")
            prompt_api_key " $ {providers[$i]}"
        fi
    done

    save_provider_config
}

9. LiteLLM Routing Strategy
9.1 Overview
LiteLLM is the single entry point for all LLM requests from all services.
No service calls Ollama directly. No service calls external APIs directly.
LiteLLM provides: unified API, routing, fallbacks, rate limiting, cost tracking, load balancing.
9.2 Routing Strategy (from Script 2 config generation)
# /mnt/data/ai-platform/litellm/config.yaml
# Generated by Script 2 â€” DO NOT EDIT MANUALLY (will be overwritten)
# Use Script 4 to add/modify models, or edit and set LITELLM_CONFIG_MANAGED=false

general_settings:
  master_key: "${LITELLM_MASTER_KEY}"          # Generated by Script 1
  database_url: "postgresql://${PG_USER}:${PG_PASS}@postgresql:5432/litellm"
  alerting:
    - "webhook"
  alert_types:
    - "llm_exceptions"
    - "llm_too_slow"
    - "budget_alerts"

router_settings:
  routing_strategy: "usage-based-routing-v2"   # Balances cost + speed
  enable_pre_call_checks: true                 # Validate before sending
  retry_policy:
    BadRequestErrorRetries: 0                  # Don't retry bad requests
    AuthenticationErrorRetries: 0              # Don't retry auth failures
    TimeoutErrorRetries: 2                     # Retry timeouts twice
    RateLimitErrorRetries: 3                   # Retry rate limits 3 times
    ContentPolicyViolationErrorRetries: 0      # Don't retry policy blocks
  timeout: 120                                 # Global timeout seconds
  num_retries: 2                               # Default retries
  allowed_fails: 3                             # Mark unhealthy after 3 fails
  cooldown_time: 60                            # Seconds before retrying failed model
  fallbacks:
    - model: "gpt-4o"
      fallback_models: ["claude-sonnet-4", "gemini-2.5-pro", "ollama/llama3.1:8b"]
    - model: "claude-sonnet-4"
      fallback_models: ["gpt-4o", "gemini-2.5-pro", "ollama/llama3.1:8b"]
    - model: "gemini-2.5-pro"
      fallback_models: ["gpt-4o", "claude-sonnet-4", "ollama/llama3.1:8b"]

litellm_settings:
  drop_params: true                            # Drop unsupported params per model
  set_verbose: false                           # Set true for debugging
  cache: true                                  # Enable response caching
  cache_params:
    type: "redis"
    host: "redis"
    port: 6379
    ttl: 3600                                  # Cache for 1 hour
  success_callback: ["prometheus"]             # Export metrics
  failure_callback: ["prometheus"]
  max_budget: 100.0                            # Monthly budget cap USD
  budget_duration: "monthly"

model_list:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #  LOCAL MODELS (Ollama)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  - model_name: "local-default"
    litellm_params:
      model: "ollama/llama3.1:8b"
      api_base: "http://ollama:11434"
      stream: true
    model_info:
      mode: "chat"
      max_tokens: 8192
      supports_function_calling: true

  - model_name: "local-fast"
    litellm_params:
      model: "ollama/phi3:mini"
      api_base: "http://ollama:11434"
      stream: true
    model_info:
      mode: "chat"
      max_tokens: 4096

  - model_name: "local-embed"
    litellm_params:
      model: "ollama/nomic-embed-text"
      api_base: "http://ollama:11434"
    model_info:
      mode: "embedding"

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  #  EXTERNAL MODELS (conditionally included)
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # [OpenAI block â€” included if OPENAI_API_KEY is set]
  - model_name: "gpt-4o"
    litellm_params:
      model: "openai/gpt-4o"
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      mode: "chat"
      max_tokens: 16384

  - model_name: "gpt-4o-mini"
    litellm_params:
      model: "openai/gpt-4o-mini"
      api_key: "os.environ/OPENAI_API_KEY"
    model_info:
      mode: "chat"
      max_tokens: 16384

  # [Anthropic block â€” included if ANTHROPIC_API_KEY is set]
  - model_name: "claude-sonnet-4"
    litellm_params:
      model: "anthropic/claude-sonnet-4-20250514"
      api_key: "os.environ/ANTHROPIC_API_KEY"
    model_info:
      mode: "chat"
      max_tokens: 8192

  # [Gemini block â€” included if GEMINI_API_KEY is set]
  - model_name: "gemini-2.5-pro"
    litellm_params:
      model: "gemini/gemini-2.5-pro-preview-06-05"
      api_key: "os.environ/GEMINI_API_KEY"
    model_info:
      mode: "chat"
      max_tokens: 65536

  - model_name: "gemini-2.5-flash"
    litellm_params:
      model: "gemini/gemini-2.5-flash-preview-05-20"
      api_key: "os.environ/GEMINI_API_KEY"
    model_info:
      mode: "chat"
      max_tokens: 65536

  # ... (remaining providers follow same pattern)
9.3 Routing Strategies Available
Copy table


Strategy
routing_strategy Value
Behavior
When to Use



Usage-Based v2
usage-based-routing-v2
Distributes across models weighted by current utilization and cost
Default â€” balanced


Lowest Latency
latency-based-routing
Routes to model with lowest recent p95 latency
Speed-critical apps


Lowest Cost
cost-based-routing
Always picks cheapest model that can handle the request
Budget-constrained


Simple Shuffle
simple-shuffle
Random distribution across healthy models
Testing/load distribution


Least Busy
least-busy
Routes to model with fewest in-flight requests
High concurrency


Changing strategy at runtime:
# Edit config and restart
sed -i 's/routing_strategy:.*/routing_strategy: "latency-based-routing"/' \
    /mnt/data/ai-platform/litellm/config.yaml
docker restart litellm
9.4 Cost Controls
# Per-user budgets (set via LiteLLM admin API or config)
budget_config:
  default_max_budget: 50.0          # USD per user per month
  default_budget_duration: "monthly"
  budget_alert_threshold: 0.8       # Alert at 80% of budget

# Per-model rate limits
rate_limit_config:
  default_tpm_limit: 100000         # Tokens per minute
  default_rpm_limit: 100            # Requests per minute
---

## 10. Vector Database Strategy

### 10.1 Overview

Three vector databases are offered. User selects one (or more) during Script 2 interactive prompts.
Each serves different use cases and has different performance profiles.

### 10.2 Comparison Matrix

| Feature | Qdrant | Weaviate | Chroma |
|---|---|---|---|
| **Default?** | âœ… Primary | âŒ Optional | âŒ Optional |
| **Written in** | Rust | Go | Python |
| **Performance** | Excellent (Rust) | Very Good (Go) | Moderate (Python) |
| **Memory usage** | Lowâ€“Medium | Mediumâ€“High | Medium |
| **Disk storage** | Efficient (mmap) | Moderate | Moderate |
| **Max vectors** | Billions (sharded) | Billions (sharded) | Millions |
| **Filtering** | Full payload filtering | GraphQL-like filters | Metadata filtering |
| **Hybrid search** | Dense + Sparse (SPLADE) | Dense + BM25 | Dense only |
| **Multi-tenancy** | Collections + payload | Classes + tenants | Collections + tenants |
| **REST API** | âœ… Comprehensive | âœ… GraphQL + REST | âœ… Simple REST |
| **gRPC API** | âœ… High-performance | âœ… | âŒ |
| **Python client** | âœ… Official | âœ… Official | âœ… Official |
| **Docker image size** | ~90 MB | ~350 MB | ~500 MB |
| **RAM for 1M vectors** | ~1.5 GB (768d) | ~2.5 GB (768d) | ~3 GB (768d) |
| **Quantization** | Scalar + Product + Binary | Product (PQ) | âŒ |
| **Snapshot/backup** | âœ… Built-in API | âœ… Built-in API | âŒ (copy files) |
| **RBAC** | âœ… API keys | âœ… API keys + OIDC | âŒ |
| **LiteLLM integration** | Direct | Direct | Direct |
| **Dify integration** | âœ… Native plugin | âœ… Native plugin | âœ… Native plugin |
| **AnythingLLM integration** | âœ… Supported | âœ… Supported | âœ… Default |
| **n8n integration** | âœ… Community node | âœ… Native node | âœ… Community node |
| **Flowise integration** | âœ… Supported | âœ… Supported | âœ… Supported |

### 10.3 Recommendation Logic (Script 2)

```bash
recommend_vector_db() {
    local ram_gb=" $ 1"

    if [ " $ ram_gb" -ge 32 ]; then
        echo "RECOMMENDED: Qdrant (primary) + Weaviate (optional for hybrid search)"
    elif [ "$ram_gb" -ge 16 ]; then
        echo "RECOMMENDED: Qdrant (best performance per GB of RAM)"
    else
        echo "RECOMMENDED: Chroma (simplest, lowest resource usage)"
    fi
}
10.4 Qdrant Configuration (Default)
# /mnt/data/ai-platform/qdrant/config/config.yaml
storage:
  storage_path: /qdrant/storage
  snapshots_path: /qdrant/snapshots
  on_disk_payload: true              # Keeps payload on disk, saves RAM
  optimizers:
    default_segment_number: 2
    max_segment_size_kb: 200000      # 200 MB segments
    memmap_threshold_kb: 50000       # mmap files > 50 MB
    indexing_threshold_kb: 20000     # Build index when > 20 MB
    flush_interval_sec: 5
  performance:
    max_search_threads: 0            # 0 = auto (num CPUs)
    max_optimization_threads: 1

service:
  host: "0.0.0.0"
  http_port: 6333
  grpc_port: 6334
  api_key: "${QDRANT_API_KEY}"       # Generated by Script 1
  enable_tls: false                  # TLS handled by Caddy

telemetry_disabled: true
10.5 Weaviate Configuration (Optional)
# Environment variables for Weaviate container
QUERY_DEFAULTS_LIMIT: 25
AUTHENTICATION_APIKEY_ENABLED: 'true'
AUTHENTICATION_APIKEY_ALLOWED_KEYS: '${WEAVIATE_API_KEY}'
AUTHENTICATION_APIKEY_USERS: 'admin'
AUTHORIZATION_ADMINLIST_ENABLED: 'true'
AUTHORIZATION_ADMINLIST_USERS: 'admin'
DEFAULT_VECTORIZER_MODULE: 'none'      # We provide vectors from embedding models
ENABLE_MODULES: ''
CLUSTER_HOSTNAME: 'weaviate-node1'
PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
DISK_USE_WARNING_PERCENTAGE: 80
DISK_USE_READONLY_PERCENTAGE: 90
10.6 Chroma Configuration (Optional)
# Environment variables for Chroma container
IS_PERSISTENT: "TRUE"
PERSIST_DIRECTORY: "/chroma/chroma"
ANONYMIZED_TELEMETRY: "FALSE"
CHROMA_SERVER_AUTH_PROVIDER: "chromadb.auth.token.TokenAuthServerProvider"
CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER: "Authorization"
CHROMA_SERVER_AUTH_CREDENTIALS: "${CHROMA_AUTH_TOKEN}"
10.7 Vector DB in Service Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EMBEDDING FLOW                            â”‚
â”‚                                                              â”‚
â”‚  Document â†’ Dify/AnythingLLM/n8n/Flowise                    â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  LiteLLM â”€â”€â†’ Ollama (nomic-embed-text)                      â”‚
â”‚       â”‚       or OpenAI (text-embedding-3-large)             â”‚
â”‚       â”‚       or Cohere (embed-english-v3.0)                 â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Vector [768d or 1536d float array]                          â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Qdrant / Weaviate / Chroma  â”€â”€â†’  Store + Index             â”‚
â”‚                                                              â”‚
â”‚                    RETRIEVAL FLOW                             â”‚
â”‚                                                              â”‚
â”‚  User Query â†’ Application                                    â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  LiteLLM â”€â”€â†’ Embed query (same model as indexing!)          â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Vector DB â”€â”€â†’ Top-K nearest neighbors                      â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Application â”€â”€â†’ LiteLLM â”€â”€â†’ LLM (with retrieved context)  â”‚
â”‚       â”‚                                                      â”‚
â”‚       â–¼                                                      â”‚
â”‚  Response to user                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

11. OpenClaw Integration
11.1 Overview
OpenClaw is a highly sensitive service â€” it manages legal documents, contracts, and confidential client data. It receives the strictest access controls of any service in the platform.
11.2 Access Model â€” Tailscale Only
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               OPENCLAW ACCESS MODEL                  â”‚
â”‚                                                      â”‚
â”‚  PUBLIC INTERNET â”€â”€â”€â”€ âœ– BLOCKED â”€â”€â”€â”€                â”‚
â”‚                                                      â”‚
â”‚  Hetzner Firewall    : Port 18789 NOT allowed       â”‚
â”‚  Docker bind         : ${TAILSCALE_IP}:18789 ONLY   â”‚
â”‚  Caddy reverse proxy : NO openclaw subdomain        â”‚
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  TAILSCALE NETWORK ONLY                   â”‚      â”‚
â”‚  â”‚                                            â”‚      â”‚
â”‚  â”‚  Admin laptop â”€â”€â†’ Tailscale â”€â”€â†’ Server    â”‚      â”‚
â”‚  â”‚       â”‚                          â”‚         â”‚      â”‚
â”‚  â”‚       â”‚    http://<ts-ip>:18789  â”‚         â”‚      â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚      â”‚
â”‚  â”‚                                            â”‚      â”‚
â”‚  â”‚  OR via Tailscale MagicDNS:               â”‚      â”‚
â”‚  â”‚  http://server-name.tailnet.ts.net:18789  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
11.3 Docker Compose Specifics
# OpenClaw service â€” binds ONLY to Tailscale interface
openclaw:
  image: openclaw/openclaw:latest
  container_name: openclaw
  restart: unless-stopped
  ports:
    - "${TAILSCALE_IP}:18789:8080"    # ONLY Tailscale IP â€” critical
  environment:
    - DATABASE_URL=postgresql://${PG_OPENCLAW_USER}:${PG_OPENCLAW_PASS}@postgresql:5432/openclaw
    - REDIS_URL=redis://redis:6379/4
    - SECRET_KEY=${OPENCLAW_SECRET_KEY}
    - ALLOWED_HOSTS=${TAILSCALE_IP},localhost
    - CSRF_TRUSTED_ORIGINS=http://${TAILSCALE_IP}:18789
    - DEFAULT_LLM_PROVIDER=litellm
    - LITELLM_API_BASE=http://litellm:4000
    - LITELLM_API_KEY=${LITELLM_MASTER_KEY}
    - GOOGLE_DRIVE_ENABLED=${OPENCLAW_GDRIVE_ENABLED:-false}
    - GOOGLE_DRIVE_CREDENTIALS_FILE=/app/credentials/gdrive_service_account.json
    - GOOGLE_DRIVE_FOLDER_ID=${OPENCLAW_GDRIVE_FOLDER_ID:-}
  volumes:
    - /mnt/data/ai-platform/openclaw/data:/app/data
    - /mnt/data/ai-platform/openclaw/credentials:/app/credentials:ro
    - /mnt/data/ai-platform/openclaw/media:/app/media
  networks:
    - ai-platform-internal
  depends_on:
    postgresql:
      condition: service_healthy
    redis:
      condition: service_healthy
    litellm:
      condition: service_healthy
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 30s
11.4 OpenClaw Database Isolation
OpenClaw gets its own PostgreSQL database and user â€” not shared with other services:
-- Created by Script 2 during PostgreSQL initialization
CREATE USER openclaw_user WITH PASSWORD '${PG_OPENCLAW_PASS}';
CREATE DATABASE openclaw OWNER openclaw_user;
GRANT ALL PRIVILEGES ON DATABASE openclaw TO openclaw_user;
-- openclaw_user has ZERO access to dify, litellm, n8n, or other databases
11.5 Tailscale IP Detection (Script 1)
detect_tailscale_ip() {
    if ! command -v tailscale &>/dev/null; then
        log_warn "Tailscale not installed. OpenClaw will be configured but not accessible until Tailscale is set up."
        TAILSCALE_IP="100.x.x.x"  # Placeholder
        return 1
    fi

    TAILSCALE_IP= $ (tailscale ip -4 2>/dev/null)
    if [ -z " $ TAILSCALE_IP" ]; then
        log_warn "Tailscale installed but not connected. Run 'tailscale up' first."
        TAILSCALE_IP="100.x.x.x"  # Placeholder
        return 1
    fi

    export TAILSCALE_IP
    log_info "Tailscale IPv4: ${TAILSCALE_IP}"
    return 0
}

12. Google Drive Integration (OpenClaw)
12.1 Overview
OpenClaw can sync legal documents with Google Drive. This is optional and configured during Script 3 (post-deployment configuration).
12.2 Authentication Method: Service Account
We use a Google Service Account (not OAuth2 user consent) because:

No browser-based login flow needed on a headless server
Runs unattended â€” no token refresh issues
Can be scoped to a single shared folder
Credential is a JSON file â€” easy to manage

12.3 Setup Flow (Script 3 â€” Interactive)
configure_openclaw_gdrive() {
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  OPENCLAW â€” GOOGLE DRIVE INTEGRATION (OPTIONAL)"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    read -rp "  Enable Google Drive sync? [y/N]: " enable_gdrive
    if [[ ! " $ enable_gdrive" =~ ^[Yy] ]]; then
        log_info "Google Drive integration skipped."
        return 0
    fi

    echo ""
    echo "  PREREQUISITES:"
    echo "  1. Go to https://console.cloud.google.com/iam-admin/serviceaccounts"
    echo "  2. Create a service account (e.g., 'openclaw-gdrive')"
    echo "  3. Download the JSON key file"
    echo "  4. In Google Drive, create a folder for OpenClaw documents"
    echo "  5. Share that folder with the service account email"
    echo "     (the email looks like: openclaw-gdrive@project-id.iam.gserviceaccount.com)"
    echo "  6. Copy the folder ID from the URL:"
    echo "     https://drive.google.com/drive/folders/FOLDER_ID_HERE"
    echo ""

    # Prompt for service account JSON path
    read -rp "  Path to service account JSON file: " sa_json_path
    if [ ! -f " $ sa_json_path" ]; then
        log_error "File not found:  $ sa_json_path"
        return 1
    fi

    # Validate JSON structure
    if ! jq -e '.type == "service_account"' " $ sa_json_path" &>/dev/null; then
        log_error "Invalid service account JSON. Must contain \"type\": \"service_account\""
        return 1
    fi

    # Copy to secure location
    cp " $ sa_json_path" /mnt/data/ai-platform/openclaw/credentials/gdrive_service_account.json
    chmod 600 /mnt/data/ai-platform/openclaw/credentials/gdrive_service_account.json
    chown 1000:1000 /mnt/data/ai-platform/openclaw/credentials/gdrive_service_account.json
    log_info "Service account JSON copied to secure location."

    # Prompt for folder ID
    read -rp "  Google Drive folder ID: " gdrive_folder_id
    if [ -z " $ gdrive_folder_id" ]; then
        log_error "Folder ID cannot be empty."
        return 1
    fi

    # Store configuration
    {
        echo "OPENCLAW_GDRIVE_ENABLED=true"
        echo "OPENCLAW_GDRIVE_FOLDER_ID=${gdrive_folder_id}"
    } >> /mnt/data/ai-platform/credentials/openclaw.env

    log_info "Google Drive integration configured. Restart OpenClaw to activate."
    docker restart openclaw
}
12.4 Google Drive Permissions Model
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Drive                                                â”‚
â”‚  â””â”€â”€ Shared Folder: "OpenClaw Legal Documents"              â”‚
â”‚       â”œâ”€â”€ Shared with: openclaw-gdrive@project.iam.gsa.com â”‚
â”‚       â”œâ”€â”€ Permission: Editor                                â”‚
â”‚       â”œâ”€â”€ Folder ID: 1AbC2dEfG3hIjKlMnOpQrStUvWxYz         â”‚
â”‚       â”‚                                                      â”‚
â”‚       â”œâ”€â”€ Contracts/                                        â”‚
â”‚       â”‚   â”œâ”€â”€ client-a-contract-v2.pdf                      â”‚
â”‚       â”‚   â””â”€â”€ client-b-nda.docx                             â”‚
â”‚       â”œâ”€â”€ Templates/                                        â”‚
â”‚       â”‚   â”œâ”€â”€ standard-nda.docx                             â”‚
â”‚       â”‚   â””â”€â”€ service-agreement.docx                        â”‚
â”‚       â””â”€â”€ Research/                                         â”‚
â”‚           â””â”€â”€ case-law-notes.pdf                            â”‚
â”‚                                                              â”‚
â”‚  Service account can ONLY access this folder and children   â”‚
â”‚  Service account CANNOT access any other Drive content      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
12.5 Security Notes

Service account JSON is stored mode 600 â€” only container user can read
JSON file is mounted read-only in Docker (:ro flag)
Service account has no domain-wide delegation â€” only folder-level access
Folder should be shared as Editor (for upload) or Viewer (read-only sync)
If service account JSON is compromised: revoke key in GCP console â†’ delete â†’ create new key â†’ replace file â†’ restart OpenClaw

---

## 13. Credentials & Secrets Management

### 13.1 Principles

1. **No secrets in git** â€” ever. Not in scripts, not in compose files, not in comments.
2. **No secrets in shell history** â€” use `read -s` for interactive input, not command arguments.
3. **Secrets stored on data disk** â€” survives OS reinstall, single location to protect.
4. **File permissions enforced** â€” 600 for secret files, 700 for credential directories.
5. **Generated secrets are random** â€” 32+ character cryptographic random strings.
6. **User-provided secrets prompted interactively** â€” with validation before storage.
7. **.env files are the distribution mechanism** â€” Docker Compose reads from them.

### 13.2 Credential Directory Structure
/mnt/data/ai-platform/credentials/        # Mode 700
â”œâ”€â”€ .env                                   # Master env file â€” loaded by docker-compose
â”œâ”€â”€ api_keys.env                           # External API keys (user-provided)
â”œâ”€â”€ generated_secrets.env                  # Auto-generated passwords/tokens
â”œâ”€â”€ openclaw.env                           # OpenClaw-specific config
â”œâ”€â”€ tailscale_authkey.txt                  # Tailscale auth key (optional)
â”œâ”€â”€ backup_encryption.key                  # Backup encryption passphrase
â”œâ”€â”€ openclaw/                              # Mode 700
â”‚   â””â”€â”€ gdrive_service_account.json        # Mode 600 â€” Google Drive SA key
â””â”€â”€ README.md                              # Documents what each file contains

### 13.3 Secret Generation (Script 1)

```bash
generate_secret() {
    local length="${1:-32}"
    # /dev/urandom â†’ base64 â†’ strip non-alphanumeric â†’ take N chars
    tr -dc 'A-Za-z0-9' </dev/urandom | head -c " $ length"
}

generate_all_secrets() {
    local secrets_file="/mnt/data/ai-platform/credentials/generated_secrets.env"

    # Only generate if not already present (idempotent)
    if [ -f " $ secrets_file" ]; then
        log_info "Secrets file already exists. Preserving existing secrets."
        return 0
    fi

    log_info "Generating cryptographic secrets..."

    cat > "$secrets_file" << EOF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUTO-GENERATED SECRETS â€”  $ (date -u +"%Y-%m-%dT%H:%M:%SZ")
# DO NOT EDIT MANUALLY UNLESS YOU KNOW WHAT YOU'RE DOING
# Regenerating will require reconfiguring all services
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PostgreSQL
PG_SUPERUSER_PASS= $ (generate_secret 40)
PG_LITELLM_PASS= $ (generate_secret 32)
PG_DIFY_PASS= $ (generate_secret 32)
PG_N8N_PASS= $ (generate_secret 32)
PG_OPENCLAW_PASS= $ (generate_secret 32)

# Redis
REDIS_PASSWORD= $ (generate_secret 32)

# LiteLLM
LITELLM_MASTER_KEY=sk-litellm- $ (generate_secret 40)
LITELLM_SALT_KEY= $ (generate_secret 32)

# Dify
DIFY_SECRET_KEY= $ (generate_secret 48)
DIFY_INIT_PASSWORD= $ (generate_secret 16)

# n8n
N8N_ENCRYPTION_KEY= $ (generate_secret 32)

# OpenClaw
OPENCLAW_SECRET_KEY= $ (generate_secret 48)

# Caddy Basic Auth (admin endpoints)
CADDY_ADMIN_USER=admin
CADDY_ADMIN_PASS_HASH= $ (generate_secret 24)

# Vector Databases
QDRANT_API_KEY= $ (generate_secret 32)
WEAVIATE_API_KEY= $ (generate_secret 32)
CHROMA_AUTH_TOKEN= $ (generate_secret 32)

# Backup Encryption
BACKUP_ENCRYPTION_PASSPHRASE= $ (generate_secret 48)

# AnythingLLM
ANYTHINGLLM_AUTH_TOKEN= $ (generate_secret 32)

# Flowise
FLOWISE_USERNAME=admin
FLOWISE_PASSWORD= $ (generate_secret 24)
FLOWISE_SECRETKEY_OVERWRITE= $ (generate_secret 32)

# Open WebUI
OPEN_WEBUI_SECRET_KEY= $ (generate_secret 32)
EOF

    chmod 600 "$secrets_file"
    log_info "Secrets generated and stored in ${secrets_file}"
}
13.4 API Key Collection (Script 1 â€” Interactive)
collect_api_keys() {
    local api_keys_file="/mnt/data/ai-platform/credentials/api_keys.env"

    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  EXTERNAL API KEY CONFIGURATION"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "  Enter API keys for external LLM providers."
    echo "  Leave blank to skip a provider (can be added later)."
    echo "  Keys are stored locally and NEVER leave this server."
    echo ""

    # OpenAI
    read -s -rp "  OpenAI API key (sk-...): " openai_key
    echo ""

    # Anthropic
    read -s -rp "  Anthropic API key (sk-ant-...): " anthropic_key
    echo ""

    # Google Gemini
    read -s -rp "  Google Gemini API key: " gemini_key
    echo ""

    # Groq
    read -s -rp "  Groq API key (gsk_...): " groq_key
    echo ""

    # Mistral
    read -s -rp "  Mistral API key: " mistral_key
    echo ""

    # OpenRouter
    read -s -rp "  OpenRouter API key (sk-or-...): " openrouter_key
    echo ""

    # Cohere
    read -s -rp "  Cohere API key: " cohere_key
    echo ""

    # DeepSeek
    read -s -rp "  DeepSeek API key: " deepseek_key
    echo ""

    # Validate at least one is provided (warn if none)
    local key_count=0
    [ -n " $ openai_key" ] && ((key_count++))
    [ -n " $ anthropic_key" ] && ((key_count++))
    [ -n " $ gemini_key" ] && ((key_count++))
    [ -n " $ groq_key" ] && ((key_count++))

    if [ "$key_count" -eq 0 ]; then
        log_warn "No external API keys provided. Only local Ollama models will be available."
        log_warn "You can add keys later by editing: ${api_keys_file}"
    fi

    # Write file
    cat > "$api_keys_file" << EOF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTERNAL API KEYS â€” Configured  $ (date -u +"%Y-%m-%dT%H:%M:%SZ")
# Edit this file and restart LiteLLM to add/change keys
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY= $ {openai_key}
ANTHROPIC_API_KEY=${anthropic_key}
GEMINI_API_KEY=${gemini_key}
GROQ_API_KEY=${groq_key}
MISTRAL_API_KEY=${mistral_key}
OPENROUTER_API_KEY=${openrouter_key}
COHERE_API_KEY=${cohere_key}
DEEPSEEK_API_KEY=${deepseek_key}
EOF

    chmod 600 "$api_keys_file"
    log_info "API keys stored in ${api_keys_file} (${key_count} keys configured)"
}
13.5 Master .env File Assembly (Script 2)
assemble_master_env() {
    local master_env="/mnt/data/ai-platform/credentials/.env"
    local creds_dir="/mnt/data/ai-platform/credentials"

    log_info "Assembling master .env file..."

    # Start with header
    cat > " $ master_env" << 'EOF'
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MASTER ENVIRONMENT FILE â€” AUTO-ASSEMBLED
# This file is sourced by docker-compose.yml
# DO NOT EDIT â€” edit individual files in credentials/ instead
# Reassemble with: script3.sh --reassemble-env
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF

    # Append generated secrets
    echo "" >> " $ master_env"
    echo "# --- Generated Secrets ---" >> " $ master_env"
    grep -v '^#' " $ {creds_dir}/generated_secrets.env" | grep -v '^ $ ' >> " $ master_env"

    # Append API keys
    echo "" >> " $ master_env"
    echo "# --- External API Keys ---" >> " $ master_env"
    grep -v '^#' "${creds_dir}/api_keys.env" | grep -v '^ $ ' >> " $ master_env"

    # Append OpenClaw config (if exists)
    if [ -f "${creds_dir}/openclaw.env" ]; then
        echo "" >> " $ master_env"
        echo "# --- OpenClaw Config ---" >> " $ master_env"
        grep -v '^#' "${creds_dir}/openclaw.env" | grep -v '^ $ ' >> " $ master_env"
    fi

    # Append computed values
    echo "" >> " $ master_env"
    echo "# --- Computed Values ---" >> " $ master_env"
    echo "TAILSCALE_IP=${TAILSCALE_IP:-100.x.x.x}" >> " $ master_env"
    echo "SERVER_DOMAIN= $ {SERVER_DOMAIN:-ai.example.com}" >> " $ master_env"
    echo "COMPOSE_PROJECT_NAME=ai-platform" >> " $ master_env"

    chmod 600 "$master_env"
    log_info "Master .env assembled at ${master_env}"
}
13.6 Secret Rotation Procedure
# Rotate a specific secret (example: Redis password)
rotate_secret() {
    local secret_name=" $ 1"
    local secrets_file="/mnt/data/ai-platform/credentials/generated_secrets.env"

    # Generate new value
    local new_value
    new_value= $ (generate_secret 32)

    # Update in secrets file
    sed -i "s/^${secret_name}=.*/${secret_name}=${new_value}/" "$secrets_file"

    # Reassemble master .env
    assemble_master_env

    # Restart affected services
    log_info "Secret ${secret_name} rotated. Restarting affected services..."
    cd /opt/ai-platform
    docker compose down
    docker compose up -d

    log_info "Rotation complete. Verify services with: docker compose ps"
}
13.7 Emergency Key Revocation
EMERGENCY: API KEY COMPROMISED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. SSH to server immediately
2. Edit /mnt/data/ai-platform/credentials/api_keys.env
3. Remove/replace the compromised key
4. Run: cd /opt/ai-platform && docker compose restart litellm
5. Go to provider dashboard â†’ revoke old key â†’ generate new key
6. Update api_keys.env with new key â†’ restart litellm again
7. Check LiteLLM logs: docker logs litellm --tail 100

Total time to revoke: < 2 minutes from SSH connection

14. Monitoring Architecture
14.1 Overview
Monitoring is NOT optional â€” it runs by default.
The stack uses lightweight tools suitable for a single-server deployment.
No Prometheus/Grafana (overkill for single server).
14.2 Monitoring Components
Copy table


Component
Purpose
Runs As
Resource Cost



Docker healthchecks
Per-container liveness
Built into each container
Zero (Docker native)


Dozzle
Real-time log viewer (web UI)
Docker container
~15 MB RAM


cAdvisor
Container resource metrics
Docker container
~50 MB RAM


Custom health script
Aggregated health + alerting
Cron job (Script 3)
~5 MB per run


Uptime Kuma
External monitoring + alerting
Docker container
~60 MB RAM


Netdata (optional)
Full system metrics dashboard
Docker container
~150 MB RAM


14.3 Docker Healthchecks (Every Container)
Every service in docker-compose.yml has a healthcheck:
# Pattern applied to ALL services:
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:PORT/health"]
  interval: 30s       # Check every 30 seconds
  timeout: 10s        # Fail if no response in 10 seconds
  retries: 3          # Mark unhealthy after 3 consecutive failures
  start_period: 60s   # Grace period after container start
Copy table


Service
Health Endpoint
Check Method



PostgreSQL
N/A
pg_isready -U postgres


Redis
N/A
redis-cli ping


Ollama
http://localhost:11434/
curl -f


LiteLLM
http://localhost:4000/health
curl -f


Dify API
http://localhost:5001/health
curl -f


Dify Web
http://localhost:3000/
curl -f


n8n
http://localhost:5678/healthz
curl -f


OpenClaw
http://localhost:8080/health
curl -f


Open WebUI
http://localhost:8080/health
curl -f


AnythingLLM
http://localhost:3001/api/ping
curl -f


Flowise
http://localhost:3000/api/v1/ping
curl -f


Qdrant
http://localhost:6333/healthz
curl -f


Weaviate
http://localhost:8080/v1/.well-known/ready
curl -f


Caddy
http://localhost:2019/config/
curl -f


Uptime Kuma
http://localhost:3001/
curl -f


14.4 Dozzle â€” Log Viewer
dozzle:
  image: amir20/dozzle:latest
  container_name: dozzle
  restart: unless-stopped
  ports:
    - "${TAILSCALE_IP}:9999:8080"     # Tailscale-only access
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro
  environment:
    - DOZZLE_LEVEL=info
    - DOZZLE_TAILSCALE=false
    - DOZZLE_NO_ANALYTICS=true
  networks:
    - ai-platform-internal
Why Dozzle:

Zero configuration â€” discovers all containers automatically
Real-time log streaming with search/filter
~15 MB RAM footprint
Read-only Docker socket access â€” cannot modify containers

14.5 Uptime Kuma â€” Status & Alerts
uptime-kuma:
  image: louislam/uptime-kuma:latest
  container_name: uptime-kuma
  restart: unless-stopped
  ports:
    - "${TAILSCALE_IP}:3200:3001"     # Tailscale-only access
  volumes:
    - /mnt/data/ai-platform/uptime-kuma/data:/app/data
  networks:
    - ai-platform-internal
Auto-configured monitors (Script 3):
# Script 3 uses Uptime Kuma API to add monitors for all services
configure_uptime_kuma_monitors() {
    local base_url="http://localhost:3200"

    # Wait for Uptime Kuma to start
    wait_for_service " $ base_url" 60

    # Add monitors via API (after initial setup)
    local monitors=(
        "PostgreSQL|postgres|localhost|5432|tcp"
        "Redis|redis|localhost|6379|tcp"
        "Ollama|ollama|http://localhost:11434|200|http"
        "LiteLLM|litellm|http://localhost:4000/health|200|http"
        "Dify API|dify-api|http://localhost:5001/health|200|http"
        "n8n|n8n|http://localhost:5678/healthz|200|http"
        "Qdrant|qdrant|http://localhost:6333/healthz|200|http"
        "Caddy|caddy|http://localhost:2019/config/|200|http"
    )

    for monitor in " $ {monitors[@]}"; do
        IFS='|' read -r name slug url expected type <<< " $ monitor"
        add_uptime_kuma_monitor " $ name" " $ slug" " $ url" " $ expected" " $ type"
    done
}
14.6 Custom Health Check Script (Cron)
#!/usr/bin/env bash
# /opt/ai-platform/scripts/health-check.sh
# Runs every 5 minutes via cron (set up by Script 3)
# Outputs structured status and optionally sends alerts

set -euo pipefail

HEALTH_LOG="/mnt/data/ai-platform/logs/health/ $ (date +%Y-%m-%d).log"
ALERT_FILE="/mnt/data/ai-platform/logs/health/alerts.log"
STATUS_FILE="/mnt/data/ai-platform/logs/health/current_status.json"

declare -A SERVICES=(
    ["postgresql"]="pg_isready -h localhost -p 5432"
    ["redis"]="redis-cli -h localhost -p 6379 ping"
    ["ollama"]="curl -sf http://localhost:11434/ > /dev/null"
    ["litellm"]="curl -sf http://localhost:4000/health > /dev/null"
    ["dify-api"]="curl -sf http://localhost:5001/health > /dev/null"
    ["n8n"]="curl -sf http://localhost:5678/healthz > /dev/null"
    ["caddy"]="curl -sf http://localhost:2019/config/ > /dev/null"
    ["qdrant"]="curl -sf http://localhost:6333/healthz > /dev/null"
)

timestamp= $ (date -u +"%Y-%m-%dT%H:%M:%SZ")
all_healthy=true
status_json="{"

for service in "${!SERVICES[@]}"; do
    check_cmd="${SERVICES[ $ service]}"
    if eval " $ check_cmd" 2>/dev/null; then
        status="healthy"
    else
        status="unhealthy"
        all_healthy=false
        echo "${timestamp} ALERT: ${service} is UNHEALTHY" >> " $ ALERT_FILE"
    fi
    status_json+="\" $ {service}\":\"${status}\","
    echo "${timestamp} ${service}: ${status}" >> " $ HEALTH_LOG"
done

# System metrics
cpu_usage= $ (top -bn1 | grep "Cpu(s)" | awk '{print  $ 2}')
mem_total= $ (free -m | awk '/Mem:/ {print  $ 2}')
mem_used= $ (free -m | awk '/Mem:/ {print  $ 3}')
mem_pct= $ ((mem_used * 100 / mem_total))
disk_pct=$(df /mnt/data | awk 'NR==2 {print  $ 5}' | tr -d '%')

status_json+="\"cpu_percent\":\" $ {cpu_usage}\","
status_json+="\"memory_percent\":\"${mem_pct}\","
status_json+="\"disk_percent\":\"${disk_pct}\","
status_json+="\"all_healthy\":${all_healthy},"
status_json+="\"timestamp\":\"${timestamp}\""
status_json+="}"

echo " $ status_json" > " $ STATUS_FILE"

# Alert thresholds
if [ " $ mem_pct" -gt 90 ]; then
    echo " $ {timestamp} ALERT: Memory usage at ${mem_pct}%" >> " $ ALERT_FILE"
fi
if [ " $ disk_pct" -gt 85 ]; then
    echo "${timestamp} ALERT: Disk usage at ${disk_pct}%" >> "$ALERT_FILE"
fi

# Log rotation (keep 30 days)
find /mnt/data/ai-platform/logs/health/ -name "*.log" -mtime +30 -delete
14.7 Cron Setup (Script 3)
setup_monitoring_cron() {
    local cron_file="/etc/cron.d/ai-platform-health"

    cat > " $ cron_file" << 'EOF'
# AI Platform health checks
*/5 * * * * root /opt/ai-platform/scripts/health-check.sh >> /dev/null 2>&1
# Daily log summary
0 8 * * * root /opt/ai-platform/scripts/daily-summary.sh >> /dev/null 2>&1
# Backup check (verify last backup succeeded)
0 9 * * * root /opt/ai-platform/scripts/backup-verify.sh >> /dev/null 2>&1
EOF

    chmod 644 " $ cron_file"
    log_info "Health monitoring cron jobs installed."
}
14.8 Monitoring Dashboard Access
Copy table


Tool
URL
Access



Dozzle (logs)
http://<tailscale-ip>:9999
Tailscale only


Uptime Kuma
http://<tailscale-ip>:3200
Tailscale only


cAdvisor
http://<tailscale-ip>:9998
Tailscale only


Health JSON
cat /mnt/data/ai-platform/logs/health/current_status.json
SSH only


Alert log
tail -f /mnt/data/ai-platform/logs/health/alerts.log
SSH only
---

## 13. Credentials & Secrets Management

### 13.1 Principles

1. **No secrets in git** â€” ever. Not in scripts, not in compose files, not in comments.
2. **No secrets in shell history** â€” use `read -s` for interactive input, not command arguments.
3. **Secrets stored on data disk** â€” survives OS reinstall, single location to protect.
4. **File permissions enforced** â€” 600 for secret files, 700 for credential directories.
5. **Generated secrets are random** â€” 32+ character cryptographic random strings.
6. **User-provided secrets prompted interactively** â€” with validation before storage.
7. **.env files are the distribution mechanism** â€” Docker Compose reads from them.

### 13.2 Credential Directory Structure
/mnt/data/ai-platform/credentials/        # Mode 700
â”œâ”€â”€ .env                                   # Master env file â€” loaded by docker-compose
â”œâ”€â”€ api_keys.env                           # External API keys (user-provided)
â”œâ”€â”€ generated_secrets.env                  # Auto-generated passwords/tokens
â”œâ”€â”€ openclaw.env                           # OpenClaw-specific config
â”œâ”€â”€ tailscale_authkey.txt                  # Tailscale auth key (optional)
â”œâ”€â”€ backup_encryption.key                  # Backup encryption passphrase
â”œâ”€â”€ openclaw/                              # Mode 700
â”‚   â””â”€â”€ gdrive_service_account.json        # Mode 600 â€” Google Drive SA key
â””â”€â”€ README.md                              # Documents what each file contains

### 13.3 Secret Generation (Script 1)

```bash
generate_secret() {
    local length="${1:-32}"
    # /dev/urandom â†’ base64 â†’ strip non-alphanumeric â†’ take N chars
    tr -dc 'A-Za-z0-9' </dev/urandom | head -c " $ length"
}

generate_all_secrets() {
    local secrets_file="/mnt/data/ai-platform/credentials/generated_secrets.env"

    # Only generate if not already present (idempotent)
    if [ -f " $ secrets_file" ]; then
        log_info "Secrets file already exists. Preserving existing secrets."
        return 0
    fi

    log_info "Generating cryptographic secrets..."

    cat > "$secrets_file" << EOF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AUTO-GENERATED SECRETS â€”  $ (date -u +"%Y-%m-%dT%H:%M:%SZ")
# DO NOT EDIT MANUALLY UNLESS YOU KNOW WHAT YOU'RE DOING
# Regenerating will require reconfiguring all services
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PostgreSQL
PG_SUPERUSER_PASS= $ (generate_secret 40)
PG_LITELLM_PASS= $ (generate_secret 32)
PG_DIFY_PASS= $ (generate_secret 32)
PG_N8N_PASS= $ (generate_secret 32)
PG_OPENCLAW_PASS= $ (generate_secret 32)

# Redis
REDIS_PASSWORD= $ (generate_secret 32)

# LiteLLM
LITELLM_MASTER_KEY=sk-litellm- $ (generate_secret 40)
LITELLM_SALT_KEY= $ (generate_secret 32)

# Dify
DIFY_SECRET_KEY= $ (generate_secret 48)
DIFY_INIT_PASSWORD= $ (generate_secret 16)

# n8n
N8N_ENCRYPTION_KEY= $ (generate_secret 32)

# OpenClaw
OPENCLAW_SECRET_KEY= $ (generate_secret 48)

# Caddy Basic Auth (admin endpoints)
CADDY_ADMIN_USER=admin
CADDY_ADMIN_PASS_HASH= $ (generate_secret 24)

# Vector Databases
QDRANT_API_KEY= $ (generate_secret 32)
WEAVIATE_API_KEY= $ (generate_secret 32)
CHROMA_AUTH_TOKEN= $ (generate_secret 32)

# Backup Encryption
BACKUP_ENCRYPTION_PASSPHRASE= $ (generate_secret 48)

# AnythingLLM
ANYTHINGLLM_AUTH_TOKEN= $ (generate_secret 32)

# Flowise
FLOWISE_USERNAME=admin
FLOWISE_PASSWORD= $ (generate_secret 24)
FLOWISE_SECRETKEY_OVERWRITE= $ (generate_secret 32)

# Open WebUI
OPEN_WEBUI_SECRET_KEY= $ (generate_secret 32)
EOF

    chmod 600 "$secrets_file"
    log_info "Secrets generated and stored in ${secrets_file}"
}
13.4 API Key Collection (Script 1 â€” Interactive)
collect_api_keys() {
    local api_keys_file="/mnt/data/ai-platform/credentials/api_keys.env"

    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  EXTERNAL API KEY CONFIGURATION"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "  Enter API keys for external LLM providers."
    echo "  Leave blank to skip a provider (can be added later)."
    echo "  Keys are stored locally and NEVER leave this server."
    echo ""

    # OpenAI
    read -s -rp "  OpenAI API key (sk-...): " openai_key
    echo ""

    # Anthropic
    read -s -rp "  Anthropic API key (sk-ant-...): " anthropic_key
    echo ""

    # Google Gemini
    read -s -rp "  Google Gemini API key: " gemini_key
    echo ""

    # Groq
    read -s -rp "  Groq API key (gsk_...): " groq_key
    echo ""

    # Mistral
    read -s -rp "  Mistral API key: " mistral_key
    echo ""

    # OpenRouter
    read -s -rp "  OpenRouter API key (sk-or-...): " openrouter_key
    echo ""

    # Cohere
    read -s -rp "  Cohere API key: " cohere_key
    echo ""

    # DeepSeek
    read -s -rp "  DeepSeek API key: " deepseek_key
    echo ""

    # Validate at least one is provided (warn if none)
    local key_count=0
    [ -n " $ openai_key" ] && ((key_count++))
    [ -n " $ anthropic_key" ] && ((key_count++))
    [ -n " $ gemini_key" ] && ((key_count++))
    [ -n " $ groq_key" ] && ((key_count++))

    if [ "$key_count" -eq 0 ]; then
        log_warn "No external API keys provided. Only local Ollama models will be available."
        log_warn "You can add keys later by editing: ${api_keys_file}"
    fi

    # Write file
    cat > "$api_keys_file" << EOF
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXTERNAL API KEYS â€” Configured  $ (date -u +"%Y-%m-%dT%H:%M:%SZ")
# Edit this file and restart LiteLLM to add/change keys
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

OPENAI_API_KEY= $ {openai_key}
ANTHROPIC_API_KEY=${anthropic_key}
GEMINI_API_KEY=${gemini_key}
GROQ_API_KEY=${groq_key}
MISTRAL_API_KEY=${mistral_key}
OPENROUTER_API_KEY=${openrouter_key}
COHERE_API_KEY=${cohere_key}
DEEPSEEK_API_KEY=${deepseek_key}
EOF

    chmod 600 "$api_keys_file"
    log_info "API keys stored in ${api_keys_file} (${key_count} keys configured)"
}
13.5 Master .env File Assembly (Script 2)
assemble_master_env() {
    local master_env="/mnt/data/ai-platform/credentials/.env"
    local creds_dir="/mnt/data/ai-platform/credentials"

    log_info "Assembling master .env file..."

    # Start with header
    cat > " $ master_env" << 'EOF'
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MASTER ENVIRONMENT FILE â€” AUTO-ASSEMBLED
# This file is sourced by docker-compose.yml
# DO NOT EDIT â€” edit individual files in credentials/ instead
# Reassemble with: script3.sh --reassemble-env
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
EOF

    # Append generated secrets
    echo "" >> " $ master_env"
    echo "# --- Generated Secrets ---" >> " $ master_env"
    grep -v '^#' " $ {creds_dir}/generated_secrets.env" | grep -v '^ $ ' >> " $ master_env"

    # Append API keys
    echo "" >> " $ master_env"
    echo "# --- External API Keys ---" >> " $ master_env"
    grep -v '^#' "${creds_dir}/api_keys.env" | grep -v '^ $ ' >> " $ master_env"

    # Append OpenClaw config (if exists)
    if [ -f "${creds_dir}/openclaw.env" ]; then
        echo "" >> " $ master_env"
        echo "# --- OpenClaw Config ---" >> " $ master_env"
        grep -v '^#' "${creds_dir}/openclaw.env" | grep -v '^ $ ' >> " $ master_env"
    fi

    # Append computed values
    echo "" >> " $ master_env"
    echo "# --- Computed Values ---" >> " $ master_env"
    echo "TAILSCALE_IP=${TAILSCALE_IP:-100.x.x.x}" >> " $ master_env"
    echo "SERVER_DOMAIN= $ {SERVER_DOMAIN:-ai.example.com}" >> " $ master_env"
    echo "COMPOSE_PROJECT_NAME=ai-platform" >> " $ master_env"

    chmod 600 "$master_env"
    log_info "Master .env assembled at ${master_env}"
}
13.6 Secret Rotation Procedure
# Rotate a specific secret (example: Redis password)
rotate_secret() {
    local secret_name=" $ 1"
    local secrets_file="/mnt/data/ai-platform/credentials/generated_secrets.env"

    # Generate new value
    local new_value
    new_value= $ (generate_secret 32)

    # Update in secrets file
    sed -i "s/^${secret_name}=.*/${secret_name}=${new_value}/" "$secrets_file"

    # Reassemble master .env
    assemble_master_env

    # Restart affected services
    log_info "Secret ${secret_name} rotated. Restarting affected services..."
    cd /opt/ai-platform
    docker compose down
    docker compose up -d

    log_info "Rotation complete. Verify services with: docker compose ps"
}
13.7 Emergency Key Revocation
EMERGENCY: API KEY COMPROMISED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. SSH to server immediately
2. Edit /mnt/data/ai-platform/credentials/api_keys.env
3. Remove/replace the compromised key
4. Run: cd /opt/ai-platform && docker compose restart litellm
5. Go to provider dashboard â†’ revoke old key â†’ generate new key
6. Update api_keys.env with new key â†’ restart litellm again
7. Check LiteLLM logs: docker logs litellm --tail 100

Total time to revoke: < 2 minutes from SSH connection

14. Monitoring Architecture
14.1 Overview
Monitoring is NOT optional â€” it runs by default.
The stack uses lightweight tools suitable for a single-server deployment.
No Prometheus/Grafana (overkill for single server).
14.2 Monitoring Components
Copy table


Component
Purpose
Runs As
Resource Cost



Docker healthchecks
Per-container liveness
Built into each container
Zero (Docker native)


Dozzle
Real-time log viewer (web UI)
Docker container
~15 MB RAM


cAdvisor
Container resource metrics
Docker container
~50 MB RAM


Custom health script
Aggregated health + alerting
Cron job (Script 3)
~5 MB per run


Uptime Kuma
External monitoring + alerting
Docker container
~60 MB RAM


Netdata (optional)
Full system metrics dashboard
Docker container
~150 MB RAM


14.3 Docker Healthchecks (Every Container)
Every service in docker-compose.yml has a healthcheck:
# Pattern applied to ALL services:
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:PORT/health"]
  interval: 30s       # Check every 30 seconds
  timeout: 10s        # Fail if no response in 10 seconds
  retries: 3          # Mark unhealthy after 3 consecutive failures
  start_period: 60s   # Grace period after container start
Copy table


Service
Health Endpoint
Check Method



PostgreSQL
N/A
pg_isready -U postgres


Redis
N/A
redis-cli ping


Ollama
http://localhost:11434/
curl -f


LiteLLM
http://localhost:4000/health
curl -f


Dify API
http://localhost:5001/health
curl -f


Dify Web
http://localhost:3000/
curl -f


n8n
http://localhost:5678/healthz
curl -f


OpenClaw
http://localhost:8080/health
curl -f


Open WebUI
http://localhost:8080/health
curl -f


AnythingLLM
http://localhost:3001/api/ping
curl -f


Flowise
http://localhost:3000/api/v1/ping
curl -f


Qdrant
http://localhost:6333/healthz
curl -f


Weaviate
http://localhost:8080/v1/.well-known/ready
curl -f


Caddy
http://localhost:2019/config/
curl -f


Uptime Kuma
http://localhost:3001/
curl -f


14.4 Dozzle â€” Log Viewer
dozzle:
  image: amir20/dozzle:latest
  container_name: dozzle
  restart: unless-stopped
  ports:
    - "${TAILSCALE_IP}:9999:8080"     # Tailscale-only access
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro
  environment:
    - DOZZLE_LEVEL=info
    - DOZZLE_TAILSCALE=false
    - DOZZLE_NO_ANALYTICS=true
  networks:
    - ai-platform-internal
Why Dozzle:

Zero configuration â€” discovers all containers automatically
Real-time log streaming with search/filter
~15 MB RAM footprint
Read-only Docker socket access â€” cannot modify containers

14.5 Uptime Kuma â€” Status & Alerts
uptime-kuma:
  image: louislam/uptime-kuma:latest
  container_name: uptime-kuma
  restart: unless-stopped
  ports:
    - "${TAILSCALE_IP}:3200:3001"     # Tailscale-only access
  volumes:
    - /mnt/data/ai-platform/uptime-kuma/data:/app/data
  networks:
    - ai-platform-internal
Auto-configured monitors (Script 3):
# Script 3 uses Uptime Kuma API to add monitors for all services
configure_uptime_kuma_monitors() {
    local base_url="http://localhost:3200"

    # Wait for Uptime Kuma to start
    wait_for_service " $ base_url" 60

    # Add monitors via API (after initial setup)
    local monitors=(
        "PostgreSQL|postgres|localhost|5432|tcp"
        "Redis|redis|localhost|6379|tcp"
        "Ollama|ollama|http://localhost:11434|200|http"
        "LiteLLM|litellm|http://localhost:4000/health|200|http"
        "Dify API|dify-api|http://localhost:5001/health|200|http"
        "n8n|n8n|http://localhost:5678/healthz|200|http"
        "Qdrant|qdrant|http://localhost:6333/healthz|200|http"
        "Caddy|caddy|http://localhost:2019/config/|200|http"
    )

    for monitor in " $ {monitors[@]}"; do
        IFS='|' read -r name slug url expected type <<< " $ monitor"
        add_uptime_kuma_monitor " $ name" " $ slug" " $ url" " $ expected" " $ type"
    done
}
14.6 Custom Health Check Script (Cron)
#!/usr/bin/env bash
# /opt/ai-platform/scripts/health-check.sh
# Runs every 5 minutes via cron (set up by Script 3)
# Outputs structured status and optionally sends alerts

set -euo pipefail

HEALTH_LOG="/mnt/data/ai-platform/logs/health/ $ (date +%Y-%m-%d).log"
ALERT_FILE="/mnt/data/ai-platform/logs/health/alerts.log"
STATUS_FILE="/mnt/data/ai-platform/logs/health/current_status.json"

declare -A SERVICES=(
    ["postgresql"]="pg_isready -h localhost -p 5432"
    ["redis"]="redis-cli -h localhost -p 6379 ping"
    ["ollama"]="curl -sf http://localhost:11434/ > /dev/null"
    ["litellm"]="curl -sf http://localhost:4000/health > /dev/null"
    ["dify-api"]="curl -sf http://localhost:5001/health > /dev/null"
    ["n8n"]="curl -sf http://localhost:5678/healthz > /dev/null"
    ["caddy"]="curl -sf http://localhost:2019/config/ > /dev/null"
    ["qdrant"]="curl -sf http://localhost:6333/healthz > /dev/null"
)

timestamp= $ (date -u +"%Y-%m-%dT%H:%M:%SZ")
all_healthy=true
status_json="{"

for service in "${!SERVICES[@]}"; do
    check_cmd="${SERVICES[ $ service]}"
    if eval " $ check_cmd" 2>/dev/null; then
        status="healthy"
    else
        status="unhealthy"
        all_healthy=false
        echo "${timestamp} ALERT: ${service} is UNHEALTHY" >> " $ ALERT_FILE"
    fi
    status_json+="\" $ {service}\":\"${status}\","
    echo "${timestamp} ${service}: ${status}" >> " $ HEALTH_LOG"
done

# System metrics
cpu_usage= $ (top -bn1 | grep "Cpu(s)" | awk '{print  $ 2}')
mem_total= $ (free -m | awk '/Mem:/ {print  $ 2}')
mem_used= $ (free -m | awk '/Mem:/ {print  $ 3}')
mem_pct= $ ((mem_used * 100 / mem_total))
disk_pct=$(df /mnt/data | awk 'NR==2 {print  $ 5}' | tr -d '%')

status_json+="\"cpu_percent\":\" $ {cpu_usage}\","
status_json+="\"memory_percent\":\"${mem_pct}\","
status_json+="\"disk_percent\":\"${disk_pct}\","
status_json+="\"all_healthy\":${all_healthy},"
status_json+="\"timestamp\":\"${timestamp}\""
status_json+="}"

echo " $ status_json" > " $ STATUS_FILE"

# Alert thresholds
if [ " $ mem_pct" -gt 90 ]; then
    echo " $ {timestamp} ALERT: Memory usage at ${mem_pct}%" >> " $ ALERT_FILE"
fi
if [ " $ disk_pct" -gt 85 ]; then
    echo "${timestamp} ALERT: Disk usage at ${disk_pct}%" >> "$ALERT_FILE"
fi

# Log rotation (keep 30 days)
find /mnt/data/ai-platform/logs/health/ -name "*.log" -mtime +30 -delete
14.7 Cron Setup (Script 3)
setup_monitoring_cron() {
    local cron_file="/etc/cron.d/ai-platform-health"

    cat > " $ cron_file" << 'EOF'
# AI Platform health checks
*/5 * * * * root /opt/ai-platform/scripts/health-check.sh >> /dev/null 2>&1
# Daily log summary
0 8 * * * root /opt/ai-platform/scripts/daily-summary.sh >> /dev/null 2>&1
# Backup check (verify last backup succeeded)
0 9 * * * root /opt/ai-platform/scripts/backup-verify.sh >> /dev/null 2>&1
EOF

    chmod 644 " $ cron_file"
    log_info "Health monitoring cron jobs installed."
}
14.8 Monitoring Dashboard Access
Copy table


Tool
URL
Access



Dozzle (logs)
http://<tailscale-ip>:9999
Tailscale only


Uptime Kuma
http://<tailscale-ip>:3200
Tailscale only


cAdvisor
http://<tailscale-ip>:9998
Tailscale only


Health JSON
cat /mnt/data/ai-platform/logs/health/current_status.json
SSH only


Alert log
tail -f /mnt/data/ai-platform/logs/health/alerts.log
SSH only



---

**Continuing automatically to Part 7 of 12: Backup & Restore Architecture + Disaster Recovery...**
continuePART 7 OF 12 â€” BACKUP & RESTORE ARCHITECTURE + DISASTER RECOVERY
---

## 15. Backup & Restore Architecture

### 15.1 Principles

1. **Backups are automatic** â€” daily by default, configured by Script 3.
2. **Backups are encrypted** â€” AES-256 using auto-generated passphrase.
3. **Backups are complete** â€” a single backup restores the ENTIRE platform.
4. **Backups are tested** â€” weekly integrity verification via cron.
5. **Restore is one command** â€” `script3.sh --restore <backup-file>`.
6. **Backup location is configurable** â€” local, external drive, or remote (rsync/rclone).
7. **Retention policy enforced** â€” oldest backups auto-deleted per configured policy.

### 15.2 What Gets Backed Up

| Category | Source Path | Contents | Criticality |
|---|---|---|---|
| **Credentials** | `/mnt/data/ai-platform/credentials/` | All secrets, API keys, service account JSON | ğŸ”´ CRITICAL |
| **PostgreSQL** | Logical dump (pg_dumpall) | All databases for all services | ğŸ”´ CRITICAL |
| **LiteLLM Config** | `/mnt/data/ai-platform/litellm/` | Model routing, budgets, user config | ğŸŸ¡ HIGH |
| **Dify Storage** | `/mnt/data/ai-platform/dify/` | Apps, workflows, datasets, uploaded files | ğŸ”´ CRITICAL |
| **n8n Data** | `/mnt/data/ai-platform/n8n/` | Workflows, credentials, execution logs | ğŸ”´ CRITICAL |
| **OpenClaw Data** | `/mnt/data/ai-platform/openclaw/` | Legal documents, templates, settings | ğŸ”´ CRITICAL |
| **Qdrant Snapshots** | `/mnt/data/ai-platform/qdrant/snapshots/` | Vector database snapshots | ğŸŸ¡ HIGH |
| **Weaviate Backup** | `/mnt/data/ai-platform/weaviate/backups/` | Vector database backup | ğŸŸ¡ HIGH |
| **Open WebUI** | `/mnt/data/ai-platform/open-webui/` | Chat history, user settings | ğŸŸ¢ MEDIUM |
| **AnythingLLM** | `/mnt/data/ai-platform/anythingllm/` | Workspaces, documents, embeddings | ğŸŸ¢ MEDIUM |
| **Flowise** | `/mnt/data/ai-platform/flowise/` | Flows, chatflows, credentials | ğŸŸ¡ HIGH |
| **Uptime Kuma** | `/mnt/data/ai-platform/uptime-kuma/` | Monitor config, incident history | ğŸŸ¢ LOW |
| **Caddy Config** | `/mnt/data/ai-platform/caddy/` | Caddyfile, TLS certs, data | ğŸŸ¡ HIGH |
| **Docker Compose** | `/opt/ai-platform/` | Compose files, scripts (also in git) | ğŸŸ¢ LOW |
| **Ollama Models** | **NOT backed up** | Too large; re-pull from registry | âšª SKIP |

### 15.3 What Is NOT Backed Up (and Why)

| Item | Size | Reason | Recovery Method |
|---|---|---|---|
| Ollama models | 5â€“100+ GB | Immutable; re-download from Ollama registry | `ollama pull <model>` |
| Docker images | 5â€“20 GB | Immutable; re-download from Docker Hub | `docker compose pull` |
| Redis data | < 100 MB | Ephemeral cache; rebuilds automatically | Services repopulate on start |
| Container logs | Variable | Available via Docker; rotated automatically | `docker logs <container>` |
| OS-level config | N/A | Reinstallable; Script 1 recreates everything | Re-run Script 1 |

### 15.4 Backup Script

```bash
#!/usr/bin/env bash
# /opt/ai-platform/scripts/backup.sh
# Called by cron daily or manually via script3.sh --backup

set -euo pipefail

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PLATFORM_DIR="/mnt/data/ai-platform"
BACKUP_DIR="/mnt/data/ai-platform/backups"
CREDENTIALS_DIR="${PLATFORM_DIR}/credentials"
TIMESTAMP= $ (date +%Y%m%d-%H%M%S)
BACKUP_NAME="ai-platform-backup- $ {TIMESTAMP}"
WORK_DIR="${BACKUP_DIR}/work-${TIMESTAMP}"
FINAL_FILE="${BACKUP_DIR}/${BACKUP_NAME}.tar.gz.enc"

# Load encryption passphrase
ENCRYPTION_KEY= $ (grep '^BACKUP_ENCRYPTION_PASSPHRASE=' \
    " $ {CREDENTIALS_DIR}/generated_secrets.env" | cut -d'=' -f2-)

# Source common functions
source /opt/ai-platform/scripts/common.sh

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pre-flight checks
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
preflight_checks() {
    log_info "Running backup pre-flight checks..."

    # Check disk space (need at least 10 GB free)
    local free_gb
    free_gb= $ (df /mnt/data --output=avail -BG | tail -1 | tr -d ' G')
    if [ " $ free_gb" -lt 10 ]; then
        log_error "Insufficient disk space: ${free_gb}GB free (need 10GB minimum)"
        exit 1
    fi

    # Verify PostgreSQL is healthy
    if ! docker exec postgresql pg_isready -U postgres > /dev/null 2>&1; then
        log_error "PostgreSQL is not healthy. Cannot create consistent backup."
        exit 1
    fi

    # Create work directory
    mkdir -p "$WORK_DIR"
    log_info "Pre-flight checks passed. Free disk: ${free_gb}GB"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 1: PostgreSQL dump
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
backup_postgresql() {
    log_info "Dumping PostgreSQL databases..."

    # Dump all databases (consistent snapshot)
    docker exec postgresql pg_dumpall \
        -U postgres \
        --clean \
        --if-exists \
        --quote-all-identifiers \
        | gzip > "${WORK_DIR}/postgresql-all.sql.gz"

    # Also dump individually for selective restore
    for db in litellm dify n8n openclaw; do
        if docker exec postgresql psql -U postgres -lqt | grep -qw " $ db"; then
            docker exec postgresql pg_dump \
                -U postgres \
                --format=custom \
                --compress=6 \
                " $ db" > "${WORK_DIR}/postgresql-${db}.dump"
            log_info "  Dumped database: ${db}"
        fi
    done

    log_info "PostgreSQL dump complete."
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 2: Vector database snapshots
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
backup_vector_dbs() {
    # Qdrant snapshot
    if docker ps --format '{{.Names}}' | grep -q '^qdrant $ '; then
        log_info "Creating Qdrant snapshot..."
        # Trigger snapshot via API
        local collections
        collections= $ (curl -sf http://localhost:6333/collections | jq -r '.result.collections[].name')
        for collection in  $ collections; do
            curl -sf -X POST \
                "http://localhost:6333/collections/ $ {collection}/snapshots" \
                -H "api-key: $(grep QDRANT_API_KEY ${CREDENTIALS_DIR}/generated_secrets.env | cut -d= -f2-)" \
                > /dev/null
            log_info "  Snapshot created for collection: ${collection}"
        done
        # Copy snapshots
        cp -r "${PLATFORM_DIR}/qdrant/snapshots/" "${WORK_DIR}/qdrant-snapshots/" 2>/dev/null || true
    fi

    # Weaviate backup
    if docker ps --format '{{.Names}}' | grep -q '^weaviate $ '; then
        log_info "Creating Weaviate backup..."
        curl -sf -X POST \
            "http://localhost:8080/v1/backups/filesystem" \
            -H "Content-Type: application/json" \
            -d "{\"id\": \"backup- $ {TIMESTAMP}\"}" \
            > /dev/null
        cp -r "${PLATFORM_DIR}/weaviate/backups/" "${WORK_DIR}/weaviate-backups/" 2>/dev/null || true
    fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 3: Application data
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
backup_application_data() {
    log_info "Copying application data..."

    local dirs=(
        "credentials"
        "litellm"
        "dify"
        "n8n"
        "openclaw"
        "open-webui"
        "anythingllm"
        "flowise"
        "uptime-kuma"
        "caddy"
    )

    for dir in "${dirs[@]}"; do
        if [ -d "${PLATFORM_DIR}/${dir}" ]; then
            # Use rsync for efficient copy, exclude large temp files
            rsync -a \
                --exclude='*.tmp' \
                --exclude='*.log' \
                --exclude='__pycache__' \
                --exclude='node_modules' \
                --exclude='.cache' \
                "${PLATFORM_DIR}/${dir}/" "${WORK_DIR}/data-${dir}/"
            log_info "  Copied: ${dir}"
        fi
    done

    # Copy docker compose and scripts
    rsync -a /opt/ai-platform/ "${WORK_DIR}/platform-config/" \
        --exclude='.git' --exclude='__pycache__'
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 4: Create manifest
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
create_manifest() {
    log_info "Creating backup manifest..."

    cat > "${WORK_DIR}/MANIFEST.json" << EOF
{
    "backup_name": "${BACKUP_NAME}",
    "timestamp": " $ (date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "hostname": " $ (hostname)",
    "platform_version": "1.0.0",
    "tailscale_ip": " $ (tailscale ip -4 2>/dev/null || echo 'unknown')",
    "docker_version": " $ (docker --version | awk '{print  $ 3}' | tr -d ',')",
    "os_version": " $ (lsb_release -ds 2>/dev/null || cat /etc/os-release | grep PRETTY | cut -d= -f2 | tr -d '\"')",
    "disk_usage_before_backup": "$(du -sh ${PLATFORM_DIR} | awk '{print $1}')",
    "components": {
        "postgresql": $(docker ps --format '{{.Names}}' | grep -cw postgresql || echo 0),
        "redis": $(docker ps --format '{{.Names}}' | grep -cw redis || echo 0),
        "ollama": $(docker ps --format '{{.Names}}' | grep -cw ollama || echo 0),
        "litellm": $(docker ps --format '{{.Names}}' | grep -cw litellm || echo 0),
        "dify": $(docker ps --format '{{.Names}}' | grep -cw 'dify-*' || echo 0),
        "n8n": $(docker ps --format '{{.Names}}' | grep -cw n8n || echo 0),
        "openclaw": $(docker ps --format '{{.Names}}' | grep -cw openclaw || echo 0),
        "qdrant": $(docker ps --format '{{.Names}}' | grep -cw qdrant || echo 0)
    },
    "databases_dumped": $(ls ${WORK_DIR}/postgresql-*.dump 2>/dev/null | wc -l),
    "encryption": "AES-256-CBC",
    "checksum_algorithm": "SHA-256"
}
EOF
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 5: Compress and encrypt
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
compress_and_encrypt() {
    log_info "Compressing backup..."

    # Create tar.gz
    tar -czf "${BACKUP_DIR}/${BACKUP_NAME}.tar.gz" \
        -C " $ WORK_DIR" .

    local unencrypted_size
    unencrypted_size= $ (du -sh "${BACKUP_DIR}/${BACKUP_NAME}.tar.gz" | awk '{print $1}')
    log_info "Compressed size: ${unencrypted_size}"

    # Encrypt with AES-256
    log_info "Encrypting backup..."
    openssl enc -aes-256-cbc -salt -pbkdf2 -iter 100000 \
        -in "${BACKUP_DIR}/${BACKUP_NAME}.tar.gz" \
        -out " $ FINAL_FILE" \
        -pass "pass: $ {ENCRYPTION_KEY}"

    # Generate checksum
    sha256sum " $ FINAL_FILE" > " $ {FINAL_FILE}.sha256"

    # Clean up unencrypted files
    rm -f "${BACKUP_DIR}/${BACKUP_NAME}.tar.gz"
    rm -rf " $ WORK_DIR"

    local final_size
    final_size= $ (du -sh "$FINAL_FILE" | awk '{print $1}')
    log_info "Final encrypted backup: ${FINAL_FILE} (${final_size})"
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Step 6: Retention cleanup
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
enforce_retention() {
    local keep_days="${1:-30}"
    local keep_count="${2:-10}"

    log_info "Enforcing retention policy: ${keep_days} days or ${keep_count} backups..."

    # Delete by age
    find " $ BACKUP_DIR" -name "ai-platform-backup-*.tar.gz.enc" \
        -mtime "+ $ {keep_days}" -delete

    # Delete by count (keep newest N)
    local backup_count
    backup_count= $ (ls -1 " $ {BACKUP_DIR}"/ai-platform-backup-*.tar.gz.enc 2>/dev/null | wc -l)
    if [ " $ backup_count" -gt " $ keep_count" ]; then
        local to_delete= $ ((backup_count - keep_count))
        ls -1t " $ {BACKUP_DIR}"/ai-platform-backup-*.tar.gz.enc | tail -n " $ to_delete" | while read -r old_backup; do
            rm -f " $ old_backup" "${old_backup}.sha256"
            log_info "  Deleted old backup:  $ (basename " $ old_backup")"
        done
    fi
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main execution
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
main() {
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "  AI PLATFORM BACKUP STARTING"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    preflight_checks
    backup_postgresql
    backup_vector_dbs
    backup_application_data
    create_manifest
    compress_and_encrypt
    enforce_retention 30 10

    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log_info "  BACKUP COMPLETE: ${FINAL_FILE}"
    log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
}

main "$@"
15.5 Restore Script
#!/usr/bin/env bash
# /opt/ai-platform/scripts/restore.sh
# Usage: ./restore.sh <backup-file.tar.gz.enc>

set -euo pipefail

BACKUP_FILE=" $ 1"
PLATFORM_DIR="/mnt/data/ai-platform"
CREDENTIALS_DIR=" $ {PLATFORM_DIR}/credentials"
RESTORE_DIR="/mnt/data/ai-platform/restore-work"

source /opt/ai-platform/scripts/common.sh

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Pre-flight
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if [ ! -f "$BACKUP_FILE" ]; then
    log_error "Backup file not found:  $ BACKUP_FILE"
    exit 1
fi

# Verify checksum if available
if [ -f " $ {BACKUP_FILE}.sha256" ]; then
    log_info "Verifying backup checksum..."
    if sha256sum -c "${BACKUP_FILE}.sha256"; then
        log_info "Checksum verified âœ“"
    else
        log_error "Checksum verification FAILED. Backup may be corrupted."
        read -rp "Continue anyway? (yes/no): " confirm
        [ " $ confirm" != "yes" ] && exit 1
    fi
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Get encryption key
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if [ -f " $ {CREDENTIALS_DIR}/generated_secrets.env" ]; then
    ENCRYPTION_KEY= $ (grep '^BACKUP_ENCRYPTION_PASSPHRASE=' \
        " $ {CREDENTIALS_DIR}/generated_secrets.env" | cut -d'=' -f2-)
else
    log_warn "No existing credentials found. Enter backup encryption passphrase:"
    read -s -rp "Passphrase: " ENCRYPTION_KEY
    echo ""
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Decrypt and extract
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
log_info "Decrypting backup..."
mkdir -p " $ RESTORE_DIR"

openssl enc -aes-256-cbc -d -salt -pbkdf2 -iter 100000 \
    -in " $ BACKUP_FILE" \
    -pass "pass:${ENCRYPTION_KEY}" \
    | tar -xzf - -C " $ RESTORE_DIR"

# Verify manifest
if [ -f " $ {RESTORE_DIR}/MANIFEST.json" ]; then
    log_info "Backup manifest:"
    cat "${RESTORE_DIR}/MANIFEST.json" | jq .
    echo ""
    read -rp "Proceed with restore? (yes/no): " confirm
    [ " $ confirm" != "yes" ] && { rm -rf " $ RESTORE_DIR"; exit 0; }
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Stop all services
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
log_info "Stopping all services..."
cd /opt/ai-platform
docker compose down || true

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Restore credentials
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
log_info "Restoring credentials..."
if [ -d "${RESTORE_DIR}/data-credentials" ]; then
    # Backup current credentials just in case
    if [ -d " $ CREDENTIALS_DIR" ]; then
        mv " $ CREDENTIALS_DIR" "${CREDENTIALS_DIR}.pre-restore- $ (date +%s)"
    fi
    cp -r " $ {RESTORE_DIR}/data-credentials" " $ CREDENTIALS_DIR"
    chmod 700 " $ CREDENTIALS_DIR"
    find " $ CREDENTIALS_DIR" -type f -exec chmod 600 {} \;
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Restore PostgreSQL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
log_info "Restoring PostgreSQL..."

# Start only PostgreSQL
docker compose up -d postgresql
sleep 10

# Wait for PostgreSQL to be ready
until docker exec postgresql pg_isready -U postgres > /dev/null 2>&1; do
    sleep 2
done

# Restore from full dump
if [ -f " $ {RESTORE_DIR}/postgresql-all.sql.gz" ]; then
    gunzip -c "${RESTORE_DIR}/postgresql-all.sql.gz" | \
        docker exec -i postgresql psql -U postgres
    log_info "PostgreSQL full dump restored."
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Restore application data
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
log_info "Restoring application data..."

local restore_dirs=(
    "litellm" "dify" "n8n" "openclaw"
    "open-webui" "anythingllm" "flowise"
    "uptime-kuma" "caddy"
)

for dir in "${restore_dirs[@]}"; do
    if [ -d "${RESTORE_DIR}/data-${dir}" ]; then
        # Backup current data
        if [ -d "${PLATFORM_DIR}/${dir}" ]; then
            mv "${PLATFORM_DIR}/${dir}" "${PLATFORM_DIR}/${dir}.pre-restore"
        fi
        cp -r "${RESTORE_DIR}/data-${dir}" "${PLATFORM_DIR}/${dir}"
        log_info "  Restored: ${dir}"
    fi
done

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Restore vector databases
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if [ -d "${RESTORE_DIR}/qdrant-snapshots" ]; then
    log_info "Restoring Qdrant snapshots..."
    cp -r "${RESTORE_DIR}/qdrant-snapshots/"* "${PLATFORM_DIR}/qdrant/snapshots/" 2>/dev/null || true
    # Qdrant will auto-restore from snapshots on start
fi

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Start all services
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
log_info "Starting all services..."
docker compose up -d

# Wait and verify
sleep 30
/opt/ai-platform/scripts/health-check.sh

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Cleanup
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
rm -rf "$RESTORE_DIR"
log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log_info "  RESTORE COMPLETE"
log_info "  Run 'docker compose ps' to verify services"
log_info "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

16. Disaster Recovery
16.1 Recovery Scenarios
Copy table


Scenario
RTO (Recovery Time)
Data Loss
Procedure



Container crash
0 min (auto-restart)
None
Docker restart: unless-stopped handles it


Service corruption
5â€“15 min
None
docker compose down <service> && docker compose up -d <service>


Database corruption
15â€“30 min
Up to 24h
Restore from backup: script3.sh --restore <file>


Data disk failure
30â€“60 min
Up to 24h
Replace disk â†’ restore from offsite backup


OS disk failure
45â€“90 min
None
Reinstall OS â†’ run Script 1 â†’ Script 2 â†’ restore from backup


Complete server loss
1â€“3 hours
Up to 24h
New server â†’ run all scripts â†’ restore from offsite backup


Encryption key lost
âˆ
ALL
UNRECOVERABLE â€” document key in secure vault


16.2 Recovery Priority Order
Priority 1 (CRITICAL â€” Restore First):
  â”œâ”€â”€ Credentials â†’ Without these, nothing works
  â””â”€â”€ PostgreSQL â†’ Core state for all applications

Priority 2 (HIGH â€” Restore Second):
  â”œâ”€â”€ LiteLLM config â†’ Re-enables all LLM routing
  â”œâ”€â”€ Dify data â†’ Restores AI workflows
  â””â”€â”€ n8n data â†’ Restores automations

Priority 3 (MEDIUM â€” Restore Third):
  â”œâ”€â”€ OpenClaw data â†’ Legal documents
  â”œâ”€â”€ Vector DB snapshots â†’ Embeddings (can rebuild from source)
  â””â”€â”€ Flowise flows â†’ Low-code AI chains

Priority 4 (LOW â€” Can Rebuild):
  â”œâ”€â”€ Open WebUI â†’ Chat history (nice to have)
  â”œâ”€â”€ Uptime Kuma â†’ Monitoring config (quick to redo)
  â””â”€â”€ Ollama models â†’ Re-pull from registry
16.3 Offsite Backup Configuration (Script 3 Interactive)
configure_offsite_backup() {
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  OFFSITE BACKUP CONFIGURATION"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "  1) Local only (default â€” backups stay on data disk)"
    echo "  2) rsync to remote server via SSH"
    echo "  3) rclone to cloud storage (S3, GCS, B2, etc.)"
    echo "  4) USB/external drive"
    echo ""
    read -rp "  Select backup destination [1]: " backup_dest
    backup_dest="${backup_dest:-1}"

    case " $ backup_dest" in
        2)
            read -rp "  Remote SSH destination (user@host:/path): " rsync_dest
            echo "BACKUP_OFFSITE_METHOD=rsync" >> " $ {CREDENTIALS_DIR}/backup_config.env"
            echo "BACKUP_RSYNC_DEST=${rsync_dest}" >> "${CREDENTIALS_DIR}/backup_config.env"
            ;;
        3)
            log_info "Install rclone: curl https://rclone.org/install.sh | bash"
            log_info "Configure remote: rclone config"
            read -rp "  rclone remote name: " rclone_remote
            read -rp "  rclone remote path: " rclone_path
            echo "BACKUP_OFFSITE_METHOD=rclone" >> "${CREDENTIALS_DIR}/backup_config.env"
            echo "BACKUP_RCLONE_DEST=${rclone_remote}:${rclone_path}" >> "${CREDENTIALS_DIR}/backup_config.env"
            ;;
        4)
            read -rp "  Mount point of external drive: " ext_mount
            echo "BACKUP_OFFSITE_METHOD=local" >> "${CREDENTIALS_DIR}/backup_config.env"
            echo "BACKUP_OFFSITE_PATH=${ext_mount}/ai-platform-backups" >> "${CREDENTIALS_DIR}/backup_config.env"
            ;;
        *)
            echo "BACKUP_OFFSITE_METHOD=none" >> "${CREDENTIALS_DIR}/backup_config.env"
            log_warn "No offsite backup configured. Data is only on this server!"
            ;;
    esac
}
16.4 Backup Verification (Weekly Cron)
#!/usr/bin/env bash
# /opt/ai-platform/scripts/backup-verify.sh
# Verifies the most recent backup can be decrypted and contains expected files

set -euo pipefail

BACKUP_DIR="/mnt/data/ai-platform/backups"
VERIFY_DIR="/tmp/backup-verify-$$"

source /opt/ai-platform/scripts/common.sh

# Find most recent backup
latest_backup= $ (ls -1t " $ {BACKUP_DIR}"/ai-platform-backup-*.tar.gz.enc 2>/dev/null | head -1)
if [ -z " $ latest_backup" ]; then
    log_error "BACKUP VERIFY FAILED: No backups found!"
    echo " $ (date -u +%Y-%m-%dT%H:%M:%SZ) CRITICAL: No backups found" >> \
        /mnt/data/ai-platform/logs/health/alerts.log
    exit 1
fi

# Check age
backup_age_days= $ (( ( $ (date +%s) -  $ (stat -c %Y " $ latest_backup")) / 86400 ))
if [ "$backup_age_days" -gt 2 ]; then
    log_warn "Latest backup is ${backup_age_days} days old (expected < 2)"
    echo "$(date -u +%Y-%m-%dT%H:%M:%SZ) WARNING: Backup is ${backup_age_days} days old" >> \
        /mnt/data/ai-platform/logs/health/alerts.log
fi

# Verify checksum
if [ -f "${latest_backup}.sha256" ]; then
    if ! sha256sum -c "${latest_backup}.sha256" > /dev/null 2>&1; then
        log_error "BACKUP VERIFY FAILED: Checksum mismatch for  $ (basename " $ latest_backup")"
        exit 1
    fi
fi

# Decrypt and verify contents
ENCRYPTION_KEY= $ (grep '^BACKUP_ENCRYPTION_PASSPHRASE=' \
    /mnt/data/ai-platform/credentials/generated_secrets.env | cut -d'=' -f2-)

mkdir -p " $ VERIFY_DIR"
trap "rm -rf  $ VERIFY_DIR" EXIT

openssl enc -aes-256-cbc -d -salt -pbkdf2 -iter 100000 \
    -in " $ latest_backup" \
    -pass "pass:${ENCRYPTION_KEY}" \
    | tar -tzf - > "${VERIFY_DIR}/file-list.txt" 2>/dev/null

# Check for critical files
critical_files=(
    "MANIFEST.json"
    "postgresql-all.sql.gz"
    "data-credentials/"
)

for f in "${critical_files[@]}"; do
    if ! grep -q " $ f" " $ {VERIFY_DIR}/file-list.txt"; then
        log_error "BACKUP VERIFY FAILED: Missing critical file: ${f}"
        exit 1
    fi
done

file_count= $ (wc -l < " $ {VERIFY_DIR}/file-list.txt")
backup_size= $ (du -sh " $ latest_backup" | awk '{print $1}')

log_info "BACKUP VERIFY PASSED:  $ (basename " $ latest_backup") | ${backup_size} | ${file_count} files | ${backup_age_days} days old"
---

## 17. Docker Compose Architecture

### 17.1 Design Principles

1. **Single compose file** â€” one `docker-compose.yml` manages all services.
2. **Override files for optional services** â€” `docker-compose.override.yml` generated by Script 2.
3. **Named volumes mapped to data disk** â€” all persistent data under `/mnt/data/ai-platform/`.
4. **Explicit networks** â€” services grouped by function, minimal cross-talk.
5. **Health checks on every service** â€” Docker-native, feeds into Uptime Kuma.
6. **Resource limits** â€” prevent any single container from starving the system.
7. **Restart policy: unless-stopped** â€” auto-recover from crashes, respect manual stops.
8. **Environment variables from .env files** â€” no secrets in compose file.

### 17.2 Network Architecture
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docker Networks                                                     â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ai-frontend (bridge)                                          â”‚  â”‚
â”‚  â”‚  Purpose: User-facing services â†” Caddy reverse proxy           â”‚  â”‚
â”‚  â”‚                                                                 â”‚  â”‚
â”‚  â”‚  Members:                                                       â”‚  â”‚
â”‚  â”‚    caddy, open-webui, dify-web, dify-api, anythingllm,        â”‚  â”‚
â”‚  â”‚    n8n, flowise, openclaw, uptime-kuma, dozzle                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ai-backend (bridge)                                           â”‚  â”‚
â”‚  â”‚  Purpose: Application â†” Infrastructure communication           â”‚  â”‚
â”‚  â”‚                                                                 â”‚  â”‚
â”‚  â”‚  Members:                                                       â”‚  â”‚
â”‚  â”‚    litellm, ollama, postgresql, redis, qdrant,                â”‚  â”‚
â”‚  â”‚    weaviate, chroma, dify-api, dify-worker, dify-sandbox,     â”‚  â”‚
â”‚  â”‚    n8n, flowise, openclaw, open-webui, anythingllm            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ai-monitoring (bridge)                                        â”‚  â”‚
â”‚  â”‚  Purpose: Monitoring services â†” targets                        â”‚  â”‚
â”‚  â”‚                                                                 â”‚  â”‚
â”‚  â”‚  Members:                                                       â”‚  â”‚
â”‚  â”‚    uptime-kuma, dozzle, cadvisor                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â”‚  Note: Services on multiple networks can reach each other.          â”‚
â”‚  Services ONLY on ai-frontend CANNOT reach ai-backend directly.    â”‚
â”‚  Caddy is on ai-frontend only â€” reaches backends via service name. â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 17.3 Service Dependency Map
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Caddy   â”‚  (reverse proxy â€” entry point)
                â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
                      â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚               â”‚               â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Open WebUI â”‚  â”‚   Dify Web  â”‚  â”‚   n8n   â”‚  â”‚  AnythingLLMâ”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚               â”‚               â”‚
      â”‚         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚               â”‚
      â”‚         â”‚  Dify API  â”‚        â”‚               â”‚
      â”‚         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚               â”‚
      â”‚               â”‚               â”‚               â”‚
      â”‚         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”        â”‚               â”‚
      â”‚         â”‚ Dify Workerâ”‚        â”‚               â”‚
      â”‚         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚               â”‚
      â”‚               â”‚               â”‚               â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚  LiteLLM   â”‚  â”‚ PostgreSQLâ”‚  â”‚   Redis    â”‚
        â”‚ (gateway)  â”‚  â”‚ (shared)  â”‚  â”‚ (shared)   â”‚
        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚        â”‚        â”‚
   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
   â”‚ Ollama  â”‚ â”‚ Cloudâ”‚ â”‚ Cloud   â”‚
   â”‚ (local) â”‚ â”‚ APIs â”‚ â”‚ APIs    â”‚
   â”‚         â”‚ â”‚(GPT) â”‚ â”‚(Claude) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   Vector DB Layer (selected during Script 2):
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Qdrant â”‚  â”‚ Weaviate â”‚  â”‚ Chroma â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â–²            â–²            â–²
       â”‚            â”‚            â”‚
   Connected to: dify-api, dify-worker, n8n,
   openclaw, anythingllm, flowise, open-webui

### 17.4 Docker Compose â€” Core Services

```yaml
# /opt/ai-platform/docker-compose.yml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI PLATFORM â€” Core Services
# Generated by Script 2 â€” Do not edit directly
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

version: "3.9"

x-common-env: &common-env
  TZ: ${TIMEZONE:-UTC}

x-restart-policy: &restart-policy
  restart: unless-stopped

x-logging: &default-logging
  logging:
    driver: "json-file"
    options:
      max-size: "10m"
      max-file: "3"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NETWORKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
networks:
  ai-frontend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/24
  ai-backend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.1.0/24
  ai-monitoring:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.2.0/24

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SERVICES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
services:

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # INFRASTRUCTURE LAYER
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  postgresql:
    image: postgres:16-alpine
    container_name: postgresql
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${PG_SUPERUSER_PASS}
      POSTGRES_MULTIPLE_DATABASES: litellm,dify,n8n,openclaw
    volumes:
      - /mnt/data/ai-platform/postgresql/data:/var/lib/postgresql/data
      - /mnt/data/ai-platform/postgresql/init:/docker-entrypoint-initdb.d:ro
    networks:
      - ai-backend
    ports: []  # No external ports â€” backend network only
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"
        reservations:
          memory: 512M
          cpus: "0.5"

  redis:
    image: redis:7-alpine
    container_name: redis
    <<: [*restart-policy, *default-logging]
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly no
      --save ""
    volumes:
      - /mnt/data/ai-platform/redis/data:/data
    networks:
      - ai-backend
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 768M
          cpus: "1.0"
        reservations:
          memory: 128M

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # LLM LAYER
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_NUM_PARALLEL: ${OLLAMA_NUM_PARALLEL:-2}
      OLLAMA_MAX_LOADED_MODELS: ${OLLAMA_MAX_LOADED_MODELS:-2}
      OLLAMA_FLASH_ATTENTION: "1"
      OLLAMA_KV_CACHE_TYPE: "q8_0"
    volumes:
      - /mnt/data/ai-platform/ollama/models:/root/.ollama
    networks:
      - ai-backend
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:11434/api/tags || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: ${OLLAMA_MEMORY_LIMIT:-48G}
          cpus: "${OLLAMA_CPU_LIMIT:-8.0}"
        reservations:
          memory: 4G
          cpus: "2.0"
      # GPU passthrough handled by Docker runtime config
      # For NVIDIA: runtime: nvidia + NVIDIA_VISIBLE_DEVICES=all
      # Configured by Script 2 based on detected hardware

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      DATABASE_URL: postgresql://litellm:${PG_LITELLM_PASS}@postgresql:5432/litellm
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      LITELLM_SALT_KEY: ${LITELLM_SALT_KEY}
      UI_USERNAME: admin
      UI_PASSWORD: ${LITELLM_UI_PASSWORD}
      STORE_MODEL_IN_DB: "True"
      LITELLM_LOG: "INFO"
    volumes:
      - /mnt/data/ai-platform/litellm/config.yaml:/app/config.yaml:ro
      - /mnt/data/ai-platform/litellm/data:/app/data
    networks:
      - ai-backend
      - ai-frontend
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:4000/health/liveliness || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "2.0"
        reservations:
          memory: 256M

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # VECTOR DATABASE LAYER (Qdrant â€” default)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      QDRANT__SERVICE__API_KEY: ${QDRANT_API_KEY}
      QDRANT__SERVICE__ENABLE_TLS: "false"
      QDRANT__STORAGE__STORAGE_PATH: /qdrant/storage
      QDRANT__STORAGE__SNAPSHOTS_PATH: /qdrant/snapshots
      QDRANT__STORAGE__ON_DISK_PAYLOAD: "true"
      QDRANT__STORAGE__OPTIMIZERS__MEMMAP_THRESHOLD_KB: 20480
      QDRANT__CLUSTER__ENABLED: "false"
    volumes:
      - /mnt/data/ai-platform/qdrant/storage:/qdrant/storage
      - /mnt/data/ai-platform/qdrant/snapshots:/qdrant/snapshots
    networks:
      - ai-backend
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:6333/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
        reservations:
          memory: 512M

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # APPLICATION LAYER
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      OPENAI_API_BASE_URL: http://litellm:4000/v1
      OPENAI_API_KEY: ${LITELLM_MASTER_KEY}
      WEBUI_SECRET_KEY: ${OPENWEBUI_SECRET}
      ENABLE_SIGNUP: "false"
      DEFAULT_USER_ROLE: "user"
      ENABLE_COMMUNITY_SHARING: "false"
      ENABLE_OLLAMA_API: "false"
      # Point all LLM traffic through LiteLLM, not direct to Ollama
      OLLAMA_BASE_URL: ""
      # RAG settings
      RAG_EMBEDDING_ENGINE: "openai"
      RAG_EMBEDDING_MODEL: "text-embedding-3-small"
      RAG_OPENAI_API_BASE_URL: "http://litellm:4000/v1"
      RAG_OPENAI_API_KEY: ${LITELLM_MASTER_KEY}
      # Vector DB
      VECTOR_DB: "qdrant"
      QDRANT_URI: "http://qdrant:6333"
      QDRANT_API_KEY: ${QDRANT_API_KEY}
    volumes:
      - /mnt/data/ai-platform/open-webui/data:/app/backend/data
    networks:
      - ai-frontend
      - ai-backend
    depends_on:
      litellm:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8080/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"
        reservations:
          memory: 256M

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # DIFY (multi-container)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  dify-api:
    image: langgenius/dify-api:latest
    container_name: dify-api
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      MODE: api
      SECRET_KEY: ${DIFY_SECRET_KEY}
      CONSOLE_WEB_URL: http://${TAILSCALE_IP}:3000
      CONSOLE_API_URL: http://${TAILSCALE_IP}:5001
      SERVICE_API_URL: http://${TAILSCALE_IP}:5001
      APP_WEB_URL: http://${TAILSCALE_IP}:3000
      # Database
      DB_USERNAME: dify
      DB_PASSWORD: ${PG_DIFY_PASS}
      DB_HOST: postgresql
      DB_PORT: 5432
      DB_DATABASE: dify
      # Redis
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_DB: 1
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      # Storage
      STORAGE_TYPE: local
      STORAGE_LOCAL_PATH: /app/api/storage
      # Vector store
      VECTOR_STORE: qdrant
      QDRANT_URL: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY}
      QDRANT_CLIENT_TIMEOUT: 20
      # LLM â€” all through LiteLLM
      OPENAI_API_BASE: http://litellm:4000/v1
      OPENAI_API_KEY: ${LITELLM_MASTER_KEY}
    volumes:
      - /mnt/data/ai-platform/dify/storage:/app/api/storage
    networks:
      - ai-frontend
      - ai-backend
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy
      litellm:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:5001/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"

  dify-worker:
    image: langgenius/dify-api:latest
    container_name: dify-worker
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      MODE: worker
      SECRET_KEY: ${DIFY_SECRET_KEY}
      DB_USERNAME: dify
      DB_PASSWORD: ${PG_DIFY_PASS}
      DB_HOST: postgresql
      DB_PORT: 5432
      DB_DATABASE: dify
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      REDIS_DB: 1
      CELERY_BROKER_URL: redis://:${REDIS_PASSWORD}@redis:6379/2
      STORAGE_TYPE: local
      STORAGE_LOCAL_PATH: /app/api/storage
      VECTOR_STORE: qdrant
      QDRANT_URL: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY}
    volumes:
      - /mnt/data/ai-platform/dify/storage:/app/api/storage
    networks:
      - ai-backend
    depends_on:
      postgresql:
        condition: service_healthy
      redis:
        condition: service_healthy

  dify-web:
    image: langgenius/dify-web:latest
    container_name: dify-web
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      CONSOLE_API_URL: http://${TAILSCALE_IP}:5001
      APP_API_URL: http://${TAILSCALE_IP}:5001
    networks:
      - ai-frontend
    depends_on:
      - dify-api
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3000/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  dify-sandbox:
    image: langgenius/dify-sandbox:latest
    container_name: dify-sandbox
    <<: [*restart-policy, *default-logging]
    environment:
      API_KEY: ${DIFY_SANDBOX_KEY}
      GIN_MODE: release
      WORKER_TIMEOUT: 15
    networks:
      - ai-backend
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "1.0"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # N8N
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  n8n:
    image: docker.n8n.io/n8nio/n8n:latest
    container_name: n8n
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      N8N_HOST: 0.0.0.0
      N8N_PORT: 5678
      N8N_PROTOCOL: http
      WEBHOOK_URL: http://${TAILSCALE_IP}:5678/
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY}
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgresql
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: n8n
      DB_POSTGRESDB_PASSWORD: ${PG_N8N_PASS}
      EXECUTIONS_DATA_PRUNE: "true"
      EXECUTIONS_DATA_MAX_AGE: 168
      GENERIC_TIMEZONE: ${TIMEZONE:-UTC}
    volumes:
      - /mnt/data/ai-platform/n8n/data:/home/node/.n8n
    networks:
      - ai-frontend
      - ai-backend
    depends_on:
      postgresql:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:5678/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FLOWISE
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  flowise:
    image: flowiseai/flowise:latest
    container_name: flowise
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      PORT: 3001
      FLOWISE_USERNAME: admin
      FLOWISE_PASSWORD: ${FLOWISE_PASSWORD}
      FLOWISE_SECRETKEY_OVERWRITE: ${FLOWISE_SECRET_KEY}
      DATABASE_TYPE: postgres
      DATABASE_HOST: postgresql
      DATABASE_PORT: 5432
      DATABASE_NAME: flowise
      DATABASE_USER: flowise
      DATABASE_PASSWORD: ${PG_FLOWISE_PASS}
      APIKEY_PATH: /root/.flowise
      SECRETKEY_PATH: /root/.flowise
      LOG_PATH: /root/.flowise/logs
    volumes:
      - /mnt/data/ai-platform/flowise/data:/root/.flowise
    networks:
      - ai-frontend
      - ai-backend
    depends_on:
      postgresql:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3001/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ANYTHINGLLM
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      STORAGE_DIR: /app/server/storage
      LLM_PROVIDER: generic-openai
      GENERIC_OPEN_AI_BASE_PATH: http://litellm:4000/v1
      GENERIC_OPEN_AI_API_KEY: ${LITELLM_MASTER_KEY}
      EMBEDDING_ENGINE: generic-openai
      GENERIC_OPEN_AI_EMBEDDING_URL: http://litellm:4000/v1
      VECTOR_DB: qdrant
      QDRANT_ENDPOINT: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY}
      AUTH_TOKEN: ${ANYTHINGLLM_AUTH_TOKEN}
      JWT_SECRET: ${ANYTHINGLLM_JWT_SECRET}
      DISABLE_TELEMETRY: "true"
    volumes:
      - /mnt/data/ai-platform/anythingllm/storage:/app/server/storage
    networks:
      - ai-frontend
      - ai-backend
    depends_on:
      litellm:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3001/api/ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # OPENCLAW
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  openclaw:
    image: openclaw/openclaw:latest
    container_name: openclaw
    <<: [*restart-policy, *default-logging]
    environment:
      <<: *common-env
      DATABASE_URL: postgresql://openclaw:${PG_OPENCLAW_PASS}@postgresql:5432/openclaw
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379/3
      LLM_API_BASE: http://litellm:4000/v1
      LLM_API_KEY: ${LITELLM_MASTER_KEY}
      VECTOR_DB_TYPE: qdrant
      QDRANT_URL: http://qdrant:6333
      QDRANT_API_KEY: ${QDRANT_API_KEY}
      SECRET_KEY: ${OPENCLAW_SECRET_KEY}
      GOOGLE_DRIVE_ENABLED: ${OPENCLAW_GDRIVE_ENABLED:-false}
      GOOGLE_DRIVE_CREDENTIALS_PATH: /app/credentials/gdrive_service_account.json
      GOOGLE_DRIVE_FOLDER_ID: ${OPENCLAW_GDRIVE_FOLDER_ID:-}
    volumes:
      - /mnt/data/ai-platform/openclaw/data:/app/data
      - /mnt/data/ai-platform/credentials/openclaw/gdrive_service_account.json:/app/credentials/gdrive_service_account.json:ro
    networks:
      - ai-frontend
      - ai-backend
    depends_on:
      postgresql:
        condition: service_healthy
      litellm:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8000/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 45s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # REVERSE PROXY
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  caddy:
    image: caddy:2-alpine
    container_name: caddy
    <<: [*restart-policy, *default-logging]
    ports:
      - "${TAILSCALE_IP}:80:80"
      - "${TAILSCALE_IP}:443:443"
    volumes:
      - /mnt/data/ai-platform/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - /mnt/data/ai-platform/caddy/data:/data
      - /mnt/data/ai-platform/caddy/config:/config
    networks:
      - ai-frontend
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:80/ || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.5"

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # MONITORING
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  uptime-kuma:
    image: louislam/uptime-kuma:latest
    container_name: uptime-kuma
    <<: [*restart-policy, *default-logging]
    volumes:
      - /mnt/data/ai-platform/uptime-kuma/data:/app/data
    networks:
      - ai-frontend
      - ai-monitoring
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3001/ || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"

  dozzle:
    image: amir20/dozzle:latest
    container_name: dozzle
    <<: [*restart-policy, *default-logging]
    environment:
      DOZZLE_NO_ANALYTICS: "true"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - ai-frontend
      - ai-monitoring
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: "0.25"

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    <<: [*restart-policy, *default-logging]
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - ai-monitoring
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.5"
17.5 Docker Compose â€” Optional Override (Weaviate)
# /opt/ai-platform/docker-compose.weaviate.yml
# Included only if user selects Weaviate during Script 2

services:
  weaviate:
    image: semitechnologies/weaviate:latest
    container_name: weaviate
    restart: unless-stopped
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_APIKEY_ENABLED: "true"
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: ${WEAVIATE_API_KEY}
      AUTHENTICATION_APIKEY_USERS: admin
      PERSISTENCE_DATA_PATH: /var/lib/weaviate
      DEFAULT_VECTORIZER_MODULE: none
      CLUSTER_HOSTNAME: node1
      BACKUP_FILESYSTEM_PATH: /var/lib/weaviate/backups
      ENABLE_MODULES: "backup-filesystem"
      LOG_LEVEL: info
    volumes:
      - /mnt/data/ai-platform/weaviate/data:/var/lib/weaviate
      - /mnt/data/ai-platform/weaviate/backups:/var/lib/weaviate/backups
    networks:
      - ai-backend
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8080/v1/.well-known/ready || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2.0"
17.6 Docker Compose â€” Optional Override (Chroma)
# /opt/ai-platform/docker-compose.chroma.yml
# Included only if user selects Chroma during Script 2

services:
  chroma:
    image: chromadb/chroma:latest
    container_name: chroma
    restart: unless-stopped
    environment:
      IS_PERSISTENT: "TRUE"
      PERSIST_DIRECTORY: /chroma/chroma
      ANONYMIZED_TELEMETRY: "FALSE"
      CHROMA_SERVER_AUTHN_PROVIDER: "chromadb.auth.token_authn.TokenAuthenticationServerProvider"
      CHROMA_SERVER_AUTHN_CREDENTIALS: ${CHROMA_AUTH_TOKEN}
    volumes:
      - /mnt/data/ai-platform/chroma/data:/chroma/chroma
    networks:
      - ai-backend
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8000/api/v1/heartbeat || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.0"
17.7 Compose Startup Command (Script 2 generates)
generate_startup_command() {
    local compose_cmd="docker compose -f docker-compose.yml"

    # Add optional vector DB overrides
    if [ "${INSTALL_WEAVIATE}" = "true" ]; then
        compose_cmd+=" -f docker-compose.weaviate.yml"
    fi
    if [ "${INSTALL_CHROMA}" = "true" ]; then
        compose_cmd+=" -f docker-compose.chroma.yml"
    fi

    # Write convenience script
    cat > /opt/ai-platform/start.sh << EOF
#!/usr/bin/env bash
cd /opt/ai-platform
${compose_cmd} up -d
EOF
    chmod +x /opt/ai-platform/start.sh

    cat > /opt/ai-platform/stop.sh << EOF
#!/usr/bin/env bash
cd /opt/ai-platform
${compose_cmd} down
EOF
    chmod +x /opt/ai-platform/stop.sh

    cat > /opt/ai-platform/status.sh << EOF
#!/usr/bin/env bash
cd /opt/ai-platform
${compose_cmd} ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"
EOF
    chmod +x /opt/ai-platform/status.sh
}
17.8 Port Allocation Summary
Copy table


Port
Service
Network Binding
Access



80
Caddy (HTTP)
${TAILSCALE_IP}:80
Tailscale only


443
Caddy (HTTPS)
${TAILSCALE_IP}:443
Tailscale only


3000
Dify Web
Internal only (via Caddy)
Via reverse proxy


3001
Flowise
Internal only (via Caddy)
Via reverse proxy


3200
Uptime Kuma
Internal only (via Caddy)
Via reverse proxy


4000
LiteLLM
Internal only (via Caddy)
Via reverse proxy


5001
Dify API
Internal only (via Caddy)
Via reverse proxy


5678
n8n
Internal only (via Caddy)
Via reverse proxy


6333
Qdrant HTTP
Internal only
Backend network


6334
Qdrant gRPC
Internal only
Backend network


8080
Open WebUI
Internal only (via Caddy)
Via reverse proxy


8000
OpenClaw
Internal only (via Caddy)
Via reverse proxy


9998
cAdvisor
Internal only (via Caddy)
Via reverse proxy


9999
Dozzle
Internal only (via Caddy)
Via reverse proxy


11434
Ollama
Internal only
Backend network


5432
PostgreSQL
Internal only
Backend network


6379
Redis
Internal only
Backend network



Key security point: Only Caddy exposes ports, and only on the Tailscale interface. 
No service is reachable from the public internet or the LAN.
---

## 18. Caddy Reverse Proxy Configuration

### 18.1 Design Principles

1. **Single entry point** â€” all user traffic flows through Caddy.
2. **Tailscale IP binding only** â€” Caddy listens exclusively on the Tailscale interface.
3. **Automatic HTTPS disabled** â€” internal network, no public DNS; use HTTP over Tailscale's encrypted WireGuard tunnel.
4. **Path-based routing** â€” all services available via `http://<tailscale-ip>/<service>/`.
5. **Subdomain routing optional** â€” if MagicDNS is configured, services accessible as `service.tailnet-name.ts.net`.
6. **WebSocket support** â€” required by Open WebUI, n8n, Dozzle, Flowise.
7. **Request size limits** â€” large file uploads for Dify/OpenClaw document processing.
8. **Security headers** â€” even on internal network, defense in depth.

### 18.2 Caddyfile (Generated by Script 2)

```caddyfile
# /mnt/data/ai-platform/caddy/Caddyfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI Platform â€” Reverse Proxy Configuration
# Generated by Script 2 â€” Edit with care
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{
    # Disable automatic HTTPS â€” we're behind Tailscale's WireGuard tunnel
    auto_https off

    # Admin API â€” disabled for security
    admin off

    # Logging
    log {
        output file /data/access.log {
            roll_size 50mb
            roll_keep 5
            roll_keep_for 720h
        }
        format json
    }

    # Global timeouts
    servers {
        timeouts {
            read_body   120s
            read_header 10s
            write       300s
            idle        120s
        }
    }
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Common security headers snippet
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(security_headers) {
    header {
        X-Content-Type-Options    "nosniff"
        X-Frame-Options           "SAMEORIGIN"
        X-XSS-Protection          "1; mode=block"
        Referrer-Policy            "strict-origin-when-cross-origin"
        -Server
    }
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Common proxy settings snippet
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(proxy_defaults) {
    header_up X-Real-IP {remote_host}
    header_up X-Forwarded-For {remote_host}
    header_up X-Forwarded-Proto {scheme}
    header_up Host {upstream_hostport}
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# WebSocket support snippet
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
(websocket_support) {
    header_up Connection {>Connection}
    header_up Upgrade {>Upgrade}
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN SITE â€” http://<tailscale-ip>
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
:80 {
    import security_headers

    # â”€â”€ Landing Page / Dashboard â”€â”€
    handle / {
        respond `
<!DOCTYPE html>
<html>
<head><title>AI Platform</title>
<style>
    body { font-family: -apple-system, sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; background: #0f172a; color: #e2e8f0; }
    h1 { color: #38bdf8; border-bottom: 2px solid #1e3a5f; padding-bottom: 15px; }
    .services { display: grid; grid-template-columns: repeat(auto-fill, minmax(280px, 1fr)); gap: 15px; }
    .service { background: #1e293b; border: 1px solid #334155; border-radius: 8px; padding: 20px; transition: border-color 0.2s; }
    .service:hover { border-color: #38bdf8; }
    a { color: #38bdf8; text-decoration: none; font-size: 1.2em; font-weight: 600; }
    a:hover { text-decoration: underline; }
    .desc { color: #94a3b8; margin-top: 8px; font-size: 0.9em; }
    .cat { color: #64748b; font-size: 0.75em; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 5px; }
</style></head>
<body>
<h1>ğŸ§  AI Platform</h1>
<div class="services">
    <div class="service"><div class="cat">Chat Interface</div><a href="/chat/">Open WebUI</a><div class="desc">Chat with AI models â€” GPT, Claude, local LLMs</div></div>
    <div class="service"><div class="cat">AI Development</div><a href="/dify/">Dify</a><div class="desc">Build AI workflows, RAG apps, agents</div></div>
    <div class="service"><div class="cat">Automation</div><a href="/n8n/">n8n</a><div class="desc">Workflow automation with AI nodes</div></div>
    <div class="service"><div class="cat">AI Development</div><a href="/flowise/">Flowise</a><div class="desc">Visual LLM chain builder</div></div>
    <div class="service"><div class="cat">Knowledge Base</div><a href="/anythingllm/">AnythingLLM</a><div class="desc">Document chat and workspace management</div></div>
    <div class="service"><div class="cat">Legal AI</div><a href="/openclaw/">OpenClaw</a><div class="desc">Legal document analysis and drafting</div></div>
    <div class="service"><div class="cat">LLM Gateway</div><a href="/litellm/">LiteLLM</a><div class="desc">Model routing, budgets, API keys</div></div>
    <div class="service"><div class="cat">Monitoring</div><a href="/status/">Uptime Kuma</a><div class="desc">Service health and uptime monitoring</div></div>
    <div class="service"><div class="cat">Monitoring</div><a href="/logs/">Dozzle</a><div class="desc">Real-time container log viewer</div></div>
    <div class="service"><div class="cat">Monitoring</div><a href="/metrics/">cAdvisor</a><div class="desc">Container resource metrics</div></div>
</div>
</body></html>` 200
    }

    # â”€â”€ Open WebUI â”€â”€
    handle_path /chat/* {
        reverse_proxy open-webui:8080 {
            import proxy_defaults
            import websocket_support
            transport http {
                read_buffer  16384
            }
        }
    }

    # Open WebUI also needs root-level WebSocket for streaming
    @openwebui_ws {
        header Connection *Upgrade*
        header Upgrade    websocket
        path /ws/*
    }
    handle @openwebui_ws {
        reverse_proxy open-webui:8080 {
            import proxy_defaults
            import websocket_support
        }
    }

    # â”€â”€ Dify â”€â”€
    handle_path /dify/* {
        reverse_proxy dify-web:3000 {
            import proxy_defaults
            import websocket_support
        }
    }

    handle_path /dify-api/* {
        reverse_proxy dify-api:5001 {
            import proxy_defaults
            import websocket_support
            transport http {
                read_buffer 16384
            }
        }
    }

    # Dify console API routes
    handle /console/api/* {
        reverse_proxy dify-api:5001 {
            import proxy_defaults
        }
    }

    # Dify v1 API routes (for external integrations)
    handle /v1/* {
        reverse_proxy dify-api:5001 {
            import proxy_defaults
        }
    }

    # Dify file uploads â€” large body size
    handle /files/* {
        request_body {
            max_size 100MB
        }
        reverse_proxy dify-api:5001 {
            import proxy_defaults
        }
    }

    # â”€â”€ n8n â”€â”€
    handle_path /n8n/* {
        reverse_proxy n8n:5678 {
            import proxy_defaults
            import websocket_support
        }
    }

    # n8n webhooks (must be root-level paths for external calls)
    handle /webhook/* {
        reverse_proxy n8n:5678 {
            import proxy_defaults
        }
    }
    handle /webhook-test/* {
        reverse_proxy n8n:5678 {
            import proxy_defaults
        }
    }

    # â”€â”€ Flowise â”€â”€
    handle_path /flowise/* {
        reverse_proxy flowise:3001 {
            import proxy_defaults
            import websocket_support
        }
    }

    # â”€â”€ AnythingLLM â”€â”€
    handle_path /anythingllm/* {
        reverse_proxy anythingllm:3001 {
            import proxy_defaults
            import websocket_support
        }
    }

    # â”€â”€ OpenClaw â”€â”€
    handle_path /openclaw/* {
        request_body {
            max_size 50MB
        }
        reverse_proxy openclaw:8000 {
            import proxy_defaults
            import websocket_support
        }
    }

    # â”€â”€ LiteLLM Admin UI â”€â”€
    handle_path /litellm/* {
        reverse_proxy litellm:4000 {
            import proxy_defaults
        }
    }

    # LiteLLM OpenAI-compatible API (for external tools)
    handle /litellm-api/v1/* {
        uri strip_prefix /litellm-api
        reverse_proxy litellm:4000 {
            import proxy_defaults
        }
    }

    # â”€â”€ Uptime Kuma â”€â”€
    handle_path /status/* {
        reverse_proxy uptime-kuma:3001 {
            import proxy_defaults
            import websocket_support
        }
    }

    # â”€â”€ Dozzle â”€â”€
    handle_path /logs/* {
        reverse_proxy dozzle:8080 {
            import proxy_defaults
            import websocket_support
        }
    }

    # â”€â”€ cAdvisor â”€â”€
    handle_path /metrics/* {
        reverse_proxy cadvisor:8080 {
            import proxy_defaults
        }
    }

    # â”€â”€ Fallback â”€â”€
    handle {
        respond "404 â€” Service not found. Visit / for the dashboard." 404
    }
}
18.3 Caddyfile Considerations & Notes
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# IMPORTANT NOTES FOR CADDY CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# 1. PATH-BASED vs SUBDOMAIN ROUTING
#    Some applications (Open WebUI, Dify) may have issues with
#    path-prefix routing because they generate absolute URLs.
#    If issues arise, Script 2 can reconfigure to use subdomain
#    routing with Tailscale MagicDNS:
#
#    chat.machine-name.tailnet.ts.net â†’ Open WebUI
#    dify.machine-name.tailnet.ts.net  â†’ Dify
#    n8n.machine-name.tailnet.ts.net   â†’ n8n
#
# 2. SUBPATH SUPPORT MATRIX
#    âœ… n8n â€” native SUBPATH support via N8N_PATH env var
#    âœ… Flowise â€” supports FLOWISE_BASE_PATH env var
#    âœ… LiteLLM â€” stateless API, works with any prefix
#    âœ… Uptime Kuma â€” supports BASE_PATH
#    âœ… Dozzle â€” supports --base option
#    âš ï¸  Open WebUI â€” limited subpath support, may need root mount
#    âš ï¸  Dify â€” expects root path, may need subdomain
#    âš ï¸  AnythingLLM â€” may need root path
#
# 3. FALLBACK STRATEGY (implemented in Script 2)
#    If path-based routing fails for a service:
#    a. Try configuring the app's native SUBPATH/BASE_URL setting
#    b. If that fails, expose on a unique port via Caddy
#    c. As last resort, expose directly on Tailscale IP:<port>
#
# 4. DIRECT PORT ACCESS (always available as fallback)
#    Even with Caddy, Script 2 can expose individual services
#    directly on Tailscale IP for debugging:
#      ${TAILSCALE_IP}:8080 â†’ Open WebUI
#      ${TAILSCALE_IP}:3000 â†’ Dify Web
#      etc.

19. Tailscale Integration Details
19.1 Why Tailscale
Copy table


Requirement
Tailscale Solution



Secure remote access without VPN config
Zero-config WireGuard mesh


No public IP / dynamic DNS needed
Stable Tailscale IP (100.x.y.z)


No port forwarding on router
Outbound connection only


Access from phone/laptop/anywhere
Tailscale client on any device


MagicDNS for friendly URLs
ai-server.tailnet.ts.net


Share access with specific people
Tailscale ACLs + device sharing


Funnel (optional public access)
Expose specific services publicly


19.2 Installation & Configuration (Script 1)
install_tailscale() {
    log_info "Installing Tailscale..."

    # Install via official script
    curl -fsSL https://tailscale.com/install.sh | sh

    # Enable and start
    systemctl enable --now tailscaled

    log_info "Tailscale installed. Version:  $ (tailscale version | head -1)"
}

configure_tailscale() {
    local authkey_file="/mnt/data/ai-platform/credentials/tailscale_authkey.txt"

    # Check if already authenticated
    if tailscale status > /dev/null 2>&1; then
        TAILSCALE_IP= $ (tailscale ip -4)
        log_info "Tailscale already connected. IP: ${TAILSCALE_IP}"
        return 0
    fi

    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "  TAILSCALE AUTHENTICATION"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    echo "Two options:"
    echo "  1. Auth Key (headless â€” recommended for servers)"
    echo "     Get one at: https://login.tailscale.com/admin/settings/keys"
    echo "     Create a reusable, pre-approved key."
    echo ""
    echo "  2. Interactive browser login"
    echo "     Tailscale will print a URL to open in your browser."
    echo ""

    read -rp "Do you have an auth key? [y/N]: " has_key

    if [[ "${has_key,,}" == "y" ]]; then
        read -rsp "Paste your Tailscale auth key: " ts_authkey
        echo ""

        # Validate format (tskey-auth-...)
        if [[ ! " $ ts_authkey" =~ ^tskey-auth- ]]; then
            log_warn "Key doesn't look like a Tailscale auth key (expected tskey-auth-...)"
            read -rp "Continue anyway? [y/N]: " continue_anyway
            if [[ " $ {continue_anyway,,}" != "y" ]]; then
                log_error "Tailscale setup aborted."
                return 1
            fi
        fi

        # Save for potential re-use
        echo " $ ts_authkey" > " $ authkey_file"
        chmod 600 " $ authkey_file"

        # Connect
        tailscale up --authkey=" $ ts_authkey" --hostname="ai-platform" --accept-routes
    else
        # Interactive login
        log_info "Starting interactive Tailscale login..."
        echo "A URL will appear below. Open it in your browser to authenticate."
        echo ""
        tailscale up --hostname="ai-platform" --accept-routes
    fi

    # Verify connection
    if ! tailscale status > /dev/null 2>&1; then
        log_error "Tailscale connection failed. Check 'tailscale status' for details."
        return 1
    fi

    TAILSCALE_IP=$(tailscale ip -4)
    log_info "Tailscale connected successfully!"
    log_info "  Tailscale IP: ${TAILSCALE_IP}"
    log_info "  MagicDNS:      $ (tailscale status --self --json | jq -r '.Self.DNSName' 2>/dev/null || echo 'N/A')"

    # Save Tailscale IP to credentials
    echo "TAILSCALE_IP= $ {TAILSCALE_IP}" >> /mnt/data/ai-platform/credentials/.env

    return 0
}
19.3 Firewall Integration with Tailscale
configure_firewall_with_tailscale() {
    local ts_interface="tailscale0"
    local ts_ip="${TAILSCALE_IP}"

    log_info "Configuring UFW firewall with Tailscale..."

    # Reset to clean state
    ufw --force reset

    # Default policies
    ufw default deny incoming
    ufw default allow outgoing

    # Allow SSH on all interfaces (emergency access)
    ufw allow 22/tcp comment "SSH"

    # Allow ALL traffic on Tailscale interface
    ufw allow in on "$ts_interface" comment "Tailscale â€” all traffic"

    # Allow Docker internal networks (so containers can communicate)
    ufw allow from 172.28.0.0/16 comment "Docker networks"

    # Block everything else on physical interfaces
    # (ufw default deny incoming already handles this)

    # Enable
    ufw --force enable

    log_info "Firewall configured:"
    log_info "  âœ… SSH (port 22) â€” open on all interfaces"
    log_info "  âœ… Tailscale interface â€” all traffic allowed"
    log_info "  âœ… Docker internal â€” container-to-container allowed"
    log_info "  âŒ All other inbound traffic â€” DENIED"

    # Verify
    ufw status verbose
}
19.4 Tailscale MagicDNS URLs (Post-Setup)
After setup, services accessible at (examples):

  http://ai-platform.tailnet-name.ts.net/           â†’ Dashboard
  http://ai-platform.tailnet-name.ts.net/chat/       â†’ Open WebUI
  http://ai-platform.tailnet-name.ts.net/dify/       â†’ Dify
  http://ai-platform.tailnet-name.ts.net/n8n/        â†’ n8n
  http://ai-platform.tailnet-name.ts.net/litellm/    â†’ LiteLLM

Or via Tailscale IP directly:

  http://100.x.y.z/           â†’ Dashboard
  http://100.x.y.z/chat/      â†’ Open WebUI
  etc.

20. PostgreSQL Initialization
20.1 Multi-Database Init Script
PostgreSQL needs to create multiple databases and users on first boot.
This init script is mounted into the docker-entrypoint-initdb.d directory.
#!/usr/bin/env bash
# /mnt/data/ai-platform/postgresql/init/01-init-databases.sh
# Runs ONLY on first PostgreSQL start (when data directory is empty)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

set -euo pipefail

# Function to create database and user
create_db_and_user() {
    local db_name=" $ 1"
    local db_user=" $ 2"
    local db_pass=" $ 3"

    echo "Creating database ' $ {db_name}' with user '${db_user}'..."

    psql -v ON_ERROR_STOP=1 --username " $ POSTGRES_USER" <<-EOSQL
        -- Create user if not exists
        DO \ $ \$
        BEGIN
            IF NOT EXISTS (SELECT FROM pg_catalog.pg_roles WHERE rolname = '${db_user}') THEN
                CREATE ROLE ${db_user} WITH LOGIN PASSWORD '${db_pass}';
            END IF;
        END
        \ $ \ $ ;

        -- Create database if not exists
        SELECT 'CREATE DATABASE ${db_name} OWNER ${db_user}'
        WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = '${db_name}')\gexec

        -- Grant permissions
        GRANT ALL PRIVILEGES ON DATABASE ${db_name} TO ${db_user};

        -- Connect to the database and set up schema permissions
        \c ${db_name}
        GRANT ALL ON SCHEMA public TO ${db_user};
        ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO ${db_user};
        ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO ${db_user};
EOSQL

    echo "âœ… Database '${db_name}' ready."
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Enable extensions commonly needed
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
psql -v ON_ERROR_STOP=1 --username " $ POSTGRES_USER" <<-EOSQL
    -- Extensions that may be needed by services
    CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
    CREATE EXTENSION IF NOT EXISTS "pg_trgm";
    CREATE EXTENSION IF NOT EXISTS "vector";  -- pgvector if available
EOSQL

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Create all databases
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Environment variables are passed from docker-compose
create_db_and_user "litellm"  "litellm"  " $ {PG_LITELLM_PASS}"
create_db_and_user "dify"     "dify"     "${PG_DIFY_PASS}"
create_db_and_user "n8n"      "n8n"      "${PG_N8N_PASS}"
create_db_and_user "openclaw" "openclaw" "${PG_OPENCLAW_PASS}"
create_db_and_user "flowise"  "flowise"  "${PG_FLOWISE_PASS}"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# pgvector setup for Dify (if using PG as vector store)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname "dify" <<-EOSQL
    CREATE EXTENSION IF NOT EXISTS "vector";
EOSQL

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  All databases initialized successfully!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
20.2 PostgreSQL Image Selection
# Standard postgres:16-alpine does NOT include pgvector.
# If pgvector is needed (Dify can use PG as vector store):

# Option A: Use pgvector image (recommended if Dify uses PG vectors)
postgresql:
  image: pgvector/pgvector:pg16

# Option B: Use standard image (if using Qdrant/Weaviate/Chroma for vectors)
postgresql:
  image: postgres:16-alpine

# Script 2 selects the appropriate image based on user choices.
# Default: postgres:16-alpine (lighter, sufficient when external vector DB used)
20.3 PostgreSQL Tuning (Script 1)
generate_pg_config() {
    local total_ram_gb=" $ 1"

    # Calculate PostgreSQL-appropriate settings
    # PG typically gets 25% of system RAM
    local shared_buffers_mb= $ (( total_ram_gb * 1024 / 4 ))
    local effective_cache_mb= $ (( total_ram_gb * 1024 * 3 / 4 ))
    local work_mem_mb= $ (( total_ram_gb * 2 ))  # Conservative
    local maintenance_work_mem_mb= $ (( total_ram_gb * 64 ))

    # Cap shared_buffers at 8GB (diminishing returns beyond)
    if [ " $ shared_buffers_mb" -gt 8192 ]; then
        shared_buffers_mb=8192
    fi

    cat > /mnt/data/ai-platform/postgresql/init/02-performance.sql << EOF
-- PostgreSQL Performance Tuning
-- Auto-generated for ${total_ram_gb}GB system RAM

ALTER SYSTEM SET shared_buffers = '${shared_buffers_mb}MB';
ALTER SYSTEM SET effective_cache_size = '${effective_cache_mb}MB';
ALTER SYSTEM SET work_mem = '${work_mem_mb}MB';
ALTER SYSTEM SET maintenance_work_mem = '${maintenance_work_mem_mb}MB';
ALTER SYSTEM SET random_page_cost = 1.1;          -- SSD assumed
ALTER SYSTEM SET effective_io_concurrency = 200;   -- SSD
ALTER SYSTEM SET wal_buffers = '64MB';
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET checkpoint_completion_target = 0.9;
ALTER SYSTEM SET default_statistics_target = 100;
ALTER SYSTEM SET max_worker_processes = 8;
ALTER SYSTEM SET max_parallel_workers_per_gather = 4;
ALTER SYSTEM SET max_parallel_workers = 8;
ALTER SYSTEM SET log_min_duration_statement = 1000; -- Log queries > 1s
EOF
}
---

## 21. LiteLLM Configuration & Model Routing

### 21.1 Role of LiteLLM

LiteLLM is the **central nervous system** of the platform's AI capabilities. Every service
that needs an LLM â€” Dify, n8n, Flowise, Open WebUI, AnythingLLM, OpenClaw â€” connects
through LiteLLM rather than directly to providers.
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WHY LITELLM?                                     â”‚
â”‚                                                                         â”‚
â”‚  Without LiteLLM:                    With LiteLLM:                      â”‚
â”‚                                                                         â”‚
â”‚  Dify â”€â”€â”€â”€â”€ OpenAI Key â”€â”€â”           Dify â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  n8n â”€â”€â”€â”€â”€â”€ OpenAI Key â”€â”€â”¤           n8n â”€â”€â”€â”€â”€â”€â”€â”¤                       â”‚
â”‚  Flowise â”€â”€ OpenAI Key â”€â”€â”¤           Flowise â”€â”€â”€â”¤                       â”‚
â”‚  WebUI â”€â”€â”€â”€ OpenAI Key â”€â”€â”¤           WebUI â”€â”€â”€â”€â”€â”¼â”€â”€â†’ LiteLLM â”€â”€â†’ APIs  â”‚
â”‚  ALLM â”€â”€â”€â”€â”€ OpenAI Key â”€â”€â”¤           ALLM â”€â”€â”€â”€â”€â”€â”¤      â”‚               â”‚
â”‚  OpenClaw â”€ OpenAI Key â”€â”€â”˜           OpenClaw â”€â”€â”˜      â”œâ”€â”€â†’ OpenAI     â”‚
â”‚                                                         â”œâ”€â”€â†’ Anthropic  â”‚
â”‚  âŒ Keys scattered everywhere         âœ… One gateway    â”œâ”€â”€â†’ Google     â”‚
â”‚  âŒ No spending visibility            âœ… Cost tracking  â”œâ”€â”€â†’ Ollama     â”‚
â”‚  âŒ No fallback/routing               âœ… Smart routing  â””â”€â”€â†’ Others     â”‚
â”‚  âŒ Can't switch models easily        âœ… Model aliases                  â”‚
â”‚  âŒ Rate limit = total failure        âœ… Auto fallback                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 21.2 LiteLLM Configuration File (Generated by Script 2)

```yaml
# /mnt/data/ai-platform/litellm/config.yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LiteLLM Proxy Configuration
# Generated by Script 2 â€” DO NOT EDIT MANUALLY
# Use the LiteLLM Admin UI or re-run Script 2 to modify
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

general_settings:
  # Master key for admin API access
  master_key: "${LITELLM_MASTER_KEY}"
  
  # Database for tracking spend, users, keys
  database_url: "postgresql://${PG_LITELLM_USER}:${PG_LITELLM_PASS}@postgresql:5432/litellm"
  
  # Allow creating virtual keys for each service
  allow_user_auth: true
  
  # Enable cost tracking
  store_model_in_db: true
  
  # Custom pricing DB updates
  custom_llm_provider: null

litellm_settings:
  # Enable streaming everywhere
  set_verbose: false
  
  # Fallback settings
  num_retries: 2
  request_timeout: 300
  
  # Caching (uses Redis)
  cache: true
  cache_params:
    type: "redis"
    host: "redis"
    port: 6379
    password: "${REDIS_PASSWORD}"
    namespace: "litellm_cache"
    ttl: 3600  # 1 hour cache TTL
  
  # Logging
  success_callback: ["langfuse"]  # Optional: if langfuse installed
  failure_callback: []
  
  # Budget & rate limiting
  max_budget: 100.0  # $100 default monthly budget (configurable)
  budget_duration: "30d"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODEL LIST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
model_list:

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # OPENAI MODELS (if API key provided)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  {{IF_OPENAI}}
  - model_name: "gpt-4o"
    litellm_params:
      model: "openai/gpt-4o"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 128000
      input_cost_per_token: 0.0000025
      output_cost_per_token: 0.00001

  - model_name: "gpt-4o-mini"
    litellm_params:
      model: "openai/gpt-4o-mini"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 128000
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006

  - model_name: "gpt-4.1"
    litellm_params:
      model: "openai/gpt-4.1"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 1047576

  - model_name: "gpt-4.1-mini"
    litellm_params:
      model: "openai/gpt-4.1-mini"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 1047576

  - model_name: "gpt-4.1-nano"
    litellm_params:
      model: "openai/gpt-4.1-nano"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 1047576

  - model_name: "o3"
    litellm_params:
      model: "openai/o3"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000

  - model_name: "o3-mini"
    litellm_params:
      model: "openai/o3-mini"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000

  - model_name: "o4-mini"
    litellm_params:
      model: "openai/o4-mini"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000

  # OpenAI Embeddings
  - model_name: "text-embedding-3-large"
    litellm_params:
      model: "openai/text-embedding-3-large"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "embedding"

  - model_name: "text-embedding-3-small"
    litellm_params:
      model: "openai/text-embedding-3-small"
      api_key: "${OPENAI_API_KEY}"
    model_info:
      mode: "embedding"
  {{/IF_OPENAI}}

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # ANTHROPIC MODELS (if API key provided)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  {{IF_ANTHROPIC}}
  - model_name: "claude-sonnet-4"
    litellm_params:
      model: "anthropic/claude-sonnet-4-20250514"
      api_key: "${ANTHROPIC_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015

  - model_name: "claude-3.5-sonnet"
    litellm_params:
      model: "anthropic/claude-3-5-sonnet-20241022"
      api_key: "${ANTHROPIC_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015

  - model_name: "claude-3.5-haiku"
    litellm_params:
      model: "anthropic/claude-3-5-haiku-20241022"
      api_key: "${ANTHROPIC_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000
      input_cost_per_token: 0.0000008
      output_cost_per_token: 0.000004

  - model_name: "claude-opus-4"
    litellm_params:
      model: "anthropic/claude-opus-4-20250514"
      api_key: "${ANTHROPIC_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 200000
      input_cost_per_token: 0.000015
      output_cost_per_token: 0.000075
  {{/IF_ANTHROPIC}}

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # GOOGLE MODELS (if API key provided)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  {{IF_GOOGLE}}
  - model_name: "gemini-2.5-pro"
    litellm_params:
      model: "gemini/gemini-2.5-pro-preview-06-05"
      api_key: "${GOOGLE_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 1048576

  - model_name: "gemini-2.5-flash"
    litellm_params:
      model: "gemini/gemini-2.5-flash-preview-05-20"
      api_key: "${GOOGLE_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 1048576

  - model_name: "gemini-2.0-flash"
    litellm_params:
      model: "gemini/gemini-2.0-flash"
      api_key: "${GOOGLE_API_KEY}"
    model_info:
      mode: "chat"
      max_tokens: 1048576
  {{/IF_GOOGLE}}

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # LOCAL OLLAMA MODELS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  {{IF_OLLAMA}}
  # Models are auto-detected from Ollama after pull
  # Script 2 populates this section based on selected models

  - model_name: "llama3.1:8b"
    litellm_params:
      model: "ollama/llama3.1:8b"
      api_base: "http://ollama:11434"
    model_info:
      mode: "chat"

  - model_name: "nomic-embed-text"
    litellm_params:
      model: "ollama/nomic-embed-text"
      api_base: "http://ollama:11434"
    model_info:
      mode: "embedding"
  {{/IF_OLLAMA}}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MODEL ALIASES (convenience names)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # Smart routing â€” "best" routes to most capable available model
  - model_name: "best"
    litellm_params:
      model: "anthropic/claude-sonnet-4-20250514"
      api_key: "${ANTHROPIC_API_KEY}"

  - model_name: "best"
    litellm_params:
      model: "openai/gpt-4o"
      api_key: "${OPENAI_API_KEY}"

  # Fast routing â€” "fast" routes to fastest available model
  - model_name: "fast"
    litellm_params:
      model: "openai/gpt-4o-mini"
      api_key: "${OPENAI_API_KEY}"

  - model_name: "fast"
    litellm_params:
      model: "anthropic/claude-3-5-haiku-20241022"
      api_key: "${ANTHROPIC_API_KEY}"

  # Local routing â€” "local" routes to Ollama
  - model_name: "local"
    litellm_params:
      model: "ollama/llama3.1:8b"
      api_base: "http://ollama:11434"

router_settings:
  # Load balancing between same-named models
  routing_strategy: "usage-based-routing-v2"
  
  # If primary model fails, try alternatives
  fallbacks:
    - {"best": ["gpt-4o", "claude-sonnet-4", "gemini-2.5-pro"]}
    - {"fast": ["gpt-4o-mini", "claude-3.5-haiku", "gemini-2.0-flash", "local"]}

  # Retry logic
  num_retries: 2
  timeout: 300
  retry_after: 5
  allowed_fails: 3
  cooldown_time: 60
21.3 Virtual Key Generation (Script 2)
generate_litellm_service_keys() {
    # Wait for LiteLLM to be healthy
    wait_for_service "litellm" "http://localhost:4000/health" 60

    local master_key="${LITELLM_MASTER_KEY}"
    local base_url="http://localhost:4000"

    # Create a virtual key for each service
    declare -A service_budgets=(
        ["dify"]="50.0"
        ["n8n"]="20.0"
        ["flowise"]="20.0"
        ["open-webui"]="30.0"
        ["anythingllm"]="20.0"
        ["openclaw"]="30.0"
    )

    for service in "${!service_budgets[@]}"; do
        local budget="${service_budgets[$service]}"

        log_info "Creating LiteLLM virtual key for: ${service} (budget: \$${budget}/month)"

        local response
        response= $ (curl -s -X POST " $ {base_url}/key/generate" \
            -H "Authorization: Bearer ${master_key}" \
            -H "Content-Type: application/json" \
            -d "{
                \"key_alias\": \"${service}\",
                \"max_budget\": ${budget},
                \"budget_duration\": \"30d\",
                \"metadata\": {
                    \"service\": \"${service}\",
                    \"created_by\": \"script2\",
                    \"created_at\": \" $ (date -u +%Y-%m-%dT%H:%M:%SZ)\"
                },
                \"models\": [],
                \"max_parallel_requests\": 10
            }")

        local key
        key= $ (echo " $ response" | jq -r '.key // empty')

        if [ -n " $ key" ]; then
            # Save to credentials file
            echo "LITELLM_KEY_${service^^}=${key}" >> \
                /mnt/data/ai-platform/credentials/litellm_service_keys.env

            log_info "  âœ… Key created for ${service}"
        else
            log_warn "  âš ï¸  Failed to create key for ${service}:  $ (echo " $ response" | jq -r '.detail // .error // "unknown error"')"
        fi
    done

    chmod 600 /mnt/data/ai-platform/credentials/litellm_service_keys.env
}
21.4 How Services Connect to LiteLLM
# Each service sees LiteLLM as if it were OpenAI:

# Dify â€” Settings > Model Provider > OpenAI-API-compatible
#   API Base: http://litellm:4000/v1
#   API Key:  <virtual key for dify>

# n8n â€” Credentials > OpenAI API
#   Base URL: http://litellm:4000/v1
#   API Key:  <virtual key for n8n>

# Flowise â€” same pattern
# Open WebUI â€” Settings > Connections > OpenAI
# AnythingLLM â€” Settings > LLM Provider > Generic OpenAI
# OpenClaw â€” environment variables

# All services think they're talking to OpenAI.
# LiteLLM transparently routes to the correct backend.

22. Script Detailed Logic â€” Template Processing
22.1 Template Engine (Used by Script 2)
Script 2 generates multiple config files from templates. Here's the template engine:
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Template Processing Engine
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

process_template() {
    local template_file=" $ 1"
    local output_file=" $ 2"
    local env_file=" $ 3"  # File containing KEY=VALUE pairs

    # Load environment
    if [ -f " $ env_file" ]; then
        set -a
        source " $ env_file"
        set +a
    fi

    local content
    content= $ (cat " $ template_file")

    # â”€â”€ Phase 1: Conditional blocks â”€â”€
    # Process {{IF_OPENAI}}...{{/IF_OPENAI}} blocks
    local providers=("OPENAI" "ANTHROPIC" "GOOGLE" "OLLAMA" "GROQ" "DEEPSEEK" "MISTRAL")

    for provider in " $ {providers[@]}"; do
        local key_var="${provider}_API_KEY"
        local has_key="${!key_var:-}"

        if [ -n " $ has_key" ]; then
            # Provider is configured â€” remove the markers, keep content
            content= $ (echo " $ content" | sed "/{{IF_ $ {provider}}}/d; /{{\/IF_${provider}}}/d")
        else
            # Provider not configured â€” remove entire block
            content= $ (echo " $ content" | sed "/{{IF_${provider}}}/,/{{\/IF_${provider}}}/d")
        fi
    done

    # Process feature flags
    local features=("WEAVIATE" "CHROMA" "FLOWISE" "OPENCLAW" "ANYTHINGLLM")
    for feature in "${features[@]}"; do
        local flag_var="INSTALL_${feature}"
        local flag_val="${!flag_var:-false}"

        if [ " $ flag_val" = "true" ]; then
            content= $ (echo " $ content" | sed "/{{IF_ $ {feature}}}/d; /{{\/IF_${feature}}}/d")
        else
            content= $ (echo " $ content" | sed "/{{IF_${feature}}}/,/{{\/IF_${feature}}}/d")
        fi
    done

    # â”€â”€ Phase 2: Variable substitution â”€â”€
    # Replace ${VARIABLE} with actual values from environment
    # Uses envsubst for safe substitution
    echo " $ content" | envsubst > " $ output_file"

    # â”€â”€ Phase 3: Verify no unresolved templates â”€â”€
    local unresolved
    unresolved= $ (grep -c '{{' " $ output_file" 2>/dev/null || true)
    if [ "$unresolved" -gt 0 ]; then
        log_warn "Template ${template_file} has ${unresolved} unresolved template markers"
    fi

    local empty_vars
    empty_vars= $ (grep -cE '\ $ \{[A-Z_]+\}' " $ output_file" 2>/dev/null || true)
    if [ " $ empty_vars" -gt 0 ]; then
        log_warn "Template ${template_file} has ${empty_vars} unresolved variables"
    fi

    log_info "Generated: ${output_file}"
}
22.2 Service Environment File Generation
generate_service_env_files() {
    local creds_dir="/mnt/data/ai-platform/credentials"
    local secrets_file="${creds_dir}/generated_secrets.env"
    local api_keys_file="${creds_dir}/api_keys.env"
    local litellm_keys_file="${creds_dir}/litellm_service_keys.env"

    source_if_exists() {
        [ -f " $ 1" ] && source " $ 1"
    }

    source_if_exists " $ secrets_file"
    source_if_exists " $ api_keys_file"
    source_if_exists " $ litellm_keys_file"

    # â”€â”€ Dify Environment â”€â”€
    cat > /mnt/data/ai-platform/dify/.env << DIFY_ENV
# Dify Configuration â€” Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Core
MODE=api
LOG_LEVEL=INFO
SECRET_KEY= $ {DIFY_SECRET_KEY}
CONSOLE_WEB_URL=http://${TAILSCALE_IP}/dify
CONSOLE_API_URL=http://${TAILSCALE_IP}/dify-api
SERVICE_API_URL=http://${TAILSCALE_IP}/dify-api
APP_WEB_URL=http://${TAILSCALE_IP}/dify

# Database
DB_USERNAME=dify
DB_PASSWORD=${PG_DIFY_PASS}
DB_HOST=postgresql
DB_PORT=5432
DB_DATABASE=dify

# Redis
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=${REDIS_PASSWORD}
REDIS_DB=0

# Celery (uses Redis)
CELERY_BROKER_URL=redis://:${REDIS_PASSWORD}@redis:6379/1

# Vector Store
VECTOR_STORE=${DIFY_VECTOR_STORE:-qdrant}
QDRANT_URL=http://qdrant:6333
QDRANT_API_KEY=${QDRANT_API_KEY}

# Storage
STORAGE_TYPE=local
STORAGE_LOCAL_PATH=/app/api/storage

# LLM via LiteLLM (OpenAI-compatible)
OPENAI_API_BASE=http://litellm:4000/v1
OPENAI_API_KEY=${LITELLM_KEY_DIFY:-${LITELLM_MASTER_KEY}}

# File upload limits
UPLOAD_FILE_SIZE_LIMIT=100  # MB
UPLOAD_IMAGE_FILE_SIZE_LIMIT=10  # MB

# Sandbox
CODE_EXECUTION_ENDPOINT=http://dify-sandbox:8194
CODE_EXECUTION_API_KEY=${DIFY_SANDBOX_KEY}
DIFY_ENV


    # â”€â”€ n8n Environment â”€â”€
    cat > /mnt/data/ai-platform/n8n/.env << N8N_ENV
# n8n Configuration â€” Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Core
N8N_HOST=0.0.0.0
N8N_PORT=5678
N8N_PROTOCOL=http
WEBHOOK_URL=http://${TAILSCALE_IP}/n8n/
N8N_PATH=/n8n/
N8N_EDITOR_BASE_URL=http://${TAILSCALE_IP}/n8n/

# Database
DB_TYPE=postgresdb
DB_POSTGRESDB_HOST=postgresql
DB_POSTGRESDB_PORT=5432
DB_POSTGRESDB_DATABASE=n8n
DB_POSTGRESDB_USER=n8n
DB_POSTGRESDB_PASSWORD=${PG_N8N_PASS}

# Security
N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_JWT_SECRET}

# Execution
EXECUTIONS_DATA_PRUNE=true
EXECUTIONS_DATA_MAX_AGE=168  # 7 days in hours
GENERIC_TIMEZONE=UTC

# Logging
N8N_LOG_LEVEL=info
N8N_LOG_OUTPUT=console

# Enable community nodes
N8N_COMMUNITY_PACKAGES_ALLOW_TOOL_USAGE=true
N8N_ENV

    # â”€â”€ Open WebUI Environment â”€â”€
    cat > /mnt/data/ai-platform/open-webui/.env << WEBUI_ENV
# Open WebUI Configuration â€” Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# OpenAI-compatible backend (LiteLLM)
OPENAI_API_BASE_URL=http://litellm:4000/v1
OPENAI_API_KEY=${LITELLM_KEY_OPEN_WEBUI:-${LITELLM_MASTER_KEY}}

# Ollama direct connection (for model management UI)
OLLAMA_BASE_URL=http://ollama:11434

# WebUI Settings
WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
WEBUI_AUTH=true
DEFAULT_USER_ROLE=user
ENABLE_SIGNUP=false

# RAG Settings
RAG_EMBEDDING_MODEL=text-embedding-3-small
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
WEBUI_ENV

    # â”€â”€ Flowise Environment â”€â”€
    if [ "${INSTALL_FLOWISE}" = "true" ]; then
        cat > /mnt/data/ai-platform/flowise/.env << FLOWISE_ENV
# Flowise Configuration â€” Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FLOWISE_USERNAME=admin
FLOWISE_PASSWORD=${FLOWISE_ADMIN_PASSWORD}
DATABASE_TYPE=postgres
DATABASE_HOST=postgresql
DATABASE_PORT=5432
DATABASE_NAME=flowise
DATABASE_USER=flowise
DATABASE_PASSWORD=${PG_FLOWISE_PASS}
APIKEY_PATH=/root/.flowise
SECRETKEY_PATH=/root/.flowise
LOG_LEVEL=info
FLOWISE_BASE_PATH=/flowise
FLOWISE_ENV
    fi

    # â”€â”€ AnythingLLM Environment â”€â”€
    if [ "${INSTALL_ANYTHINGLLM}" = "true" ]; then
        cat > /mnt/data/ai-platform/anythingllm/.env << ALLM_ENV
# AnythingLLM Configuration â€” Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SIG_KEY=${ANYTHINGLLM_SIG_KEY}
SIG_SALT=${ANYTHINGLLM_SIG_SALT}
JWT_SECRET=${ANYTHINGLLM_JWT_SECRET}
AUTH_TOKEN=${ANYTHINGLLM_AUTH_TOKEN}

# LLM via LiteLLM
LLM_PROVIDER=generic-openai
GENERIC_OPEN_AI_BASE_PATH=http://litellm:4000/v1
GENERIC_OPEN_AI_API_KEY=${LITELLM_KEY_ANYTHINGLLM:-${LITELLM_MASTER_KEY}}
GENERIC_OPEN_AI_MODEL_PREF=gpt-4o-mini
GENERIC_OPEN_AI_MAX_TOKENS=4096

# Embedding
EMBEDDING_ENGINE=openai
OPEN_AI_EMBED_KEY=${LITELLM_KEY_ANYTHINGLLM:-${LITELLM_MASTER_KEY}}
EMBEDDING_MODEL_PREF=text-embedding-3-small

# Vector DB
VECTOR_DB=qdrant
QDRANT_ENDPOINT=http://qdrant:6333
QDRANT_API_KEY=${QDRANT_API_KEY}

# Storage
STORAGE_DIR=/app/server/storage
ALLM_ENV
    fi

    # â”€â”€ OpenClaw Environment â”€â”€
    if [ "${INSTALL_OPENCLAW}" = "true" ]; then
        cat > /mnt/data/ai-platform/openclaw/.env << CLAW_ENV
# OpenClaw Configuration â€” Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SECRET_KEY=${OPENCLAW_SECRET_KEY}
DATABASE_URL=postgresql://openclaw:${PG_OPENCLAW_PASS}@postgresql:5432/openclaw
REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379/3

# LLM via LiteLLM
OPENAI_API_BASE=http://litellm:4000/v1
OPENAI_API_KEY=${LITELLM_KEY_OPENCLAW:-${LITELLM_MASTER_KEY}}
DEFAULT_MODEL=gpt-4o

# Features
ENABLE_OCR=true
MAX_UPLOAD_SIZE=52428800
CLAW_ENV
    fi

    log_info "All service environment files generated."
}

23. Ollama Model Management
23.1 Model Selection & Pull (Script 2)
configure_ollama_models() {
    local total_ram_gb=" $ 1"
    local has_gpu=" $ 2"
    local gpu_vram_gb="${3:-0}"

    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "  LOCAL MODEL SELECTION"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    echo "System: ${total_ram_gb}GB RAM | GPU: ${has_gpu} (${gpu_vram_gb}GB VRAM)"
    echo ""

    # Determine what models the system can run
    local max_model_size="small"
    if [ " $ has_gpu" = "true" ]; then
        if [ " $ gpu_vram_gb" -ge 24 ]; then
            max_model_size="xlarge"
        elif [ " $ gpu_vram_gb" -ge 16 ]; then
            max_model_size="large"
        elif [ " $ gpu_vram_gb" -ge 8 ]; then
            max_model_size="medium"
        fi
    elif [ " $ total_ram_gb" -ge 64 ]; then
        max_model_size="large"
    elif [ " $ total_ram_gb" -ge 32 ]; then
        max_model_size="medium"
    fi

    echo "Recommended model tier: ${max_model_size}"
    echo ""

    # Model catalog with size tiers
    declare -A models_catalog=(
        # [name]="display_name|size_tier|size_gb|description"
        ["llama3.1:8b"]="Llama 3.1 8B|small|4.7|General purpose, fast"
        ["llama3.1:70b"]="Llama 3.1 70B|large|40|Very capable, needs lots of RAM/VRAM"
        ["mistral:7b"]="Mistral 7B|small|4.1|Fast, good for code & reasoning"
        ["mixtral:8x7b"]="Mixtral 8x7B|large|26|MoE, very capable"
        ["codellama:13b"]="Code Llama 13B|medium|7.4|Specialized for code"
        ["phi3:14b"]="Phi-3 14B|medium|7.9|Microsoft's efficient model"
        ["gemma2:9b"]="Gemma 2 9B|small|5.4|Google's open model"
        ["qwen2.5:7b"]="Qwen 2.5 7B|small|4.4|Strong multilingual model"
        ["nomic-embed-text"]="Nomic Embed|small|0.3|Embedding model (recommended)"
        ["mxbai-embed-large"]="MxBai Embed Large|small|0.7|Alternative embedding model"
    )

    # Show available models based on tier
    echo "Available models for your system:"
    echo ""

    local tier_order=("small" "medium" "large" "xlarge")
    local idx=1
    declare -a available_models=()

    for tier in "${tier_order[@]}"; do
        [[ " $ tier" > " $ max_model_size" ]] && continue  # Skip tiers above capability

        for model in "${!models_catalog[@]}"; do
            IFS='|' read -r display_name model_tier size_gb description <<< "${models_catalog[ $ model]}"
            if [ " $ model_tier" = " $ tier" ]; then
                printf "  %2d. %-25s %5sGB  %s\n" " $ idx" " $ display_name" " $ size_gb" " $ description"
                available_models+=(" $ model")
                ((idx++))
            fi
        done
    done

    echo ""
    echo "Recommended minimal set: nomic-embed-text (embedding), llama3.1:8b (chat)"
    echo ""
    read -rp "Enter model numbers to install (comma-separated, or 'recommended'): " model_selection

    declare -a selected_models=()

    if [ " $ model_selection" = "recommended" ] || [ -z " $ model_selection" ]; then
        selected_models=("llama3.1:8b" "nomic-embed-text")
    else
        IFS=',' read -ra selections <<< " $ model_selection"
        for sel in " $ {selections[@]}"; do
            sel= $ (echo " $ sel" | tr -d ' ')
            local sel_idx= $ ((sel - 1))
            if [ " $ sel_idx" -ge 0 ] && [ " $ sel_idx" -lt " $ {#available_models[@]}" ]; then
                selected_models+=("${available_models[ $ sel_idx]}")
            fi
        done
    fi

    echo ""
    echo "Selected models:"
    for model in " $ {selected_models[@]}"; do
        echo "  â€¢ ${model}"
    done

    # Save selection for Script 2's compose generation
    printf '%s\n' "${selected_models[@]}" > \
        /mnt/data/ai-platform/credentials/ollama_models.txt

    return 0
}

pull_ollama_models() {
    local models_file="/mnt/data/ai-platform/credentials/ollama_models.txt"

    if [ ! -f " $ models_file" ]; then
        log_warn "No models file found. Skipping Ollama model pull."
        return 0
    fi

    # Wait for Ollama to be ready
    wait_for_service "ollama" "http://localhost:11434/api/tags" 120

    while IFS= read -r model; do
        [ -z " $ model" ] && continue
        log_info "Pulling Ollama model: ${model} (this may take a while)..."

        local start_time= $ (date +%s)

        if docker exec ollama ollama pull " $ model" 2>&1 | tail -5; then
            local elapsed=$(( $(date +%s) - start_time ))
            log_info "  âœ… ${model} pulled successfully (${elapsed}s)"
        else
            log_warn "  âš ï¸  Failed to pull ${model}. Can be pulled later with: docker exec ollama ollama pull ${model}"
        fi
    done < "$models_file"
}
---

## 24. Script 3 â€” Verification & Diagnostic Engine (Complete)

### 24.1 Architecture

Script 3 is a non-destructive, read-only diagnostic tool. It never modifies the system.
It runs 50+ checks organized in phases and produces a human-readable report with
machine-parseable exit codes.
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Script 3 Execution Flow                                              â”‚
â”‚                                                                       â”‚
â”‚  Phase 1: Pre-flight          Phase 4: Service Health                 â”‚
â”‚    â”œâ”€â”€ Running as root?         â”œâ”€â”€ Container status (all)            â”‚
â”‚    â”œâ”€â”€ Scripts 1 & 2 ran?       â”œâ”€â”€ HTTP health endpoints             â”‚
â”‚    â”œâ”€â”€ Required tools exist?    â”œâ”€â”€ WebSocket connectivity            â”‚
â”‚    â””â”€â”€ Data disk mounted?       â”œâ”€â”€ LiteLLM model listing             â”‚
â”‚                                 â”œâ”€â”€ Ollama model availability          â”‚
â”‚  Phase 2: Infrastructure        â””â”€â”€ Database connectivity             â”‚
â”‚    â”œâ”€â”€ Disk space & SMART                                             â”‚
â”‚    â”œâ”€â”€ Memory allocation        Phase 5: Integration                  â”‚
â”‚    â”œâ”€â”€ CPU availability           â”œâ”€â”€ LiteLLM â†” Provider connectivity â”‚
â”‚    â”œâ”€â”€ Network interfaces         â”œâ”€â”€ Service â†” LiteLLM routing       â”‚
â”‚    â”œâ”€â”€ Tailscale status           â”œâ”€â”€ Service â†” PostgreSQL            â”‚
â”‚    â”œâ”€â”€ Firewall rules             â”œâ”€â”€ Service â†” Redis                 â”‚
â”‚    â””â”€â”€ DNS resolution             â”œâ”€â”€ Service â†” Qdrant               â”‚
â”‚                                   â””â”€â”€ Caddy â†” All services            â”‚
â”‚  Phase 3: Docker                                                      â”‚
â”‚    â”œâ”€â”€ Daemon running           Phase 6: Security                     â”‚
â”‚    â”œâ”€â”€ Compose version            â”œâ”€â”€ Exposed ports audit             â”‚
â”‚    â”œâ”€â”€ Networks exist             â”œâ”€â”€ Secret file permissions         â”‚
â”‚    â”œâ”€â”€ Volumes exist              â”œâ”€â”€ Container privilege check       â”‚
â”‚    â”œâ”€â”€ Images pulled              â”œâ”€â”€ Tailscale ACL validation        â”‚
â”‚    â””â”€â”€ Resource usage             â””â”€â”€ API key validity (non-invasive) â”‚
â”‚                                                                       â”‚
â”‚  Phase 7: Report Generation                                           â”‚
â”‚    â”œâ”€â”€ Summary with pass/warn/fail counts                             â”‚
â”‚    â”œâ”€â”€ Service URL table                                              â”‚
â”‚    â”œâ”€â”€ Credential location reminder                                   â”‚
â”‚    â”œâ”€â”€ Recommended next steps                                         â”‚
â”‚    â””â”€â”€ Full log saved to /mnt/data/ai-platform/logs/                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 24.2 Core Check Framework

```bash
#!/usr/bin/env bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Script 3 of 3 â€” AI Platform Verification & Diagnostics
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
set -euo pipefail

# â”€â”€ Globals â”€â”€
SCRIPT_VERSION="3.0.0"
PLATFORM_DIR="/opt/ai-platform"
DATA_DIR="/mnt/data/ai-platform"
LOG_DIR="${DATA_DIR}/logs"
REPORT_FILE="${LOG_DIR}/verification- $ (date +%Y%m%d-%H%M%S).log"
CREDENTIALS_DIR=" $ {DATA_DIR}/credentials"

# Counters
PASS_COUNT=0
WARN_COUNT=0
FAIL_COUNT=0
SKIP_COUNT=0
TOTAL_COUNT=0

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m'

# â”€â”€ Check Result Functions â”€â”€

check_pass() {
    local name=" $ 1"
    local detail=" $ {2:-}"
    ((PASS_COUNT++))
    ((TOTAL_COUNT++))
    printf "  ${GREEN}âœ… PASS${NC}  %-45s %s\n" " $ name" " $ detail"
    echo "[PASS] $name |  $ detail" >> " $ REPORT_FILE"
}

check_warn() {
    local name=" $ 1"
    local detail=" $ {2:-}"
    ((WARN_COUNT++))
    ((TOTAL_COUNT++))
    printf "  ${YELLOW}âš ï¸  WARN${NC}  %-45s %s\n" " $ name" " $ detail"
    echo "[WARN] $name |  $ detail" >> " $ REPORT_FILE"
}

check_fail() {
    local name=" $ 1"
    local detail=" $ {2:-}"
    ((FAIL_COUNT++))
    ((TOTAL_COUNT++))
    printf "  ${RED}âŒ FAIL${NC}  %-45s %s\n" " $ name" " $ detail"
    echo "[FAIL] $name |  $ detail" >> " $ REPORT_FILE"
}

check_skip() {
    local name=" $ 1"
    local detail=" $ {2:-}"
    ((SKIP_COUNT++))
    ((TOTAL_COUNT++))
    printf "  ${BLUE}â­ï¸  SKIP${NC}  %-45s %s\n" " $ name" " $ detail"
    echo "[SKIP] $name |  $ detail" >> " $ REPORT_FILE"
}

section_header() {
    local title="$1"
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    printf "  ${BOLD}${CYAN}%s${NC}\n" " $ title"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "" >> " $ REPORT_FILE"
    echo "===  $ title ===" >> " $ REPORT_FILE"
}
24.3 Phase 2 â€” Infrastructure Checks (Detailed)
phase_2_infrastructure() {
    section_header "PHASE 2: INFRASTRUCTURE"

    # â”€â”€ Disk Space â”€â”€
    local data_disk_usage
    data_disk_usage= $ (df " $ {DATA_DIR}" --output=pcent | tail -1 | tr -d ' %')

    if [ " $ data_disk_usage" -lt 70 ]; then
        check_pass "Data disk usage" " $ {data_disk_usage}% used"
    elif [ " $ data_disk_usage" -lt 85 ]; then
        check_warn "Data disk usage" " $ {data_disk_usage}% used â€” consider cleanup"
    else
        check_fail "Data disk usage" "${data_disk_usage}% used â€” CRITICAL"
    fi

    # Free space in GB
    local free_gb
    free_gb= $ (df " $ {DATA_DIR}" --output=avail -BG | tail -1 | tr -d ' G')
    if [ " $ free_gb" -ge 50 ]; then
        check_pass "Data disk free space" " $ {free_gb}GB available"
    elif [ " $ free_gb" -ge 20 ]; then
        check_warn "Data disk free space" " $ {free_gb}GB available â€” getting low"
    else
        check_fail "Data disk free space" "${free_gb}GB available â€” CRITICAL"
    fi

    # â”€â”€ SMART Status (if available) â”€â”€
    if command -v smartctl &>/dev/null; then
        local data_device
        data_device= $ (df " $ {DATA_DIR}" --output=source | tail -1)
        # Get parent device (strip partition number)
        local parent_device
        parent_device= $ (lsblk -no pkname " $ data_device" 2>/dev/null | head -1)

        if [ -n " $ parent_device" ]; then
            local smart_status
            smart_status= $ (smartctl -H "/dev/${parent_device}" 2>/dev/null | grep -i "overall" || echo "unknown")

            if echo " $ smart_status" | grep -qi "passed\|ok"; then
                check_pass "Disk SMART health" " $ smart_status"
            elif echo " $ smart_status" | grep -qi "unknown"; then
                check_skip "Disk SMART health" "Unable to read SMART data"
            else
                check_fail "Disk SMART health" " $ smart_status"
            fi
        fi
    else
        check_skip "Disk SMART health" "smartctl not installed"
    fi

    # â”€â”€ Memory â”€â”€
    local total_mem_mb
    total_mem_mb=$(free -m | awk '/Mem:/{print  $ 2}')
    local avail_mem_mb
    avail_mem_mb= $ (free -m | awk '/Mem:/{print  $ 7}')
    local mem_usage_pct= $ (( (total_mem_mb - avail_mem_mb) * 100 / total_mem_mb ))

    if [ " $ mem_usage_pct" -lt 80 ]; then
        check_pass "Memory usage" " $ {mem_usage_pct}% used (${avail_mem_mb}MB available of ${total_mem_mb}MB)"
    elif [ " $ mem_usage_pct" -lt 90 ]; then
        check_warn "Memory usage" " $ {mem_usage_pct}% used â€” under pressure"
    else
        check_fail "Memory usage" "${mem_usage_pct}% used â€” CRITICAL"
    fi

    # Check swap
    local swap_total
    swap_total=$(free -m | awk '/Swap:/{print  $ 2}')
    if [ " $ swap_total" -gt 0 ]; then
        check_pass "Swap configured" "${swap_total}MB"
    else
        check_warn "Swap not configured" "Recommended for stability"
    fi

    # â”€â”€ Tailscale â”€â”€
    if command -v tailscale &>/dev/null; then
        local ts_status
        ts_status= $ (tailscale status --json 2>/dev/null || echo "{}")

        local ts_state
        ts_state= $ (echo " $ ts_status" | jq -r '.BackendState // "unknown"')

        if [ " $ ts_state" = "Running" ]; then
            local ts_ip
            ts_ip=$(tailscale ip -4 2>/dev/null || echo "unknown")
            check_pass "Tailscale status" "Running â€” IP: ${ts_ip}"

            # Check if Tailscale is the exit node
            local ts_hostname
            ts_hostname= $ (echo " $ ts_status" | jq -r '.Self.HostName // "unknown"')
            check_pass "Tailscale hostname" "${ts_hostname}"

            # Check MagicDNS
            local magic_dns
            magic_dns= $ (echo " $ ts_status" | jq -r '.Self.DNSName // "none"' | sed 's/\. $ //')
            if [ " $ magic_dns" != "none" ] && [ -n " $ magic_dns" ]; then
                check_pass "Tailscale MagicDNS" " $ {magic_dns}"
            else
                check_warn "Tailscale MagicDNS" "Not configured â€” using IP access only"
            fi
        else
            check_fail "Tailscale status" "State: ${ts_state}"
        fi
    else
        check_fail "Tailscale installed" "Not found"
    fi

    # â”€â”€ Firewall â”€â”€
    if command -v ufw &>/dev/null; then
        local ufw_status
        ufw_status= $ (ufw status 2>/dev/null | head -1)

        if echo " $ ufw_status" | grep -q "active"; then
            check_pass "UFW firewall" "Active"

            # Check that SSH is allowed
            if ufw status | grep -q "22/tcp.*ALLOW"; then
                check_pass "UFW SSH rule" "Port 22 allowed"
            else
                check_warn "UFW SSH rule" "SSH may be blocked!"
            fi

            # Check that no AI platform ports are publicly exposed
            local exposed_ports=0
            for port in 3000 3001 4000 5001 5678 6333 8080 8000 9998 9999 11434 5432 6379; do
                if ufw status | grep -q "${port}/tcp.*ALLOW.*Anywhere"; then
                    check_warn "UFW port ${port}" "Publicly exposed â€” should be Tailscale only"
                    ((exposed_ports++))
                fi
            done

            if [ "$exposed_ports" -eq 0 ]; then
                check_pass "UFW port exposure" "No AI platform ports publicly exposed"
            fi
        else
            check_warn "UFW firewall" "Inactive â€” relying on Tailscale for security"
        fi
    fi
}
24.4 Phase 4 â€” Service Health Checks
phase_4_service_health() {
    section_header "PHASE 4: SERVICE HEALTH"

    local compose_cmd
    if docker compose version &>/dev/null 2>&1; then
        compose_cmd="docker compose"
    else
        compose_cmd="docker-compose"
    fi

    # â”€â”€ Container Status â”€â”€
    local expected_services
    expected_services= $ (cd " $ {PLATFORM_DIR}" && ${compose_cmd} config --services 2>/dev/null)

    for service in  $ expected_services; do
        local container_state
        container_state= $ (docker inspect --format='{{.State.Status}}' \
            " $ (cd " $ {PLATFORM_DIR}" && ${compose_cmd} ps -q " $ service" 2>/dev/null)" 2>/dev/null || echo "not_found")

        local container_health
        container_health= $ (docker inspect --format='{{if .State.Health}}{{.State.Health.Status}}{{else}}no_healthcheck{{end}}' \
            " $ (cd " $ {PLATFORM_DIR}" && ${compose_cmd} ps -q " $ service" 2>/dev/null)" 2>/dev/null || echo "unknown")

        local restart_count
        restart_count= $ (docker inspect --format='{{.RestartCount}}' \
            " $ (cd " $ {PLATFORM_DIR}" && ${compose_cmd} ps -q " $ service" 2>/dev/null)" 2>/dev/null || echo "0")

        if [ " $ container_state" = "running" ]; then
            if [ " $ container_health" = "healthy" ] || [ " $ container_health" = "no_healthcheck" ]; then
                if [ "$restart_count" -gt 5 ]; then
                    check_warn "Container: ${service}" "Running (healthy) but ${restart_count} restarts â€” instability"
                else
                    check_pass "Container: ${service}" "Running | Health: ${container_health} | Restarts: ${restart_count}"
                fi
            elif [ "$container_health" = "starting" ]; then
                check_warn "Container: ${service}" "Running but health: starting (may need more time)"
            else
                check_warn "Container: ${service}" "Running but health: ${container_health}"
            fi
        elif [ "$container_state" = "not_found" ]; then
            check_fail "Container: ${service}" "Not found â€” may not have started"
        else
            check_fail "Container: ${service}" "State: ${container_state}"
        fi
    done

    # â”€â”€ HTTP Health Endpoints â”€â”€
    section_header "PHASE 4b: HTTP HEALTH ENDPOINTS"

    local ts_ip
    ts_ip= $ (tailscale ip -4 2>/dev/null || echo "127.0.0.1")

    declare -A health_endpoints=(
        ["Caddy"]="http:// $ {ts_ip}:80/"
        ["LiteLLM"]="http://${ts_ip}/litellm/health"
        ["Dify API"]="http://${ts_ip}/dify-api/health"
        ["Dify Web"]="http://${ts_ip}/dify/"
        ["Open WebUI"]="http://${ts_ip}/webui/"
        ["n8n"]="http://${ts_ip}/n8n/healthz"
        ["Qdrant"]="http://${ts_ip}/qdrant/healthz"
        ["Uptime Kuma"]="http://${ts_ip}/status/"
        ["Dozzle"]="http://${ts_ip}/dozzle/"
    )

    # Add optional services
    if docker ps --format '{{.Names}}' | grep -q flowise; then
        health_endpoints["Flowise"]="http://${ts_ip}/flowise/"
    fi
    if docker ps --format '{{.Names}}' | grep -q anythingllm; then
        health_endpoints["AnythingLLM"]="http://${ts_ip}/anythingllm/api/ping"
    fi
    if docker ps --format '{{.Names}}' | grep -q openclaw; then
        health_endpoints["OpenClaw"]="http://${ts_ip}/openclaw/"
    fi

    for service_name in "${!health_endpoints[@]}"; do
        local url="${health_endpoints[ $ service_name]}"
        local http_code
        http_code= $ (curl -s -o /dev/null -w '%{http_code}' \
            --connect-timeout 5 --max-time 10 " $ url" 2>/dev/null || echo "000")

        if [ " $ http_code" -ge 200 ] && [ "$http_code" -lt 400 ]; then
            check_pass "HTTP: ${service_name}" "Status ${http_code} â€” ${url}"
        elif [ "$http_code" = "000" ]; then
            check_fail "HTTP: ${service_name}" "Connection failed â€” ${url}"
        else
            check_warn "HTTP: ${service_name}" "Status ${http_code} â€” ${url}"
        fi
    done
}
24.5 Phase 5 â€” Integration Checks
phase_5_integration() {
    section_header "PHASE 5: INTEGRATION TESTS"

    local ts_ip
    ts_ip= $ (tailscale ip -4 2>/dev/null || echo "127.0.0.1")

    # â”€â”€ LiteLLM Model Listing â”€â”€
    local litellm_master_key
    litellm_master_key= $ (grep 'LITELLM_MASTER_KEY' "${CREDENTIALS_DIR}/generated_secrets.env" 2>/dev/null | cut -d'=' -f2)

    if [ -n " $ litellm_master_key" ]; then
        local models_response
        models_response= $ (curl -s --connect-timeout 5 --max-time 10 \
            -H "Authorization: Bearer ${litellm_master_key}" \
            "http://localhost:4000/v1/models" 2>/dev/null || echo "{}")

        local model_count
        model_count= $ (echo " $ models_response" | jq -r '.data | length // 0' 2>/dev/null || echo "0")

        if [ " $ model_count" -gt 0 ]; then
            check_pass "LiteLLM models available" " $ {model_count} models registered"

            # List first 5 models
            echo " $ models_response" | jq -r '.data[].id' 2>/dev/null | head -5 | while read -r model_id; do
                printf "         â”œâ”€â”€ %s\n" " $ model_id"
            done
            if [ "$model_count" -gt 5 ]; then
                printf "         â””â”€â”€ ... and %d more\n"  $ ((model_count - 5))
            fi
        else
            check_fail "LiteLLM models available" "No models registered"
        fi

        # â”€â”€ Test a simple completion â”€â”€
        local test_response
        test_response= $ (curl -s --connect-timeout 10 --max-time 30 \
            -X POST "http://localhost:4000/v1/chat/completions" \
            -H "Authorization: Bearer ${litellm_master_key}" \
            -H "Content-Type: application/json" \
            -d '{
                "model": "fast",
                "messages": [{"role": "user", "content": "Reply with only: OK"}],
                "max_tokens": 5
            }' 2>/dev/null || echo "{}")

        local test_content
        test_content= $ (echo " $ test_response" | jq -r '.choices[0].message.content // empty' 2>/dev/null)

        if [ -n "$test_content" ]; then
            check_pass "LiteLLM completion test" "Response: ${test_content:0:50}"
        else
            local error_msg
            error_msg= $ (echo " $ test_response" | jq -r '.error.message // .detail // "unknown error"' 2>/dev/null)
            check_warn "LiteLLM completion test" "Failed: ${error_msg:0:80}"
        fi
    else
        check_skip "LiteLLM integration" "Master key not found"
    fi

    # â”€â”€ Ollama Model Check â”€â”€
    local ollama_models
    ollama_models= $ (curl -s --connect-timeout 5 "http://localhost:11434/api/tags" 2>/dev/null || echo "{}")
    local ollama_count
    ollama_count= $ (echo " $ ollama_models" | jq -r '.models | length // 0' 2>/dev/null || echo "0")

    if [ " $ ollama_count" -gt 0 ]; then
        check_pass "Ollama models pulled" "${ollama_count} models available"
        echo " $ ollama_models" | jq -r '.models[].name' 2>/dev/null | while read -r m; do
            printf "         â”œâ”€â”€ %s\n" " $ m"
        done
    else
        check_warn "Ollama models" "No models pulled yet"
    fi

    # â”€â”€ PostgreSQL Connectivity â”€â”€
    local pg_pass
    pg_pass= $ (grep 'PG_SUPERUSER_PASS' " $ {CREDENTIALS_DIR}/generated_secrets.env" 2>/dev/null | cut -d'=' -f2)

    if [ -n " $ pg_pass" ]; then
        local pg_dbs
        pg_dbs= $ (docker exec postgresql psql -U postgres -t -A -c \
            "SELECT datname FROM pg_database WHERE datistemplate = false ORDER BY datname;" 2>/dev/null || echo "")

        if [ -n " $ pg_dbs" ]; then
            local db_count
            db_count= $ (echo " $ pg_dbs" | wc -l)
            check_pass "PostgreSQL databases" " $ {db_count} databases found"
            echo " $ pg_dbs" | while read -r db; do
                printf "         â”œâ”€â”€ %s\n" " $ db"
            done
        else
            check_fail "PostgreSQL connectivity" "Cannot list databases"
        fi
    fi

    # â”€â”€ Redis Connectivity â”€â”€
    local redis_pass
    redis_pass= $ (grep 'REDIS_PASSWORD' " $ {CREDENTIALS_DIR}/generated_secrets.env" 2>/dev/null | cut -d'=' -f2)

    local redis_ping
    redis_ping= $ (docker exec redis redis-cli -a " $ {redis_pass}" --no-auth-warning PING 2>/dev/null || echo "")

    if [ " $ redis_ping" = "PONG" ]; then
        local redis_keys
        redis_keys= $ (docker exec redis redis-cli -a "${redis_pass}" --no-auth-warning DBSIZE 2>/dev/null || echo "")
        check_pass "Redis connectivity" "PONG â€” ${redis_keys}"
    else
        check_fail "Redis connectivity" "No response to PING"
    fi

    # â”€â”€ Qdrant Connectivity â”€â”€
    local qdrant_health
    qdrant_health= $ (curl -s --connect-timeout 5 "http://localhost:6333/healthz" 2>/dev/null || echo "")

    if echo " $ qdrant_health" | grep -qi "ok\|healthy"; then
        local qdrant_collections
        qdrant_collections=$(curl -s "http://localhost:6333/collections" 2>/dev/null | jq -r '.result.collections | length // 0' 2>/dev/null || echo "0")
        check_pass "Qdrant connectivity" "Healthy â€” ${qdrant_collections} collections"
    else
        check_fail "Qdrant connectivity" "Health check failed"
    fi
}
24.6 Phase 6 â€” Security Audit
phase_6_security() {
    section_header "PHASE 6: SECURITY AUDIT"

    # â”€â”€ Port Exposure Check â”€â”€
    # Verify only Caddy ports are bound to Tailscale IP
    local ts_ip
    ts_ip= $ (tailscale ip -4 2>/dev/null || echo "")

    local listening_ports
    listening_ports= $ (ss -tlnp 2>/dev/null | grep -v "^State")

    # Check for services bound to 0.0.0.0 (all interfaces)
    local wildcard_bindings=0
    while IFS= read -r line; do
        local addr
        addr= $ (echo " $ line" | awk '{print  $ 4}')

        if echo " $ addr" | grep -q "0.0.0.0:" || echo " $ addr" | grep -q "\*:"; then
            local port
            port= $ (echo " $ addr" | rev | cut -d: -f1 | rev)
            local process
            process= $ (echo " $ line" | grep -oP 'users:\(\("\K[^"]+')

            # Skip SSH (intentionally on all interfaces usually)
            if [ " $ port" = "22" ]; then
                continue
            fi

            # Skip Docker's internal proxy
            if echo "$process" | grep -q "docker-proxy"; then
                # This is expected for container port mapping
                # But check if it should be Tailscale-bound
                check_warn "Port ${port} binding" "Bound to 0.0.0.0 via ${process} â€” verify intended"
                ((wildcard_bindings++))
            fi
        fi
    done <<< " $ listening_ports"

    if [ " $ wildcard_bindings" -eq 0 ]; then
        check_pass "Port binding security" "No unexpected wildcard bindings"
    fi

    # â”€â”€ Credential File Permissions â”€â”€
    local cred_files
    cred_files= $ (find " $ {CREDENTIALS_DIR}" -type f 2>/dev/null)

    local perm_issues=0
    while IFS= read -r cred_file; do
        [ -z " $ cred_file" ] && continue
        local perms
        perms= $ (stat -c '%a' " $ cred_file")

        if [ " $ perms" = "600" ] || [ " $ perms" = "400" ]; then
            # Good â€” owner only
            true
        else
            check_warn "File permissions" " $ {cred_file} is ${perms} â€” should be 600"
            ((perm_issues++))
        fi
    done <<< " $ cred_files"

    if [ " $ perm_issues" -eq 0 ]; then
        check_pass "Credential file permissions" "All files properly restricted"
    fi

    # â”€â”€ Container Privilege Check â”€â”€
    local privileged_containers=0
    docker ps -q 2>/dev/null | while read -r cid; do
        local name
        name= $ (docker inspect --format='{{.Name}}' " $ cid" | sed 's/\///')
        local privileged
        privileged= $ (docker inspect --format='{{.HostConfig.Privileged}}' " $ cid")

        if [ " $ privileged" = "true" ]; then
            check_warn "Container privilege" " $ {name} is running in privileged mode"
            ((privileged_containers++))
        fi
    done

    if [ " $ privileged_containers" -eq 0 ]; then
        check_pass "Container privileges" "No privileged containers"
    fi

    # â”€â”€ Docker Socket Exposure â”€â”€
    local socket_mounts=0
    docker ps -q 2>/dev/null | while read -r cid; do
        local name
        name= $ (docker inspect --format='{{.Name}}' " $ cid" | sed 's/\///')
        local mounts
        mounts= $ (docker inspect --format='{{range .Mounts}}{{.Source}}{{" "}}{{end}}' " $ cid")

        if echo " $ mounts" | grep -q "docker.sock"; then
            # dozzle and cadvisor legitimately need this
            if echo "$name" | grep -qE "dozzle|cadvisor"; then
                check_pass "Docker socket: ${name}" "Expected â€” read-only monitoring"
            else
                check_warn "Docker socket: ${name}" "Has Docker socket access â€” verify required"
            fi
        fi
    done
}
24.7 Final Report Generation
generate_final_report() {
    section_header "VERIFICATION COMPLETE"

    local ts_ip
    ts_ip=$(tailscale ip -4 2>/dev/null || echo "<tailscale-ip>")

    echo ""
    echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
    printf "â”‚  ${BOLD}Results: ${GREEN}%d PASS${NC} | ${YELLOW}%d WARN${NC} | ${RED}%d FAIL${NC} | ${BLUE}%d SKIP${NC}  â”‚\n" \
        " $ PASS_COUNT" " $ WARN_COUNT" " $ FAIL_COUNT" " $ SKIP_COUNT"
    echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"

    if [ " $ FAIL_COUNT" -eq 0 ] && [ " $ WARN_COUNT" -eq 0 ]; then
        echo "â”‚  ğŸ‰ PERFECT â€” All checks passed!                     â”‚"
    elif [ " $ FAIL_COUNT" -eq 0 ]; then
        echo "â”‚  âœ… GOOD â€” No failures, some warnings to review       â”‚"
    elif [ " $ FAIL_COUNT" -le 3 ]; then
        echo "â”‚  âš ï¸  ISSUES â€” Some failures need attention             â”‚"
    else
        echo "â”‚  âŒ PROBLEMS â€” Multiple failures detected              â”‚"
    fi
    echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"

    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "  SERVICE ACCESS URLs"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    printf "  %-20s %s\n" "Service" "URL"
    printf "  %-20s %s\n" "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€" "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
    printf "  %-20s http://%s/dify/\n" "Dify" " $ ts_ip"
    printf "  %-20s http://%s/webui/\n" "Open WebUI" " $ ts_ip"
    printf "  %-20s http://%s/n8n/\n" "n8n" " $ ts_ip"
    printf "  %-20s http://%s/litellm/ui/\n" "LiteLLM" " $ ts_ip"
    printf "  %-20s http://%s/flowise/\n" "Flowise" " $ ts_ip"
    printf "  %-20s http://%s/anythingllm/\n" "AnythingLLM" " $ ts_ip"
    printf "  %-20s http://%s/openclaw/\n" "OpenClaw" " $ ts_ip"
    printf "  %-20s http://%s/status/\n" "Uptime Kuma" " $ ts_ip"
    printf "  %-20s http://%s/dozzle/\n" "Dozzle" " $ ts_ip"
    printf "  %-20s http://%s/cadvisor/\n" "cAdvisor" " $ ts_ip"
    echo ""

    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "  CREDENTIALS"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    echo "  All credentials stored in: ${CREDENTIALS_DIR}/"
    echo ""
    echo "  Key files:"
    echo "    â€¢ generated_secrets.env  â€” Database passwords, encryption keys"
    echo "    â€¢ api_keys.env           â€” External API keys"
    echo "    â€¢ litellm_service_keys.env â€” Per-service LiteLLM virtual keys"
    echo "    â€¢ admin_credentials.txt  â€” Initial admin login for each service"
    echo ""
    echo "  âš ï¸  IMPORTANT: Back up ${CREDENTIALS_DIR}/ to a secure location!"
    echo ""

    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "  MANAGEMENT COMMANDS"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    echo "  Start platform:     /opt/ai-platform/start.sh"
    echo "  Stop platform:      /opt/ai-platform/stop.sh"
    echo "  Platform status:    /opt/ai-platform/status.sh"
    echo "  View logs:          /opt/ai-platform/logs.sh [service]"
    echo "  Run backup:         /opt/ai-platform/backup.sh"
    echo "  Re-verify:          bash /opt/ai-platform/script3-verify.sh"
    echo ""

    # Save report
    echo ""
    echo "  Full report saved to: ${REPORT_FILE}"

    # Exit code
    if [ "$FAIL_COUNT" -gt 0 ]; then
        exit 1
    else
        exit 0
    fi
}

25. Backup Architecture
25.1 Backup Script (Generated by Script 2)
#!/usr/bin/env bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI Platform Backup Script
# Generated by Script 2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
set -euo pipefail

BACKUP_DIR="/mnt/data/ai-platform/backups"
TIMESTAMP= $ (date +%Y%m%d-%H%M%S)
BACKUP_PATH=" $ {BACKUP_DIR}/${TIMESTAMP}"
COMPOSE_DIR="/opt/ai-platform"
DATA_DIR="/mnt/data/ai-platform"

mkdir -p "${BACKUP_PATH}"

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  AI Platform Backup â€” ${TIMESTAMP}"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# â”€â”€ 1. PostgreSQL dump (most critical) â”€â”€
echo "[1/5] Backing up PostgreSQL databases..."
for db in dify n8n litellm flowise openclaw; do
    if docker exec postgresql psql -U postgres -lqt | cut -d \| -f 1 | grep -qw " $ db"; then
        docker exec postgresql pg_dump -U postgres -Fc " $ db" > \
            "${BACKUP_PATH}/${db}.pg_dump"
        echo "  âœ… ${db}"
    fi
done

# â”€â”€ 2. Redis snapshot â”€â”€
echo "[2/5] Backing up Redis..."
docker exec redis redis-cli -a "${REDIS_PASSWORD}" --no-auth-warning BGSAVE
sleep 2
docker cp redis:/data/dump.rdb "${BACKUP_PATH}/redis-dump.rdb" 2>/dev/null || true
echo "  âœ… Redis snapshot"

# â”€â”€ 3. Qdrant snapshot â”€â”€
echo "[3/5] Backing up Qdrant..."
curl -s -X POST "http://localhost:6333/snapshots" > /dev/null 2>&1 || true
# Copy latest snapshot
local latest_snap
latest_snap=$(ls -t ${DATA_DIR}/qdrant/snapshots/*.snapshot 2>/dev/null | head -1)
if [ -n " $ latest_snap" ]; then
    cp " $ latest_snap" "${BACKUP_PATH}/"
    echo "  âœ… Qdrant snapshot"
else
    echo "  âš ï¸  No Qdrant snapshot available"
fi

# â”€â”€ 4. Configuration files â”€â”€
echo "[4/5] Backing up configurations..."
tar -czf "${BACKUP_PATH}/configs.tar.gz" \
    -C / \
    opt/ai-platform/docker-compose.yml \
    opt/ai-platform/.env \
    mnt/data/ai-platform/caddy/Caddyfile \
    mnt/data/ai-platform/litellm/config.yaml \
    mnt/data/ai-platform/credentials/ \
    2>/dev/null
echo "  âœ… Configurations archived"

# â”€â”€ 5. Service-specific data â”€â”€
echo "[5/5] Backing up service data..."
for svc in dify/storage n8n/data open-webui/data anythingllm/storage; do
    if [ -d "${DATA_DIR}/${svc}" ]; then
        local svc_name= $ (echo " $ svc" | tr '/' '-')
        tar -czf "${BACKUP_PATH}/${svc_name}.tar.gz" \
            -C "${DATA_DIR}" "${svc}" 2>/dev/null || true
    fi
done
echo "  âœ… Service data archived"

# â”€â”€ Calculate backup size â”€â”€
local backup_size
backup_size= $ (du -sh " $ {BACKUP_PATH}" | cut -f1)

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  Backup complete: ${BACKUP_PATH}"
echo "  Size: ${backup_size}"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# â”€â”€ Cleanup old backups (keep last 7) â”€â”€
echo ""
echo "Cleaning up old backups (keeping last 7)..."
ls -dt ${BACKUP_DIR}/*/ 2>/dev/null | tail -n +8 | while read -r old_backup; do
    echo "  Removing: ${old_backup}"
    rm -rf "$old_backup"
done

echo "Done."
25.2 Automated Backup via Cron (Set by Script 2)
setup_backup_cron() {
    local cron_entry="0 3 * * * /opt/ai-platform/backup.sh >> /mnt/data/ai-platform/logs/backup.log 2>&1"

    # Add to root's crontab if not already there
    (crontab -l 2>/dev/null | grep -v "ai-platform/backup.sh"; echo "$cron_entry") | crontab -

    log_info "Backup cron job configured: daily at 3:00 AM"
}

26. Logging Architecture
26.1 Log Locations
/mnt/data/ai-platform/logs/
â”œâ”€â”€ script1-infrastructure-YYYYMMDD-HHMMSS.log    # Script 1 execution log
â”œâ”€â”€ script2-deploy-YYYYMMDD-HHMMSS.log            # Script 2 execution log
â”œâ”€â”€ verification-YYYYMMDD-HHMMSS.log              # Script 3 reports
â”œâ”€â”€ backup.log                                      # Backup cron output
â”œâ”€â”€ caddy/                                          # Caddy access logs (JSON)
â”‚   â””â”€â”€ access.log
â””â”€â”€ platform-events.log                             # Aggregated platform events
26.2 Log Rotation (Configured by Script 1)
setup_log_rotation() {
    cat > /etc/logrotate.d/ai-platform << 'LOGROTATE'
/mnt/data/ai-platform/logs/*.log {
    daily
    rotate 14
    compress
    delaycompress
    missingok
    notifempty
    create 0640 root root
}

/mnt/data/ai-platform/logs/caddy/*.log {
    daily
    rotate 7
    compress
    delaycompress
    missingok
    notifempty
    postrotate
        docker kill --signal=USR1 caddy 2>/dev/null || true
    endscript
}
LOGROTATE

    log_info "Log rotation configured"
}
26.3 Dozzle â€” Live Log Viewer
Dozzle provides a web UI for viewing all container logs in real-time, accessible
at http://<tailscale-ip>/dozzle/. No configuration needed â€” it auto-discovers
containers via the Docker socket.
# In docker-compose.yml
dozzle:
  image: amir20/dozzle:latest
  container_name: dozzle
  restart: unless-stopped
  volumes:
    - /var/run/docker.sock:/var/run/docker.sock:ro
  environment:
    DOZZLE_BASE: /dozzle
    DOZZLE_NO_ANALYTICS: "true"
  networks:
    - ai-frontend
  # No port exposure â€” accessed via Caddy
---

## 27. Service Dependency Graph & Startup Orchestration

### 27.1 Complete Dependency Map
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SERVICE STARTUP DEPENDENCY GRAPH                              â”‚
â”‚                                                                                 â”‚
â”‚  Layer 0 â€” Infrastructure (start first, no dependencies)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚PostgreSQLâ”‚  â”‚  Redis   â”‚  â”‚  Qdrant  â”‚  â”‚  Ollama  â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚       â”‚              â”‚              â”‚              â”‚                             â”‚
â”‚  Layer 1 â€” AI Gateway (depends on Layer 0)                                      â”‚
â”‚       â”‚              â”‚              â”‚              â”‚                             â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                             â”‚
â”‚              â–¼              â”‚                       â”‚                             â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                       â”‚                             â”‚
â”‚        â”‚ LiteLLM  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜        â”‚                                                     â”‚
â”‚             â”‚              â”‚                                                     â”‚
â”‚  Layer 2 â€” Core Services (depend on Layer 0 + Layer 1)                          â”‚
â”‚             â”‚              â”‚                                                     â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚     â–¼       â–¼      â–¼       â–¼      â–¼          â–¼          â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Dify â”‚â”‚ Dify â”‚â”‚ n8n  â”‚â”‚Open â”‚â”‚Flowiseâ”‚â”‚Anythingâ”‚â”‚OpenClawâ”‚                   â”‚
â”‚  â”‚ API  â”‚â”‚Workerâ”‚â”‚      â”‚â”‚WebUIâ”‚â”‚       â”‚â”‚  LLM   â”‚â”‚        â”‚                   â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚     â”‚                                                                            â”‚
â”‚     â–¼                                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  (Dify-specific sub-services)                                          â”‚
â”‚  â”‚ Dify â”‚                                                                        â”‚
â”‚  â”‚ Web  â”‚                                                                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜                                                                        â”‚
â”‚                                                                                  â”‚
â”‚  Layer 3 â€” Monitoring & Access (depend on Layer 2 running)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â”‚  Uptime  â”‚  â”‚  Dozzle  â”‚  â”‚ cAdvisor â”‚                                       â”‚
â”‚  â”‚  Kuma    â”‚  â”‚          â”‚  â”‚          â”‚                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                                  â”‚
â”‚  Layer 4 â€” Reverse Proxy (starts last, routes to everything)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚                        Caddy                                  â”‚                â”‚
â”‚  â”‚  (waits for all upstream services to be healthy before        â”‚                â”‚
â”‚  â”‚   routing traffic to them)                                    â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

### 27.2 Docker Compose depends_on with Health Checks

```yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Startup orchestration via depends_on + healthchecks
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Layer 0 â€” no depends_on
postgresql:
  healthcheck:
    test: ["CMD-SHELL", "pg_isready -U postgres"]
    interval: 5s
    timeout: 5s
    retries: 10
    start_period: 30s

redis:
  healthcheck:
    test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "--no-auth-warning", "ping"]
    interval: 5s
    timeout: 5s
    retries: 10
    start_period: 10s

qdrant:
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:6333/healthz || exit 1"]
    interval: 10s
    timeout: 5s
    retries: 10
    start_period: 15s

ollama:
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
    interval: 10s
    timeout: 5s
    retries: 15
    start_period: 30s

# Layer 1
litellm:
  depends_on:
    postgresql:
      condition: service_healthy
    redis:
      condition: service_healthy
    ollama:
      condition: service_healthy
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:4000/health/liveliness || exit 1"]
    interval: 10s
    timeout: 10s
    retries: 15
    start_period: 45s

# Layer 2 â€” example: Dify API
dify-api:
  depends_on:
    postgresql:
      condition: service_healthy
    redis:
      condition: service_healthy
    qdrant:
      condition: service_healthy
    litellm:
      condition: service_healthy
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:5001/health || exit 1"]
    interval: 15s
    timeout: 10s
    retries: 10
    start_period: 60s

dify-worker:
  depends_on:
    dify-api:
      condition: service_healthy

dify-web:
  depends_on:
    dify-api:
      condition: service_healthy

n8n:
  depends_on:
    postgresql:
      condition: service_healthy
    redis:
      condition: service_healthy
    litellm:
      condition: service_healthy
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:5678/healthz || exit 1"]
    interval: 15s
    timeout: 10s
    retries: 10
    start_period: 45s

open-webui:
  depends_on:
    litellm:
      condition: service_healthy
  healthcheck:
    test: ["CMD-SHELL", "curl -f http://localhost:8080/ || exit 1"]
    interval: 15s
    timeout: 10s
    retries: 10
    start_period: 30s

# Layer 3 â€” Monitoring
uptime-kuma:
  depends_on:
    caddy:
      condition: service_started  # Softer dependency

# Layer 4 â€” Caddy (starts after core services)
caddy:
  depends_on:
    dify-web:
      condition: service_started
    n8n:
      condition: service_healthy
    open-webui:
      condition: service_healthy
    litellm:
      condition: service_healthy
27.3 Startup / Stop Helper Scripts (Generated by Script 2)
# /opt/ai-platform/start.sh
#!/usr/bin/env bash
set -euo pipefail

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  Starting AI Platform"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

cd /opt/ai-platform

# Start in dependency order using compose
docker compose up -d

echo ""
echo "Waiting for services to become healthy..."
echo ""

# Track startup progress
TIMEOUT=300
ELAPSED=0
while [ $ELAPSED -lt  $ TIMEOUT ]; do
    HEALTHY= $ (docker compose ps --format json 2>/dev/null | jq -r 'select(.Health == "healthy") | .Service' | wc -l)
    TOTAL= $ (docker compose ps --format json 2>/dev/null | jq -r '.Service' | wc -l)
    UNHEALTHY= $ (docker compose ps --format json 2>/dev/null | jq -r 'select(.Health == "unhealthy") | .Service' | wc -l)

    printf "\r  Services: %d/%d healthy | %d unhealthy | %ds elapsed" \
        " $ HEALTHY" " $ TOTAL" " $ UNHEALTHY" " $ ELAPSED"

    if [ " $ HEALTHY" -eq " $ TOTAL" ] && [ " $ TOTAL" -gt 0 ]; then
        break
    fi

    sleep 5
    ELAPSED= $ ((ELAPSED + 5))
done

echo ""
echo ""

if [ " $ HEALTHY" -eq " $ TOTAL" ]; then
    echo "âœ… All ${TOTAL} services are healthy!"
else
    echo "âš ï¸  ${HEALTHY}/${TOTAL} services healthy after ${TIMEOUT}s timeout."
    echo "   Check logs with: /opt/ai-platform/logs.sh"
fi

TS_IP= $ (tailscale ip -4 2>/dev/null || echo "localhost")
echo ""
echo "  Access: http:// $ {TS_IP}/"
echo ""
# /opt/ai-platform/stop.sh
#!/usr/bin/env bash
set -euo pipefail

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  Stopping AI Platform"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

cd /opt/ai-platform

# Stop in reverse dependency order
docker compose down --timeout 30

echo ""
echo "âœ… All services stopped."
echo "   Data preserved in /mnt/data/ai-platform/"
echo ""
# /opt/ai-platform/logs.sh
#!/usr/bin/env bash
cd /opt/ai-platform
SERVICE="${1:-}"
if [ -n " $ SERVICE" ]; then
    docker compose logs -f --tail=100 " $ SERVICE"
else
    docker compose logs -f --tail=50
fi
# /opt/ai-platform/status.sh
#!/usr/bin/env bash
cd /opt/ai-platform

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  AI Platform Status"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Table format
printf "  %-20s %-12s %-12s %-8s\n" "SERVICE" "STATE" "HEALTH" "UPTIME"
printf "  %-20s %-12s %-12s %-8s\n" "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€" "â”€â”€â”€â”€â”€â”€â”€â”€â”€" "â”€â”€â”€â”€â”€â”€â”€â”€â”€" "â”€â”€â”€â”€â”€â”€"

docker compose ps --format json 2>/dev/null | jq -r '
    [.Service, .State, (.Health // "n/a"), .RunningFor] | @tsv' | \
    sort | while IFS= $ '\t' read -r svc state health uptime; do
        printf "  %-20s %-12s %-12s %-8s\n" " $ svc" " $ state" " $ health" "$uptime"
    done

echo ""

# Resource usage summary
echo "  RESOURCE USAGE"
echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
docker stats --no-stream --format "  {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}" 2>/dev/null | sort

echo ""

# Disk usage
echo "  DISK USAGE"
echo "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
df -h /mnt/data 2>/dev/null | tail -1 | awk '{printf "  Data disk: %s used of %s (%s free)\n", $3, $2,  $ 4}'
du -sh /mnt/data/ai-platform/*/data 2>/dev/null | sort -rh | head -5 | while read -r size path; do
    printf "  %-40s %s\n" " $ path" " $ size"
done

echo ""
TS_IP= $ (tailscale ip -4 2>/dev/null || echo "localhost")
echo "  Access: http://${TS_IP}/"

28. Complete File Manifest
28.1 Files Created by Script 1
/opt/ai-platform/
â”œâ”€â”€ script1-infrastructure.sh          # Script 1 itself (self-copies)
â”œâ”€â”€ script2-deploy.sh                  # Placeholder / downloaded
â””â”€â”€ script3-verify.sh                  # Placeholder / downloaded

/mnt/data/                              # Data disk mount point
â””â”€â”€ ai-platform/
    â”œâ”€â”€ credentials/                    # [created, permissions 700]
    â”œâ”€â”€ logs/                           # [created]
    â”œâ”€â”€ backups/                        # [created]
    â””â”€â”€ .script1-complete               # Marker file

/etc/sysctl.d/
â””â”€â”€ 99-ai-platform.conf                # Kernel tuning

/etc/security/limits.d/
â””â”€â”€ ai-platform.conf                   # File descriptor limits

/etc/logrotate.d/
â””â”€â”€ ai-platform                         # Log rotation config

System changes:
  â€¢ Docker CE installed + configured
  â€¢ Docker Compose v2 available
  â€¢ Tailscale installed + authenticated
  â€¢ UFW configured (SSH only from anywhere, all else Tailscale only)
  â€¢ Swap configured (if needed)
  â€¢ System packages updated
28.2 Files Created by Script 2
/opt/ai-platform/
â”œâ”€â”€ docker-compose.yml                  # Main compose file (generated)
â”œâ”€â”€ .env                                # Environment variables for compose
â”œâ”€â”€ start.sh                            # Start all services
â”œâ”€â”€ stop.sh                             # Stop all services
â”œâ”€â”€ status.sh                           # Show platform status
â”œâ”€â”€ logs.sh                             # View service logs
â”œâ”€â”€ backup.sh                           # Run backup
â”œâ”€â”€ update.sh                           # Update service images
â””â”€â”€ .script2-complete                   # Marker file

/mnt/data/ai-platform/
â”œâ”€â”€ credentials/
â”‚   â”œâ”€â”€ generated_secrets.env           # All auto-generated passwords/keys [600]
â”‚   â”œâ”€â”€ api_keys.env                    # User-provided API keys [600]
â”‚   â”œâ”€â”€ litellm_service_keys.env        # Per-service LiteLLM virtual keys [600]
â”‚   â”œâ”€â”€ admin_credentials.txt           # Initial admin logins [600]
â”‚   â”œâ”€â”€ tailscale.env                   # Tailscale IP and hostname [600]
â”‚   â””â”€â”€ ollama_models.txt               # Selected Ollama models [600]
â”‚
â”œâ”€â”€ caddy/
â”‚   â””â”€â”€ Caddyfile                       # Reverse proxy configuration
â”‚
â”œâ”€â”€ litellm/
â”‚   â””â”€â”€ config.yaml                     # LiteLLM proxy configuration
â”‚
â”œâ”€â”€ postgresql/
â”‚   â”œâ”€â”€ data/                           # PostgreSQL data directory
â”‚   â””â”€â”€ init/
â”‚       â”œâ”€â”€ 01-init-databases.sql       # Database & user creation
â”‚       â””â”€â”€ 02-performance.sql          # Performance tuning
â”‚
â”œâ”€â”€ redis/
â”‚   â””â”€â”€ data/                           # Redis persistence
â”‚
â”œâ”€â”€ qdrant/
â”‚   â”œâ”€â”€ storage/                        # Qdrant vector storage
â”‚   â””â”€â”€ snapshots/                      # Qdrant snapshots
â”‚
â”œâ”€â”€ ollama/
â”‚   â””â”€â”€ models/                         # Downloaded model files
â”‚
â”œâ”€â”€ dify/
â”‚   â”œâ”€â”€ storage/                        # Uploaded files, generated content
â”‚   â””â”€â”€ nginx/                          # Dify nginx config (if needed)
â”‚
â”œâ”€â”€ n8n/
â”‚   â””â”€â”€ data/                           # Workflow data, credentials
â”‚
â”œâ”€â”€ open-webui/
â”‚   â””â”€â”€ data/                           # Chat history, settings
â”‚
â”œâ”€â”€ flowise/
â”‚   â””â”€â”€ data/                           # Flow definitions, uploads
â”‚
â”œâ”€â”€ anythingllm/
â”‚   â””â”€â”€ storage/                        # Documents, embeddings
â”‚
â”œâ”€â”€ openclaw/
â”‚   â””â”€â”€ data/                           # Legal documents, analysis
â”‚
â”œâ”€â”€ uptime-kuma/
â”‚   â””â”€â”€ data/                           # Monitoring configuration
â”‚
â”œâ”€â”€ dozzle/                             # (stateless â€” no persistent data)
â”‚
â”œâ”€â”€ cadvisor/                           # (stateless â€” no persistent data)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ caddy/
â”‚       â””â”€â”€ access.log                  # Caddy access logs
â”‚
â””â”€â”€ backups/
    â””â”€â”€ YYYYMMDD-HHMMSS/               # Timestamped backup directories
        â”œâ”€â”€ dify.pg_dump
        â”œâ”€â”€ n8n.pg_dump
        â”œâ”€â”€ litellm.pg_dump
        â”œâ”€â”€ redis-dump.rdb
        â”œâ”€â”€ configs.tar.gz
        â””â”€â”€ *.tar.gz                    # Service data archives
28.3 Docker Resources Created
Networks:
  â€¢ ai-backend     â€” Internal services (databases, Ollama, LiteLLM)
  â€¢ ai-frontend    â€” Services that Caddy routes to
  â€¢ ai-monitoring  â€” Monitoring stack

Containers (typical full install):
  01. postgresql     â€” Database server
  02. redis          â€” Cache & message broker
  03. qdrant         â€” Vector database
  04. ollama         â€” Local LLM runtime
  05. litellm        â€” AI gateway proxy
  06. dify-api       â€” Dify backend API
  07. dify-worker    â€” Dify async worker
  08. dify-web       â€” Dify frontend
  09. n8n            â€” Workflow automation
  10. open-webui     â€” Chat interface
  11. flowise        â€” Visual LLM flow builder
  12. anythingllm    â€” Document chat
  13. openclaw       â€” Legal AI
  14. uptime-kuma    â€” Uptime monitoring
  15. dozzle         â€” Log viewer
  16. cadvisor       â€” Resource monitoring
  17. caddy          â€” Reverse proxy

29. Resource Requirements Summary
29.1 Per-Service Resource Allocation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Service         â”‚ RAM (min) â”‚ RAM (rec) â”‚ Notes                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PostgreSQL      â”‚   512MB   â”‚    2GB    â”‚ Scales with data size        â”‚
â”‚ Redis           â”‚   128MB   â”‚   512MB   â”‚ Capped by maxmemory         â”‚
â”‚ Qdrant          â”‚   512MB   â”‚    2GB    â”‚ Scales with vectors          â”‚
â”‚ Ollama          â”‚    2GB    â”‚   8GB+    â”‚ Model dependent              â”‚
â”‚ LiteLLM         â”‚   256MB   â”‚   512MB   â”‚ Lightweight proxy            â”‚
â”‚ Dify API        â”‚   512MB   â”‚    1GB    â”‚ Python service               â”‚
â”‚ Dify Worker     â”‚   512MB   â”‚    1GB    â”‚ Background processing        â”‚
â”‚ Dify Web        â”‚   128MB   â”‚   256MB   â”‚ Next.js frontend             â”‚
â”‚ n8n             â”‚   256MB   â”‚   512MB   â”‚ Node.js                      â”‚
â”‚ Open WebUI      â”‚   256MB   â”‚   512MB   â”‚ Svelte frontend + backend    â”‚
â”‚ Flowise         â”‚   256MB   â”‚   512MB   â”‚ Node.js                      â”‚
â”‚ AnythingLLM     â”‚   256MB   â”‚   512MB   â”‚ Node.js                      â”‚
â”‚ OpenClaw        â”‚   256MB   â”‚   512MB   â”‚ Depends on implementation    â”‚
â”‚ Uptime Kuma     â”‚   128MB   â”‚   256MB   â”‚ Lightweight                  â”‚
â”‚ Dozzle          â”‚    64MB   â”‚   128MB   â”‚ Very lightweight             â”‚
â”‚ cAdvisor        â”‚   128MB   â”‚   256MB   â”‚ System metrics               â”‚
â”‚ Caddy           â”‚    64MB   â”‚   128MB   â”‚ Very lightweight             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL           â”‚   ~6GB    â”‚  ~18GB+   â”‚ Full stack                   â”‚
â”‚ Without Ollama  â”‚   ~4GB    â”‚  ~10GB    â”‚ Cloud-only AI providers      â”‚
â”‚ Minimal (4 svc) â”‚   ~2GB    â”‚   ~6GB    â”‚ Dify + LiteLLM + PG + Redis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
29.2 Tier Recommendations (from Script 1)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tier        â”‚ RAM      â”‚ Disk      â”‚ Recommended Services                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Minimal     â”‚  8GB     â”‚  80GB SSD â”‚ Dify, LiteLLM, PG, Redis, Caddy    â”‚
â”‚ Standard    â”‚ 16GB     â”‚ 200GB SSD â”‚ + Open WebUI, n8n, Qdrant, Ollama  â”‚
â”‚ Full        â”‚ 32GB     â”‚ 500GB SSD â”‚ + Flowise, AnythingLLM, OpenClaw   â”‚
â”‚ Production  â”‚ 64GB+    â”‚  1TB+ SSD â”‚ All services + larger models       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

30. Post-Installation Workflow
30.1 First-Time Setup Guide (Displayed by Script 3)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  GETTING STARTED â€” First 15 Minutes
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Step 1 â€” Access Dify (Primary AI Platform)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  URL: http://<tailscale-ip>/dify/
  â€¢ Create your admin account on first visit
  â€¢ Go to Settings â†’ Model Providers
  â€¢ Add "OpenAI-API-compatible" provider:
    - API Base: http://litellm:4000/v1
    - API Key: <from litellm_service_keys.env>
  â€¢ Create your first AI workflow or chatbot

  Step 2 â€” Configure Open WebUI
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  URL: http://<tailscale-ip>/webui/
  â€¢ Create admin account
  â€¢ Already configured to use LiteLLM
  â€¢ Start chatting with any configured model

  Step 3 â€” Set Up n8n Automation
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  URL: http://<tailscale-ip>/n8n/
  â€¢ Log in with credentials from admin_credentials.txt
  â€¢ Add AI credentials:
    - Type: OpenAI-compatible
    - Base URL: http://litellm:4000/v1
    - API Key: <from litellm_service_keys.env>
  â€¢ Import starter workflows (provided in /opt/ai-platform/examples/)

  Step 4 â€” Configure Uptime Kuma
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  URL: http://<tailscale-ip>/status/
  â€¢ Create admin account
  â€¢ Add monitors for each service (pre-configured template available)
  â€¢ Set up notification channels (email, Slack, Discord)

  Step 5 â€” Review LiteLLM Dashboard
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  URL: http://<tailscale-ip>/litellm/ui/
  â€¢ Log in with master key from generated_secrets.env
  â€¢ Review model routing, costs, and usage
  â€¢ Create virtual keys for additional users

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

31. Project Summary
31.1 What Has Been Designed
This master document specifies a complete, self-contained AI platform deployed
on a single Linux server with the following characteristics:
Copy table


Attribute
Detail



Total services
Up to 17 containers


AI capabilities
Chatbots, RAG, workflows, automation, document analysis


LLM routing
Unified gateway (LiteLLM) supporting cloud + local models


Security model
Zero public ports, Tailscale-only access


Automation
Three scripts: infrastructure â†’ deployment â†’ verification


Monitoring
Health checks, uptime monitoring, log aggregation, resource metrics


Backup
Automated daily backups with 7-day retention


Customization
Interactive menus for service/model/provider selection


Idempotency
All scripts safe to re-run


Documentation
Self-documenting with credential files and status commands


31.2 Three Scripts at a Glance
Script 1 â€” INFRASTRUCTURE (Run once, ~10 minutes)
  Input:  Fresh Ubuntu/Debian server with SSH access
  Output: Docker, Tailscale, firewall, kernel tuning, disk setup
  Human:  Provide Tailscale auth key, confirm disk selection

Script 2 â€” DEPLOYMENT (Run once, ~15-30 minutes)
  Input:  Server with Script 1 complete
  Output: Full running AI platform with all services
  Human:  Select services, provide API keys, choose models

Script 3 â€” VERIFICATION (Run anytime, ~2 minutes)
  Input:  Server with Script 2 complete
  Output: Diagnostic report with pass/warn/fail for every component
  Human:  Review report, address any warnings or failures
31.3 Key Design Decisions

Caddy over Nginx/Traefik â€” Simplest config, automatic reloads, sufficient for single-server
LiteLLM as mandatory â€” Decouples AI consumers from providers; enables cost tracking
PostgreSQL shared â€” One instance with per-service databases reduces RAM usage
Redis shared â€” Sufficient for the workload; per-service logical databases
Qdrant over Weaviate/Milvus â€” Lighter, Rust-based, great API, sufficient for scale
Ollama for local models â€” De facto standard, best Docker integration
Tailscale-only access â€” Eliminates entire categories of security concerns
Path-based routing â€” Works without DNS configuration; single IP access
Everything on /mnt/data â€” Separates OS from data; easy backup and migration
Interactive menus â€” Accommodates varying hardware and use cases


END OF MASTER DOCUMENT
This document contains the complete specification for generating the three
deployment scripts. Each section provides:
  â€¢ Exact configuration values and templates
  â€¢ Decision logic for conditional generation
  â€¢ Error handling patterns
  â€¢ Security considerations
The scripts should be generated to implement this specification faithfully,
using the code patterns, file paths, and architectural decisions documented
in these 12 parts.
Document version: 1.0
Total sections: 31
Total parts: 12 of 12

---

# âœ… MASTER DOCUMENT COMPLETE â€” ALL 12 PARTS DELIVERED

Here's a summary of what was covered across all parts:

| Part | Sections | Key Content |
|------|----------|-------------|
| **1** | 1â€“3 | Vision, architecture, network topology |
| **2** | 4â€“6 | Security model, Tailscale, disk strategy |
| **3** | 7â€“8 | Script 1 infrastructure logic |
| **4** | 9â€“10 | Script 1 Docker, kernel tuning, Tailscale |
| **5** | 11â€“12 | Script 2 overview, interactive menus |
| **6** | 13â€“14 | Secret generation, docker-compose structure |
| **7** | 15â€“16 | Dify, n8n, Open WebUI compose configs |
| **8** | 17 | Flowise, AnythingLLM, OpenClaw, monitoring |
| **9** | 18â€“20 | Caddy reverse proxy, PostgreSQL init |
| **10** | 21â€“23 | LiteLLM config, model routing, Ollama logic |
| **11** | 24â€“26 | Script 3 verification, backup, logging |
| **12** | 27â€“31 | Dependencies, startup, file manifest, summary |
