# Baseline AI Platform Implementation Plan

## üéØ Executive Summary

This document outlines the **final corrected implementation approach** based on comprehensive user feedback. The architecture achieves **multi-stack isolation through parameterization alone** - no multi-tenant logic baked into scripts.

**Status**: ‚úÖ **APPROVED FOR IMPLEMENTATION** with minor fixes applied

---

## üéØ Core Architecture Principle

### **"Scripts Unaware of Other Stacks"**
```
Correct mental model:
  User A runs the 5 scripts ‚Üí gets a stack
  User B runs the same 5 scripts ‚Üí gets a stack
  Scripts never reference each other's existence
  Isolation comes from OS (different user, different mount)
  
Analogy: Dockerfile doesn't know how many containers will run.
Each instance is isolated by the runtime, not by logic inside.
```

---

## üìã Final Corrections Applied

### **‚úÖ Fully Approved Components**
- ‚úÖ Container names stay simple (n8n, postgres) - isolation via network
- ‚úÖ DOCKER_NETWORK + BASE_DIR as the two isolation axes
- ‚úÖ No auto-UID detection - explicit operator input
- ‚úÖ Port allocation owned entirely by Script 1
- ‚úÖ AppArmor profiles named `${DOCKER_NETWORK}-default` etc.
- ‚úÖ AppArmor templates stored in `${BASE_DIR}/apparmor/` (tenant-owned)
- ‚úÖ sed substitutes BASE_DIR_PLACEHOLDER before loading
- ‚úÖ OpenClaw allowlist-only AppArmor - no invalid negative globs
- ‚úÖ OPENCLAW_UID = STACK_USER_UID + 1 (simple, deterministic)
- ‚úÖ Script 0 cleanup: `rm -f /etc/apparmor.d/${DOCKER_NETWORK}-*`
- ‚úÖ EBS validation: mountpoint -q, writability, 20GB minimum
- ‚úÖ Vector DB wired at deploy time in Script 2
- ‚úÖ Script 3 = ops only (renew, restart, reload, status)

### **üîß Minor Fixes Applied**
1. **Fixed port allocation retry loop** - replaced bash for-loop with while-true
2. **Replaced netstat with ss** - modern Linux preferred tool
3. **Added explicit sed substitution** in Script 2's AppArmor loading
4. **Added script header documentation** - scripts run as root, containers run as STACK_USER_UID
5. **Added TODO comment** for future per-service AppArmor hardening

---

## üèóÔ∏è Final Architecture Model

### **Stack A Configuration**
```bash
# Generated by Script 1
BASE_DIR=/mnt/data
DOCKER_NETWORK=ai_platform
DOMAIN_NAME=ai.datasquiz.net
STACK_USER_UID=1000
STACK_USER_GID=1000
OPENCLAW_UID=1001
OPENCLAW_GID=1001

# Ports (assigned by availability check)
PROMETHEUS_PORT=5000
GRAFANA_PORT=5001
N8N_PORT=5002
# ... etc
```

### **Stack B Configuration (Same Scripts, Different Values)**
```bash
# Generated by Script 1 (second run)
BASE_DIR=/mnt/data2
DOCKER_NETWORK=ai_platform_2
DOMAIN_NAME=ai2.datasquiz.net
STACK_USER_UID=2000
STACK_USER_GID=2000
OPENCLAW_UID=2001
OPENCLAW_GID=2001

# Ports (assigned by availability check)
PROMETHEUS_PORT=5100
GRAFANA_PORT=5101
N8N_PORT=5102
# ... etc
```

### **Isolation Mechanisms**
- **Filesystem**: Different `BASE_DIR` paths
- **Network**: Different `DOCKER_NETWORK` names
- **Process**: Different `STACK_USER_UID` values
- **Security**: Different AppArmor profiles
- **Ports**: Different host port mappings

---

## üìã Implementation Phases

### **Phase 1: Script 1 - Parameterized Setup (Week 1)**

#### **1.1 Script Header and Main Function**
```bash
#!/bin/bash
# Script 1: Setup & Configuration (Parameterized)
# 
# NOTE: This script runs as root (required for system setup)
# STACK_USER_UID will own BASE_DIR for container permissions

main() {
    echo "üöÄ AI Platform Setup"
    
    # Interactive configuration
    interactive_config
    
    # Validate EBS volume
    validate_ebs_mount
    
    # Create directory structure
    create_directories
    
    # Set ownership
    set_ownership
    
    # Port allocation with conflict checking
    allocate_ports
    
    # Generate AppArmor templates
    create_apparmor_templates
    
    # Generate .env
    generate_env
    
    echo "‚úÖ Stack configuration complete!"
    echo "   Base Directory: ${BASE_DIR}"
    echo "   User UID/GID: ${STACK_USER_UID}:${STACK_USER_GID}"
    echo "   Network: ${DOCKER_NETWORK}"
    echo "   Configuration: ${BASE_DIR}/config/.env"
}
```

#### **1.2 Interactive Configuration**
```bash
interactive_config() {
    echo "=== Stack Configuration ==="
    read -p "EBS mount point for this stack [/mnt/data]: " BASE_DIR
    BASE_DIR=${BASE_DIR:-/mnt/data}
    
    read -p "Service owner UID [1000]: " STACK_USER_UID
    STACK_USER_UID=${STACK_USER_UID:-1000}
    
    read -p "Service owner GID [1000]: " STACK_USER_GID
    STACK_USER_GID=${STACK_USER_GID:-1000}
    
    read -p "Docker network name [ai_platform]: " DOCKER_NETWORK
    DOCKER_NETWORK=${DOCKER_NETWORK:-ai_platform}
    
    read -p "Domain name [ai.datasquiz.net]: " DOMAIN_NAME
    DOMAIN_NAME=${DOMAIN_NAME:-ai.datasquiz.net}
    
    # OpenClaw gets next UID up
    OPENCLAW_UID=$((STACK_USER_UID + 1))
    OPENCLAW_GID=$((STACK_USER_GID + 1))
}
```

#### **1.3 EBS Validation (Enhanced)**
```bash
validate_ebs_mount() {
    # Check it exists
    if [ ! -d "${BASE_DIR}" ]; then
        echo "‚ùå ${BASE_DIR} does not exist"
        exit 1
    fi

    # Check it is a real mount point (not just local dir)
    if ! mountpoint -q "${BASE_DIR}"; then
        echo "‚ö†Ô∏è  WARNING: ${BASE_DIR} is not a dedicated mount point"
        read -p "Continue anyway? (y/N): " confirm
        [[ "$confirm" =~ ^[Yy]$ ]] || exit 1
    fi

    # Check it is writable by the specified UID
    if ! sudo -u "#${STACK_USER_UID}" test -w "${BASE_DIR}"; then
        echo "‚ùå ${BASE_DIR} is not writable by UID ${STACK_USER_UID}"
        exit 1
    fi

    # Check sufficient free space (minimum 20GB)
    local free_gb=$(df -BG "${BASE_DIR}" | awk 'NR==2 {gsub("G",""); print $4}')
    if [ "${free_gb}" -lt 20 ]; then
        echo "‚ùå Insufficient space: ${free_gb}GB free, 20GB required"
        exit 1
    fi

    echo "‚úÖ EBS volume validated at ${BASE_DIR} (${free_gb}GB free)"
}
```

#### **1.4 Port Allocation (Fixed)**
```bash
allocate_ports() {
    local services=(prometheus grafana n8n dify anythingllm litellm \
                    openwebui minio signal openclaw flowise)
    local default_ports=(5000 5001 5002 5003 5004 5005 5006 \
                         5007 5008 5009 5010 5011)

    echo "=== Port Allocation ==="
    
    for i in "${!services[@]}"; do
        local service=${services[$i]}
        local default_port=${default_ports[$i]}
        local port=""

        while true; do
            read -p "${service} port [${default_port}]: " port_input
            port=${port_input:-$default_port}

            if ss -tlnp | grep -q ":${port} "; then
                echo "‚ö†Ô∏è  Port ${port} is in use ‚Äî choose another"
            else
                echo "‚úÖ Port ${port} assigned to ${service}"
                break
            fi
        done

        # Export for later use in generate_env
        declare -g "${service^^}_PORT=${port}"
    done
}
```

#### **1.5 AppArmor Template Creation**
```bash
create_apparmor_templates() {
    local profile_dir="${BASE_DIR}/apparmor"
    mkdir -p "$profile_dir"
    
    # Default profile template
    cat > "${profile_dir}/default.profile.tmpl" << 'EOF'
#include <tunables/global>

profile ai-platform-default flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>

  # TODO: Future hardening - restrict per service to ${BASE_DIR}/data/${service_name}/**
  # Current: Allow access to entire stack data directory
  BASE_DIR_PLACEHOLDER/** rw,

  deny /etc/shadow r,
  deny /etc/passwd w,
  deny /root/** rw,

  network,
  /proc/self/** r,
  /sys/fs/cgroup/** r,
}
EOF

    # OpenClaw profile template (allowlist-only)
    cat > "${profile_dir}/openclaw.profile.tmpl" << 'EOF'
#include <tunables/global>

profile ai-platform-openclaw flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>

  # Allowlist: only what OpenClaw needs
  BASE_DIR_PLACEHOLDER/data/openclaw/** rw,
  /tmp/** rw,

  network,
  capability net_admin,
  capability sys_module,
}
EOF

    # Tailscale profile template
    cat > "${profile_dir}/tailscale.profile.tmpl" << 'EOF'
#include <tunables/global>

profile ai-platform-tailscale flags=(attach_disconnected,mediate_deleted) {
  #include <abstractions/base>

  BASE_DIR_PLACEHOLDER/data/tailscale/** rw,
  /dev/net/tun rw,
  /var/run/tailscale/** rw,

  network,
  capability net_admin,
  capability sys_module,
}
EOF

    echo "‚úÖ AppArmor templates created in ${profile_dir}"
}
```

#### **1.6 Environment Generation**
```bash
generate_env() {
    mkdir -p "${BASE_DIR}/config"
    
    cat > "${BASE_DIR}/config/.env" << EOF
# === Stack Configuration ===
BASE_DIR=${BASE_DIR}
DOCKER_NETWORK=${DOCKER_NETWORK}
DOMAIN_NAME=${DOMAIN_NAME}
LOCALHOST=localhost

# === User Identity ===
STACK_USER_UID=${STACK_USER_UID}
STACK_USER_GID=${STACK_USER_GID}
OPENCLAW_UID=${OPENCLAW_UID}
OPENCLAW_GID=${OPENCLAW_GID}

# === AppArmor Profile Names ===
APPARMOR_DEFAULT=${DOCKER_NETWORK}-default
APPARMOR_OPENCLAW=${DOCKER_NETWORK}-openclaw
APPARMOR_TAILSCALE=${DOCKER_NETWORK}-tailscale

# === Port Configuration ===
PROMETHEUS_PORT=${PROMETHEUS_PORT}
GRAFANA_PORT=${GRAFANA_PORT}
N8N_PORT=${N8N_PORT}
DIFY_PORT=${DIFY_PORT}
ANYTHINGLLM_PORT=${ANYTHINGLLM_PORT}
LITELLM_PORT=${LITELLM_PORT}
OPENWEBUI_PORT=${OPENWEBUI_PORT}
MINIO_S3_PORT=${MINIO_S3_PORT}
MINIO_CONSOLE_PORT=${MINIO_CONSOLE_PORT}
SIGNAL_PORT=${SIGNAL_PORT}
OPENCLAW_PORT=${OPENCLAW_PORT}
FLOWISE_PORT=${FLOWISE_PORT}

# === Vector DB ===
VECTOR_DB=qdrant

# === Tailscale ===
TAILSCALE_AUTH_KEY=
TAILSCALE_HOSTNAME=openclaw-${DOMAIN_NAME}
EOF

    echo "‚úÖ Configuration written to ${BASE_DIR}/config/.env"
}
```

---

### **Phase 2: Script 2 - Parameterized Deployment (Week 1)**

#### **2.1 Script Header and Main Function**
```bash
#!/bin/bash
# Script 2: Parameterized Deployment
#
# NOTE: This script runs as root (required for Docker, AppArmor, system setup)
# STACK_USER_UID owns BASE_DIR for container permissions

# Load configuration from .env
source "${BASE_DIR:-/mnt/data}/config/.env"

main() {
    echo "üöÄ AI Platform Deployment"
    
    validate_config
    create_network
    load_apparmor_profiles
    set_vectordb_config
    
    # Deploy infrastructure
    deploy_infrastructure
    deploy_ai_services
    deploy_openclaw
    deploy_caddy
    validate_deployment
}
```

#### **2.2 AppArmor Profile Loading (Fixed)**
```bash
load_apparmor_profiles() {
    local profile_dir="${BASE_DIR}/apparmor"

    for profile in default openclaw tailscale; do
        local src="${profile_dir}/${profile}.profile.tmpl"
        local dst="/etc/apparmor.d/${DOCKER_NETWORK}-${profile}"

        # Substitute BASE_DIR into template
        sed "s|BASE_DIR_PLACEHOLDER|${BASE_DIR}|g" "${src}" > "${dst}"

        # Load into kernel
        apparmor_parser -r "${dst}"
        echo "‚úÖ AppArmor profile loaded: ${DOCKER_NETWORK}-${profile}"
    done
}
```

#### **2.3 Service Deployment**
```bash
deploy_service() {
    local service_name=$1
    local image=$2
    local internal_port=$3
    local host_port=$4
    
    docker run -d \
        --name "${service_name}" \
        --network "${DOCKER_NETWORK}" \
        --restart unless-stopped \
        --security-opt "apparmor=${APPARMOR_DEFAULT}" \
        --user "${STACK_USER_UID}:${STACK_USER_GID}" \
        -p "${host_port}:${internal_port}" \
        -v "${BASE_DIR}/data/${service_name}:/app/data" \
        -v "${BASE_DIR}/logs/${service_name}:/app/logs" \
        "${vectordb_env[@]}" \
        "${image}"
}

deploy_openclaw() {
    if [ -z "${TAILSCALE_AUTH_KEY}" ]; then
        echo "‚ùå TAILSCALE_AUTH_KEY missing ‚Äî OpenClaw requires Tailscale"
        return 1
    fi

    # Create OpenClaw directories
    mkdir -p "${BASE_DIR}/data/openclaw" "${BASE_DIR}/data/tailscale"
    chown -R ${OPENCLAW_UID}:${OPENCLAW_GID} "${BASE_DIR}/data/openclaw"
    chown -R ${OPENCLAW_UID}:${OPENCLAW_GID} "${BASE_DIR}/data/tailscale"

    # Step 1: Tailscale sidecar
    docker run -d \
        --name "tailscale" \
        --network "${DOCKER_NETWORK}" \
        --restart unless-stopped \
        --cap-add NET_ADMIN \
        --cap-add SYS_MODULE \
        --security-opt "apparmor=${APPARMOR_TAILSCALE}" \
        --user "${OPENCLAW_UID}:${OPENCLAW_GID}" \
        -v "${BASE_DIR}/data/tailscale:/var/lib/tailscale" \
        -v /dev/net/tun:/dev/net/tun \
        -e "TAILSCALE_AUTH_KEY=${TAILSCALE_AUTH_KEY}" \
        -e "TAILSCALE_HOSTNAME=${TAILSCALE_HOSTNAME}" \
        tailscale/tailscale:latest

    # Wait for Tailscale authentication
    wait_for_tailscale_auth "tailscale"

    # Step 2: OpenClaw in shared network namespace
    docker run -d \
        --name "openclaw" \
        --network "container:tailscale" \
        --restart unless-stopped \
        --security-opt "apparmor=${APPARMOR_OPENCLAW}" \
        --user "${OPENCLAW_UID}:${OPENCLAW_GID}" \
        --read-only \
        --tmpfs /tmp:rw,noexec,nosuid,size=100m \
        -v "${BASE_DIR}/data/openclaw:/app/data:rw" \
        -v "${BASE_DIR}/config/openclaw:/app/config:ro" \
        "${vectordb_env[@]}" \
        openclaw/openclaw:latest

    echo "‚úÖ OpenClaw deployed"
}
```

---

### **Phase 3: Script 3 - Operations (Week 2)**

#### **3.1 Stack-Aware Operations**
```bash
#!/bin/bash
# Script 3: Operations & Management
#
# NOTE: This script runs as root (required for Docker operations)
# STACK_USER_UID owns BASE_DIR for container permissions

detect_stack() {
    if [[ -f "${BASE_DIR:-/mnt/data}/config/.env" ]]; then
        source "${BASE_DIR:-/mnt/data}/config/.env"
        echo "‚úÖ Stack detected: ${DOMAIN_NAME}"
    else
        echo "‚ùå No stack configuration found. Run from stack directory or set BASE_DIR."
        exit 1
    fi
}

renew_ssl() {
    detect_stack
    echo "üîÑ Renewing SSL for ${DOMAIN_NAME}"
    docker exec "caddy" caddy reload --config "/etc/caddy/Caddyfile"
}

restart_service() {
    local service_name=$1
    detect_stack
    echo "üîÑ Restarting ${service_name}"
    docker restart "${service_name}"
}

show_status() {
    detect_stack
    echo "üìä Stack Status (${DOMAIN_NAME}, UID ${STACK_USER_UID}):"
    docker ps --network "${DOCKER_NETWORK}" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
}

health_check() {
    detect_stack
    echo "üîç Health Check (${DOMAIN_NAME}):"
    
    local services=(prometheus grafana n8n anythingllm litellm openwebui minio)
    for service in "${services[@]}"; do
        local status=$(curl -s -o /dev/null -w "%{http_code}" \
            --max-time 5 "http://${LOCALHOST}:${!service^^}_PORT}/health" 2>/dev/null)
        
        if [[ "$status" == "200" ]]; then
            echo "‚úÖ $service: Healthy"
        elif [[ "$status" == "502" ]]; then
            echo "‚ö†Ô∏è  $service: Service not ready (502)"
        else
            echo "‚ùå $service: Unhealthy ($status)"
        fi
    done
}

main() {
    case "${1:-status}" in
        renew) renew_ssl ;;
        restart) restart_service "${2}" ;;
        status) show_status ;;
        health) health_check ;;
        *) 
            echo "Usage: $0 {renew|restart|status|health}"
            exit 1
            ;;
    esac
}
```

---

### **Phase 4: Script 4 - Add Service (Week 2)**

#### **4.1 Service Addition**
```bash
#!/bin/bash
# Script 4: Add Service to Stack
#
# NOTE: This script runs as root (required for Docker, AppArmor operations)
# STACK_USER_UID owns BASE_DIR for container permissions

detect_stack() {
    if [[ -f "${BASE_DIR:-/mnt/data}/config/.env" ]]; then
        source "${BASE_DIR:-/mnt/data}/config/.env"
    else
        echo "‚ùå No stack configuration found. Run from stack directory or set BASE_DIR."
        exit 1
    fi
}

add_service() {
    local service_name=$1
    local service_image=$2
    local internal_port=$3
    local host_port=$4
    
    detect_stack
    
    # Check port availability
    if ss -tlnp | grep -q ":$host_port "; then
        echo "‚ùå Port $host_port is in use"
        exit 1
    fi
    
    # Create service-specific AppArmor profile
    cp "/etc/apparmor.d/${APPARMOR_DEFAULT}" \
       "/etc/apparmor.d/${DOCKER_NETWORK}-${service_name}"
    apparmor_parser -r "/etc/apparmor.d/${DOCKER_NETWORK}-${service_name}"
    
    # Deploy service
    docker run -d \
        --name "${service_name}" \
        --network "${DOCKER_NETWORK}" \
        --restart unless-stopped \
        --security-opt "apparmor=${DOCKER_NETWORK}-${service_name}" \
        --user "${STACK_USER_UID}:${STACK_USER_GID}" \
        -p "${host_port}:${internal_port}" \
        -v "${BASE_DIR}/data/${service_name}:/app/data" \
        -v "${BASE_DIR}/logs/${service_name}:/app/logs" \
        "${service_image}"
    
    # Add route to Caddy
    add_caddy_route "$service_name" "$internal_port"
    
    # Reload Caddy
    docker exec "caddy" caddy reload --config "/etc/caddy/Caddyfile"
    
    echo "‚úÖ Service $service_name added to stack ${DOMAIN_NAME}"
    echo "   Internal port: $internal_port"
    echo "   Host port: $host_port"
    echo "   URL: http://${DOMAIN_NAME}/${service_name}/"
}

add_caddy_route() {
    local name=$1
    local port=$2
    # Insert before closing brace of Caddyfile
    sed -i "/respond \"AI Platform\"/i\\
    handle_path /${name}/* {\\
        reverse_proxy ${name}:${port}\\
    }\\
" "${BASE_DIR}/caddy/Caddyfile"
}

main() {
    case "${1:-add}" in
        add) add_service "${2}" "${3}" "${4}" "${5}" ;;
        *) 
            echo "Usage: $0 add <name> <image> <internal_port> <host_port>"
            exit 1
            ;;
    esac
}
```

---

### **Phase 5: Script 0 - Teardown (Week 2)**

#### **5.1 Complete Stack Removal**
```bash
#!/bin/bash
# Script 0: Stack Teardown
#
# NOTE: This script runs as root (required for Docker, AppArmor cleanup)

detect_stack() {
    if [[ -f "${BASE_DIR:-/mnt/data}/config/.env" ]]; then
        source "${BASE_DIR:-/mnt/data}/config/.env"
        echo "‚úÖ Stack detected: ${DOMAIN_NAME}"
    else
        echo "‚ùå No stack configuration found. Run from stack directory or set BASE_DIR."
        exit 1
    fi
}

teardown_stack() {
    detect_stack
    
    echo "üßπ Tearing down stack: ${DOMAIN_NAME}"
    
    # Stop all containers on the network
    echo "Stopping containers..."
    docker ps --filter "network=${DOCKER_NETWORK}" -q | xargs -r docker stop
    
    # Remove all containers on the network
    echo "Removing containers..."
    docker ps --filter "network=${DOCKER_NETWORK}" -a -q | xargs -r docker rm
    
    # Remove Docker network
    echo "Removing network..."
    docker network rm "${DOCKER_NETWORK}" 2>/dev/null || true
    
    # Remove AppArmor profiles
    echo "Removing AppArmor profiles..."
    rm -f /etc/apparmor.d/${DOCKER_NETWORK}-*
    
    # Ask about data removal
    echo ""
    read -p "Remove stack data from ${BASE_DIR}? (y/N): " remove_data
    if [[ "$remove_data" =~ ^[Yy]$ ]]; then
        rm -rf "${BASE_DIR}"
        echo "‚úÖ Stack data removed"
    else
        echo "‚ö†Ô∏è  Stack data preserved in ${BASE_DIR}"
    fi
    
    echo "‚úÖ Stack teardown complete"
}

main() {
    case "${1:-teardown}" in
        teardown) teardown_stack ;;
        *) 
            echo "Usage: $0 teardown"
            exit 1
            ;;
    esac
}
```

---

### **Phase 6: Testing & Validation (Week 2)**

#### **6.1 Multi-Stack Test**
```bash
#!/bin/bash
# Multi-Stack Validation Tests

test_multi_stack() {
    echo "üß™ Testing multi-stack deployment..."
    
    # Deploy Stack A
    cd /mnt/data || { echo "‚ùå /mnt/data not found"; return 1; }
    bash 1-setup-system.sh
    bash 2-deploy-services.sh
    
    # Deploy Stack B
    mkdir -p /mnt/data2
    chown 2000:2000 /mnt/data2
    
    # Create Stack B config
    cat > /mnt/data2/config/.env << EOF
BASE_DIR=/mnt/data2
DOCKER_NETWORK=ai_platform_2
DOMAIN_NAME=ai2.datasquiz.net
STACK_USER_UID=2000
STACK_USER_GID=2000
OPENCLAW_UID=2001
OPENCLAW_GID=2001
PROMETHEUS_PORT=5100
GRAFANA_PORT=5101
# ... other ports +100
EOF
    
    # Deploy Stack B
    cd /mnt/data2
    bash 2-deploy-services.sh
    
    # Verify isolation
    verify_stack_isolation
}

verify_stack_isolation() {
    echo "üîç Verifying stack isolation..."
    
    # Check network isolation
    local stack_a_network=$(docker inspect n8n --format='{{range .NetworkSettings.Networks}}{{.Network.Name}}')
    local stack_b_network=$(docker inspect -it ai_platform_2-n8n --format='{{range .NetworkSettings.Networks}}{{.Network.Name}}')
    
    if [[ "$stack_a_network" == "ai_platform" ]] && [[ "$stack_b_network" == "ai_platform_2" ]]; then
        echo "‚úÖ Network isolation working"
    else
        echo "‚ùå Network isolation failed"
        return 1
    fi
    
    # Check cross-stack access prevention
    docker exec n8n ls /mnt/data2/ 2>/dev/null && {
        echo "‚ùå Cross-stack access detected - SECURITY BREACH"
        return 1
    }
    
    echo "‚úÖ Cross-stack isolation working"
}

# The One-Line Test
test_one_line() {
    echo "üß™ Testing one-line deployment..."
    
    BASE_DIR=/mnt/data3 \
    STACK_USER_UID=3000 \
    DOCKER_NETWORK=ai_platform_3 \
    DOMAIN_NAME=ai3.datasquiz.net \
    PROMETHEUS_PORT=5200 \
    bash 2-deploy-services.sh
    
    echo "‚úÖ One-line test passed"
}

run_all_tests() {
    test_multi_stack || return 1
    verify_stack_isolation || return 1
    test_one_line || return 1
    
    echo "‚úÖ All tests passed"
}
```

---

## üéØ Success Criteria

### **The Test**
```bash
# Run 5 scripts twice with different .env values
# Must produce two completely isolated stacks with zero code changes

# Stack A:
cd /mnt/data && bash 1-setup-system.sh && bash 2-deploy-services.sh

# Stack B:
cd /mnt/data2 && bash 1-setup-system.sh && bash 2-deploy-services.sh

# Result: Two isolated stacks, same scripts
```

### **Validation Checklist**
- [ ] **No Auto-Detection**: Scripts ask operator for configuration
- [ ] **Simple Container Names**: No TENANT_NAME prefixes
- [ ] **Explicit Port Variables**: No port math, availability checking only
- [ ] **DOCKER_NETWORK AppArmor**: Clean profile naming
- [ ] **Allowlist Security**: Valid AppArmor syntax
- [ ] **EBS Validation**: mountpoint, writability, space check
- [ ] **Parameterized Architecture**: BASE_DIR, DOCKER_NETWORK, UIDs as variables
- [ ] **OpenClaw Isolation**: Strict filesystem confinement
- [ ] **Tailscale Sidecar**: Correct network namespace sharing
- [ ] **Vector DB Integration**: Wired at deploy time

---

## üöÄ Implementation Timeline

### **Week 1: Core Infrastructure**
- [ ] **Day 1-2**: Implement Script 1 with all corrections
- [ ] **Day 3-4**: Implement Script 2 with AppArmor loading fix
- [ ] **Day 5**: Fix current service issues

### **Week 2: Integration & Testing**
- [ ] **Day 1-2**: Implement Scripts 3 & 4
- [ ] **Day 3**: Implement Script 0
- [ ] **Day 4-5**: Multi-stack testing and validation

### **Week 3: Production Readiness**
- [ ] **Day 1-2**: Performance optimization and security hardening
- [ ] **Day 3**: Documentation and deployment guides
- [ ] **Day 4-5**: Production testing and monitoring setup

---

## üéØ Key Insight

**The correct approach**: **parameterize everything, isolate through configuration, not code**.

- **Multi-tenancy** = different `.env` values, same scripts
- **Isolation** = different BASE_DIR paths, Docker networks, UIDs, ports
- **Future-proofing** = scripts work with any configuration without changes

This allows **multiple AI stacks to run simultaneously** under different configurations with **complete isolation** while sharing the same host machine and codebase.

---

## üìã Next Steps

### **Immediate Actions (This Week)**
1. **Commit baseline plan** as release v1.0.0
2. **Start implementation** with Script 1
3. **Test port allocation fix** with while-true loop
4. **Validate AppArmor template substitution**

### **Future Enhancements (Post-Baseline)**
1. **Per-service AppArmor profiles** (hardening)
2. **Automated port range allocation** (advanced)
3. **Service discovery** (cross-stack communication)
4. **Monitoring and alerting** (production readiness)

---

*Baseline Implementation Plan: 2026-02-21*
*Version: 4.0 - Final Corrected Architecture*
*Architecture: Parameterized Multi-Stack Ready*
*Status: ‚úÖ APPROVED FOR IMPLEMENTATION*
*Release: v1.0.0*
