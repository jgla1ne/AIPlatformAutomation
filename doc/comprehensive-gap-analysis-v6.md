# AI Platform Automation - Focused Fix Plan

**Date:** February 16, 2026  
**Status:** 8/13 services deployed, 5 failing  
**Goal:** Minimal re-engineering to achieve complete end-to-end working deployment

---

## Architecture Clarifications (Based on README)

### Core Design Principles
1. **ALL DATA on /mnt/data** (mounted EBS volume) - NO /opt, NO /var
2. **5-script architecture** - Clean separation of concerns
3. **Dynamic compose generation** - Based on .env collected in Script 1
4. **Non-root dockerization** - All services run as user
5. **Network segmentation** - Public, private internal, and admin (Tailscale)
6. **Shared vector memory** - Private embeddings accessible to all AI services
7. **LiteLLM as central gateway** - Single routing point for all LLM access

### Actual Path Structure
```
/mnt/data/
â”œâ”€â”€ ai-platform/
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”œâ”€â”€ .secrets/
â”‚   â”‚   â”‚   â””â”€â”€ .env                    # All configuration
â”‚   â”‚   â”œâ”€â”€ stack/
â”‚   â”‚   â”‚   â””â”€â”€ docker-compose.yml      # Generated by Script 1
â”‚   â”‚   â””â”€â”€ logs/
â”‚   â”œâ”€â”€ data/                           # Persistent data
â”‚   â”‚   â”œâ”€â”€ postgres/
â”‚   â”‚   â”œâ”€â”€ redis/
â”‚   â”‚   â”œâ”€â”€ ollama/
â”‚   â”‚   â”œâ”€â”€ qdrant/
â”‚   â”‚   â”œâ”€â”€ minio/
â”‚   â”‚   â”œâ”€â”€ documents/                  # Shared embedding source
â”‚   â”‚   â””â”€â”€ embeddings/                 # Shared vector store
â”‚   â”œâ”€â”€ config/                         # Service configs
â”‚   â”‚   â”œâ”€â”€ litellm/
â”‚   â”‚   â”œâ”€â”€ caddy/
â”‚   â”‚   â””â”€â”€ tailscale/
â”‚   â””â”€â”€ backups/
```

---

## Current State Assessment

### What Actually Works âœ…

**Script 0 (Cleanup):** 
- âœ… Fully functional
- âœ… Removes all Docker resources
- âœ… Handles /mnt/data cleanup properly

**Script 1 (Setup):**
- âœ… Hardware detection
- âœ… User input collection
- âœ… .env generation
- âœ… Secret generation
- âš ï¸ Compose generation (skeleton only)
- âš ï¸ Volume mount definitions incomplete

**Script 2 (Deploy):**
- âœ… Finds .env correctly (after Script 1 fix)
- âœ… Deploys 8 services successfully
- âŒ 5 services failing
- âŒ No health checking
- âŒ No error handling

**Script 3 (Configure):**
- âŒ Skeleton only (~100 lines)
- âŒ Missing all post-deployment configuration

**Script 4 (Add Service):**
- âš ï¸ UI/catalog complete
- âŒ No actual deployment logic for AI services

### Why 5 Services Are Failing

Based on the deployment sequence in Script 2, likely failing services:

1. **litellm** - Missing database initialization, wrong config path
2. **dify-api** - Missing Celery broker, database not initialized
3. **dify-worker** - Depends on dify-api
4. **n8n** - Missing database setup, encryption key issues
5. **flowise** - Database connection or storage path issues

---

## Root Cause Analysis

### Issue 1: Script 1 Generates Empty Compose File âš ï¸ CRITICAL

**Problem:**
```yaml
# Script 1 line ~1700: Creates this:
services:
  placeholder:
    image: hello-world
    
# But Script 2 expects actual service definitions!
```

**Impact:** Script 2 can't deploy anything because services don't exist in compose file

**Fix:** Script 1 must generate COMPLETE compose file with all selected services

### Issue 2: Volume Mount Paths Not in .env

**Problem:**
```bash
# Script 1 generates .env but doesn't include volume paths
# Compose file needs: ${POSTGRES_DATA}/data:/var/lib/postgresql/data
# But POSTGRES_DATA variable doesn't exist in .env
```

**Impact:** Services can't mount volumes, fail to start

**Fix:** Add volume path variables to .env generation

### Issue 3: Database Initialization Missing

**Problem:**
```bash
# Postgres starts but databases for litellm, dify, n8n don't exist
# No initialization script runs
```

**Impact:** Services fail when trying to connect to non-existent databases

**Fix:** Add init scripts or Script 3 creates databases

### Issue 4: Service Dependencies Not Ordered

**Problem:**
```bash
# Script 2 deploys in phases but doesn't verify dependencies
deploy_group litellm  # Tries to start before postgres is ready
```

**Impact:** Services fail because dependencies aren't healthy yet

**Fix:** Add health checks and wait logic

### Issue 5: Missing Celery/RabbitMQ for Dify

**Problem:**
```yaml
# Dify requires message broker but it's not in compose file
# dify-worker needs CELERY_BROKER_URL
```

**Impact:** Dify stack fails completely

**Fix:** Add celery broker to compose generation

---

## Minimal Fix Strategy

### Phase 1: Fix Script 1 Compose Generation (CRITICAL - 4 hours)

**Objective:** Generate complete docker-compose.yml based on service selection

**Implementation in Script 1 `generate_docker_compose()` function:**

```bash
generate_docker_compose() {
    log_phase "PHASE 14: Generating Docker Compose Configuration"
    
    if [ "${SETUP_PHASES[compose]}" -eq 1 ]; then
        log_info "Docker Compose already generated - skipping"
        return 0
    fi
    
    log_info "Generating complete docker-compose.yml..."
    
    cat > "$COMPOSE_FILE" <<'COMPOSE_HEADER'
version: '3.8'

networks:
  ai-platform:
    name: ai-platform
    driver: bridge
  ai-platform-internal:
    name: ai-platform-internal
    driver: bridge
    internal: true
  ai-platform-monitoring:
    name: ai-platform-monitoring
    driver: bridge

volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR}/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR}/redis
  ollama_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR}/ollama
  qdrant_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR}/qdrant
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR}/minio

services:
COMPOSE_HEADER

    # Always add core infrastructure
    add_postgres_service
    add_redis_service
    
    # Add selected services
    [ "$ENABLE_QDRANT" = true ] && add_qdrant_service
    [ "$ENABLE_MINIO" = true ] && add_minio_service
    [ "$ENABLE_TAILSCALE" = true ] && add_tailscale_service
    [ "$ENABLE_OLLAMA" = true ] && add_ollama_service
    [ "$ENABLE_LITELLM" = true ] && add_litellm_service
    [ "$ENABLE_OPENWEBUI" = true ] && add_openwebui_service
    [ "$ENABLE_DIFY" = true ] && add_dify_services
    [ "$ENABLE_N8N" = true ] && add_n8n_service
    [ "$ENABLE_FLOWISE" = true ] && add_flowise_service
    [ "$ENABLE_ANYTHINGLLM" = true ] && add_anythingllm_service
    [ "$ENABLE_MONITORING" = true ] && add_monitoring_services
    
    chmod 644 "$COMPOSE_FILE"
    chown "${REAL_UID}:${REAL_GID}" "$COMPOSE_FILE"
    
    log_success "Docker Compose generated: ${COMPOSE_FILE}"
    
    save_state "compose"
}

add_postgres_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ${CONFIG_DIR}/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    networks:
      - ai-platform-internal
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    labels:
      - "ai-platform.service=postgres"
      - "ai-platform.type=infrastructure"

EOF
}

add_redis_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  redis:
    image: redis:7-alpine
    container_name: redis
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - ai-platform-internal
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    labels:
      - "ai-platform.service=redis"
      - "ai-platform.type=infrastructure"

EOF
}

add_qdrant_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "6333:6333"
      - "6334:6334"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "ai-platform.service=qdrant"
      - "ai-platform.type=vector-db"

EOF
}

add_ollama_service() {
    local runtime_config=""
    if [ "$GPU_TYPE" = "nvidia" ]; then
        runtime_config="runtime: nvidia"
    fi
    
    cat >> "$COMPOSE_FILE" <<EOF
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ${runtime_config}
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_ORIGINS=*
EOF

    if [ "$GPU_TYPE" = "nvidia" ]; then
        cat >> "$COMPOSE_FILE" <<'EOF'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
EOF
    fi

    cat >> "$COMPOSE_FILE" <<'EOF'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    labels:
      - "ai-platform.service=ollama"
      - "ai-platform.type=llm"

EOF
}

add_litellm_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY}
      LITELLM_SALT_KEY: ${LITELLM_SALT_KEY}
      DATABASE_URL: postgresql://${POSTGRES_USER}:${DB_PASSWORD}@postgres:5432/${POSTGRES_DB}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      STORE_MODEL_IN_DB: "True"
    volumes:
      - ${CONFIG_DIR}/litellm/config.yaml:/app/config.yaml:ro
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "8010:4000"
    command: ["--config", "/app/config.yaml", "--port", "4000", "--num_workers", "4"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "ai-platform.service=litellm"
      - "ai-platform.type=llm-gateway"

EOF
}

add_openwebui_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    depends_on:
      - ollama
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      WEBUI_AUTH: "True"
      WEBUI_SECRET_KEY: ${JWT_SECRET}
    volumes:
      - ${DATA_DIR}/open-webui:/app/backend/data
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "ai-platform.service=open-webui"
      - "ai-platform.type=ui"

EOF
}

add_dify_services() {
    # Add celery broker first
    cat >> "$COMPOSE_FILE" <<'EOF'
  celery-broker:
    image: rabbitmq:3-management-alpine
    container_name: celery-broker
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: dify
      RABBITMQ_DEFAULT_PASS: ${DB_PASSWORD}
    volumes:
      - ${DATA_DIR}/rabbitmq:/var/lib/rabbitmq
    networks:
      - ai-platform-internal
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "ai-platform.service=celery-broker"
      - "ai-platform.type=infrastructure"

  dify-api:
    image: langgenius/dify-api:latest
    container_name: dify-api
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      celery-broker:
        condition: service_healthy
    environment:
      MODE: api
      LOG_LEVEL: INFO
      SECRET_KEY: ${ENCRYPTION_KEY}
      DB_USERNAME: ${POSTGRES_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_HOST: postgres
      DB_PORT: 5432
      DB_DATABASE: dify
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      CELERY_BROKER_URL: amqp://dify:${DB_PASSWORD}@celery-broker:5672/
      STORAGE_TYPE: local
      STORAGE_LOCAL_PATH: /app/storage
      VECTOR_STORE: qdrant
      QDRANT_URL: http://qdrant:6333
    volumes:
      - ${DATA_DIR}/dify/storage:/app/storage
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "5001:5001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    labels:
      - "ai-platform.service=dify-api"
      - "ai-platform.type=ai-platform"

  dify-worker:
    image: langgenius/dify-api:latest
    container_name: dify-worker
    restart: unless-stopped
    depends_on:
      dify-api:
        condition: service_healthy
    environment:
      MODE: worker
      LOG_LEVEL: INFO
      SECRET_KEY: ${ENCRYPTION_KEY}
      DB_USERNAME: ${POSTGRES_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_HOST: postgres
      DB_PORT: 5432
      DB_DATABASE: dify
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
      CELERY_BROKER_URL: amqp://dify:${DB_PASSWORD}@celery-broker:5672/
      STORAGE_TYPE: local
      STORAGE_LOCAL_PATH: /app/storage
      VECTOR_STORE: qdrant
      QDRANT_URL: http://qdrant:6333
    volumes:
      - ${DATA_DIR}/dify/storage:/app/storage
    networks:
      - ai-platform-internal
    labels:
      - "ai-platform.service=dify-worker"
      - "ai-platform.type=ai-platform"

  dify-web:
    image: langgenius/dify-web:latest
    container_name: dify-web
    restart: unless-stopped
    depends_on:
      dify-api:
        condition: service_healthy
    environment:
      CONSOLE_API_URL: http://dify-api:5001
      APP_API_URL: http://dify-api:5001
    networks:
      - ai-platform
    ports:
      - "3000:3000"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "ai-platform.service=dify-web"
      - "ai-platform.type=ai-platform"

EOF
}

add_n8n_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: ${POSTGRES_USER}
      DB_POSTGRESDB_PASSWORD: ${DB_PASSWORD}
      N8N_ENCRYPTION_KEY: ${ENCRYPTION_KEY}
      N8N_HOST: ${BASE_DOMAIN}
      N8N_PORT: 5678
      N8N_PROTOCOL: https
      WEBHOOK_URL: https://n8n.${BASE_DOMAIN}
    volumes:
      - ${DATA_DIR}/n8n:/home/node/.n8n
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "5678:5678"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "ai-platform.service=n8n"
      - "ai-platform.type=workflow"

EOF
}

add_flowise_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  flowise:
    image: flowiseai/flowise:latest
    container_name: flowise
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      DATABASE_TYPE: postgres
      DATABASE_HOST: postgres
      DATABASE_PORT: 5432
      DATABASE_USER: ${POSTGRES_USER}
      DATABASE_PASSWORD: ${DB_PASSWORD}
      DATABASE_NAME: flowise
      FLOWISE_USERNAME: admin
      FLOWISE_PASSWORD: ${ADMIN_PASSWORD}
      SECRETKEY_OVERWRITE: ${ENCRYPTION_KEY}
    volumes:
      - ${DATA_DIR}/flowise:/root/.flowise
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "3001:3000"
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/v1/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "ai-platform.service=flowise"
      - "ai-platform.type=workflow"

EOF
}

add_anythingllm_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    environment:
      STORAGE_DIR: /app/server/storage
      JWT_SECRET: ${JWT_SECRET}
      LLM_PROVIDER: ollama
      OLLAMA_BASE_PATH: http://ollama:11434
      EMBEDDING_ENGINE: ollama
      EMBEDDING_BASE_PATH: http://ollama:11434
      VECTOR_DB: qdrant
      QDRANT_ENDPOINT: http://qdrant:6333
    volumes:
      - ${DATA_DIR}/anythingllm:/app/server/storage
      - ${DATA_DIR}/documents:/app/server/storage/documents
    networks:
      - ai-platform-internal
      - ai-platform
    ports:
      - "3002:3001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    labels:
      - "ai-platform.service=anythingllm"
      - "ai-platform.type=ai-platform"

EOF
}
```

**Add to .env generation (in `generate_env_file()`):**

```bash
# Add volume paths section
cat >> "$ENV_FILE" <<EOF

#==============================================================================
# VOLUME MOUNT PATHS (All under /mnt/data)
#==============================================================================

# Data directories
POSTGRES_DATA=${DATA_DIR}/postgres
REDIS_DATA=${DATA_DIR}/redis
OLLAMA_DATA=${DATA_DIR}/ollama
QDRANT_DATA=${DATA_DIR}/qdrant
MINIO_DATA=${DATA_DIR}/minio
RABBITMQ_DATA=${DATA_DIR}/rabbitmq

# Application data
DIFY_STORAGE=${DATA_DIR}/dify/storage
N8N_DATA=${DATA_DIR}/n8n
FLOWISE_DATA=${DATA_DIR}/flowise
ANYTHINGLLM_DATA=${DATA_DIR}/anythingllm
OPENWEBUI_DATA=${DATA_DIR}/open-webui

# Shared data
DOCUMENTS_PATH=${DATA_DIR}/documents
EMBEDDINGS_PATH=${DATA_DIR}/embeddings

EOF
```

**Create directories (in `create_directory_structure()`):**

```bash
create_directory_structure() {
    log_phase "PHASE 5: Creating Directory Structure"
    
    if [ "${SETUP_PHASES[directories]}" -eq 1 ]; then
        log_info "Directory structure already created - skipping"
        return 0
    fi
    
    log_info "Creating directory structure at ${BASE_DIR}..."
    
    # Core directories
    mkdir -p "${BASE_DIR}"/{deployment/{.secrets,stack,logs},data,config,backups}
    
    # Infrastructure data directories
    mkdir -p "${DATA_DIR}"/{postgres,redis,rabbitmq}
    
    # Vector/embedding directories
    mkdir -p "${DATA_DIR}"/{ollama,qdrant,minio}
    
    # Application data directories
    mkdir -p "${DATA_DIR}"/{dify/storage,n8n,flowise,anythingllm,open-webui}
    
    # Shared data directories
    mkdir -p "${DATA_DIR}"/{documents,embeddings}
    
    # Config directories
    mkdir -p "${CONFIG_DIR}"/{litellm,caddy,postgres,tailscale}
    
    # Set ownership
    chown -R "${REAL_UID}:${REAL_GID}" "${BASE_DIR}"
    
    # Set permissions
    chmod -R 755 "${BASE_DIR}"
    chmod 700 "${BASE_DIR}/deployment/.secrets"
    
    log_success "Directory structure created"
    log_info "Base directory: ${BASE_DIR}"
    
    save_state "directories"
}
```

### Phase 2: Fix Script 2 Health Checks & Error Handling (2 hours)

**Replace `deploy_group()` function:**

```bash
deploy_group() {
    local services=("$@")
    local failed_services=()
    
    for svc in "${services[@]}"; do
        if ! service_exists "$svc"; then
            log_warning "Service not defined in compose: $svc"
            continue
        fi
        
        local image=$(grep -A 5 "^  $svc:" "$COMPOSE_FILE" | grep "image:" | awk '{print $2}')
        
        echo -n -e "  ðŸ³ ${BOLD}$svc${NC}: "
        
        # Pull image
        if ! docker compose -f "$COMPOSE_FILE" --env-file "$ENV_FILE" pull "$svc" >> "$LOG_FILE" 2>&1; then
            echo -e "${RED}FAILED TO PULL${NC}"
            failed_services+=("$svc")
            continue
        fi
        
        # Start service
        if ! docker compose -f "$COMPOSE_FILE" --env-file "$ENV_FILE" up -d "$svc" >> "$LOG_FILE" 2>&1; then
            echo -e "${RED}FAILED TO START${NC}"
            docker compose -f "$COMPOSE_FILE" logs "$svc" --tail 20
            failed_services+=("$svc")
            continue
        fi
        
        # Wait for health
        if wait_for_healthy "$svc" 60; then
            echo -e "${GREEN}âœ“ HEALTHY${NC}"
            display_service_info "$svc"
        else
            echo -e "${YELLOW}âš  RUNNING (health check timeout)${NC}"
        fi
    done
    
    if [ ${#failed_services[@]} -gt 0 ]; then
        log_error "Failed services: ${failed_services[*]}"
        return 1
    fi
    
    return 0
}

wait_for_healthy() {
    local service=$1
    local timeout=${2:-30}
    local elapsed=0
    
    while [ $elapsed -lt $timeout ]; do
        # Check container is running
        if ! docker ps --format '{{.Names}}' | grep -q "^${service}$"; then
            sleep 2
            elapsed=$((elapsed + 2))
            continue
        fi
        
        # Check health status
        local health=$(docker inspect --format='{{.State.Health.Status}}' "$service" 2>/dev/null || echo "no_healthcheck")
        
        if [ "$health" = "healthy" ]; then
            return 0
        elif [ "$health" = "unhealthy" ]; then
            return 1
        elif [ "$health" = "no_healthcheck" ]; then
            # No healthcheck defined, verify running for 10s
            if [ $elapsed -ge 10 ]; then
                return 0
            fi
        fi
        
        sleep 2
        elapsed=$((elapsed + 2))
    done
    
    return 1
}

display_service_info() {
    local svc=$1
    case "$svc" in
        postgres) echo -e "    ${BLUE}â†’ Database ready on 5432${NC}" ;;
        redis)    echo -e "    ${BLUE}â†’ Cache ready on 6379${NC}" ;;
        qdrant)   echo -e "    ${BLUE}â†’ Vector DB ready on 6333${NC}" ;;
        ollama)   echo -e "    ${BLUE}â†’ LLM engine ready on 11434${NC}" ;;
        litellm)  echo -e "    ${BLUE}â†’ Gateway ready: http://localhost:8010/health${NC}" ;;
        open-webui) echo -e "    ${BLUE}â†’ UI ready: http://localhost:8080${NC}" ;;
        dify-web) echo -e "    ${BLUE}â†’ Dify ready: http://localhost:3000${NC}" ;;
        n8n)      echo -e "    ${BLUE}â†’ n8n ready: http://localhost:5678${NC}" ;;
        flowise)  echo -e "    ${BLUE}â†’ Flowise ready: http://localhost:3001${NC}" ;;
        anythingllm) echo -e "    ${BLUE}â†’ AnythingLLM ready: http://localhost:3002${NC}" ;;
    esac
}
```

### Phase 3: Implement Script 3 Configuration (4 hours)

**Complete rewrite of Script 3:**

```bash
#!/bin/bash
#============================================================================
# Script 3: Post-Deployment Configuration
# Purpose: Initialize databases, configure services, test integrations
#============================================================================

set -euo pipefail

# Paths
REAL_USER="${SUDO_USER:-$USER}"
BASE_DIR="/mnt/data/ai-platform"
DEPLOY_ROOT="$BASE_DIR/deployment"
ENV_FILE="$DEPLOY_ROOT/.secrets/.env"
COMPOSE_FILE="$DEPLOY_ROOT/stack/docker-compose.yml"
LOG_FILE="$BASE_DIR/deployment/logs/configure-$(date +%Y%m%d-%H%M%S).log"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# Load environment
if [ ! -f "$ENV_FILE" ]; then
    echo -e "${RED}Error: .env not found at $ENV_FILE${NC}"
    exit 1
fi

source "$ENV_FILE"

log_phase() {
    echo ""
    echo -e "${BLUE}â”â”â” $1 â”â”â”${NC}"
}

log_info() {
    echo -e "${BLUE}â†’${NC} $1"
}

log_success() {
    echo -e "${GREEN}âœ“${NC} $1"
}

log_error() {
    echo -e "${RED}âœ—${NC} $1"
}

#============================================================================
# PHASE 1: Database Initialization
#============================================================================

initialize_databases() {
    log_phase "PHASE 1: Database Initialization"
    
    # Wait for postgres to be fully ready
    log_info "Waiting for PostgreSQL..."
    local retries=0
    while [ $retries -lt 30 ]; do
        if docker exec postgres pg_isready -U aiplatform &>/dev/null; then
            log_success "PostgreSQL ready"
            break
        fi
        sleep 2
        retries=$((retries + 1))
    done
    
    # Create databases for each service
    log_info "Creating databases..."
    
    docker exec postgres psql -U aiplatform -c "CREATE DATABASE litellm;" 2>/dev/null || log_info "  litellm database already exists"
    docker exec postgres psql -U aiplatform -c "CREATE DATABASE dify;" 2>/dev/null || log_info "  dify database already exists"
    docker exec postgres psql -U aiplatform -c "CREATE DATABASE n8n;" 2>/dev/null || log_info "  n8n database already exists"
    docker exec postgres psql -U aiplatform -c "CREATE DATABASE flowise;" 2>/dev/null || log_info "  flowise database already exists"
    
    log_success "Databases initialized"
}

#============================================================================
# PHASE 2: LiteLLM Configuration
#============================================================================

configure_litellm() {
    log_phase "PHASE 2: LiteLLM Configuration"
    
    # Initialize LiteLLM database
    log_info "Initializing LiteLLM database schema..."
    docker exec litellm python -c "from litellm.proxy.proxy_server import initialize; initialize()" 2>/dev/null || true
    
    # Test LiteLLM health
    log_info "Testing LiteLLM API..."
    if curl -s -f http://localhost:8010/health &>/dev/null; then
        log_success "LiteLLM API responding"
    else
        log_error "LiteLLM API not responding"
        docker logs litellm --tail 20
        return 1
    fi
    
    # Test Ollama connection
    if [ "$ENABLE_OLLAMA" = "true" ]; then
        log_info "Testing LiteLLM â†’ Ollama connection..."
        docker exec litellm curl -s http://ollama:11434/ &>/dev/null && log_success "Ollama accessible from LiteLLM"
    fi
}

#============================================================================
# PHASE 3: Ollama Model Management
#============================================================================

configure_ollama() {
    if [ "$ENABLE_OLLAMA" != "true" ]; then
        return 0
    fi
    
    log_phase "PHASE 3: Ollama Model Configuration"
    
    # Parse model list
    IFS=',' read -ra MODELS <<< "$OLLAMA_MODELS"
    
    for model in "${MODELS[@]}"; do
        log_info "Pulling model: $model"
        docker exec ollama ollama pull "$model" &
    done
    
    log_info "Waiting for model pulls to complete..."
    wait
    
    log_success "All models pulled"
    
    # List available models
    log_info "Available models:"
    docker exec ollama ollama list
}

#============================================================================
# PHASE 4: Dify Initialization
#============================================================================

configure_dify() {
    if [ "$ENABLE_DIFY" != "true" ]; then
        return 0
    fi
    
    log_phase "PHASE 4: Dify Configuration"
    
    # Run Dify database migrations
    log_info "Running Dify database migrations..."
    if docker exec dify-api flask db upgrade 2>&1 | tee -a "$LOG_FILE"; then
        log_success "Dify database migrated"
    else
        log_error "Dify migration failed"
        return 1
    fi
    
    # Initialize Dify admin (if not exists)
    log_info "Checking Dify admin setup..."
    # First login will create admin account
}

#============================================================================
# PHASE 5: Vector Database Setup
#============================================================================

configure_vector_db() {
    if [ "$ENABLE_QDRANT" != "true" ]; then
        return 0
    fi
    
    log_phase "PHASE 5: Vector Database Configuration"
    
    # Test Qdrant connection
    log_info "Testing Qdrant..."
    if curl -s -f http://localhost:6333/ &>/dev/null; then
        log_success "Qdrant responding"
        
        # Get collections
        local collections=$(curl -s http://localhost:6333/collections | jq -r '.result.collections | length')
        log_info "Current collections: $collections"
    else
        log_error "Qdrant not responding"
        return 1
    fi
}

#============================================================================
# PHASE 6: Service Integration Testing
#============================================================================

test_integrations() {
    log_phase "PHASE 6: Integration Testing"
    
    local failed_tests=0
    
    # Test 1: Database connections
    log_info "Testing database connections..."
    if docker exec litellm psql -h postgres -U aiplatform -d litellm -c "SELECT 1;" &>/dev/null; then
        log_success "  LiteLLM â†’ PostgreSQL"
    else
        log_error "  LiteLLM â†’ PostgreSQL"
        failed_tests=$((failed_tests + 1))
    fi
    
    # Test 2: Redis connections
    log_info "Testing Redis connections..."
    if docker exec litellm redis-cli -h redis -a "$REDIS_PASSWORD" ping 2>/dev/null | grep -q PONG; then
        log_success "  LiteLLM â†’ Redis"
    else
        log_error "  LiteLLM â†’ Redis"
        failed_tests=$((failed_tests + 1))
    fi
    
    # Test 3: LLM pipeline
    if [ "$ENABLE_OLLAMA" = "true" ]; then
        log_info "Testing LLM pipeline..."
        
        # Test Ollama directly
        if curl -s http://localhost:11434/ &>/dev/null; then
            log_success "  Ollama endpoint"
        else
            log_error "  Ollama endpoint"
            failed_tests=$((failed_tests + 1))
        fi
        
        # Test LiteLLM â†’ Ollama
        if docker exec litellm curl -s http://ollama:11434/ &>/dev/null; then
            log_success "  LiteLLM â†’ Ollama"
        else
            log_error "  LiteLLM â†’ Ollama"
            failed_tests=$((failed_tests + 1))
        fi
    fi
    
    # Test 4: Vector DB connections
    if [ "$ENABLE_QDRANT" = "true" ]; then
        log_info "Testing vector database access..."
        
        if [ "$ENABLE_DIFY" = "true" ]; then
            if docker exec dify-api curl -s http://qdrant:6333/ &>/dev/null; then
                log_success "  Dify â†’ Qdrant"
            else
                log_error "  Dify â†’ Qdrant"
                failed_tests=$((failed_tests + 1))
            fi
        fi
        
        if [ "$ENABLE_ANYTHINGLLM" = "true" ]; then
            if docker exec anythingllm curl -s http://qdrant:6333/ &>/dev/null; then
                log_success "  AnythingLLM â†’ Qdrant"
            else
                log_error "  AnythingLLM â†’ Qdrant"
                failed_tests=$((failed_tests + 1))
            fi
        fi
    fi
    
    if [ $failed_tests -eq 0 ]; then
        log_success "All integration tests passed"
        return 0
    else
        log_error "$failed_tests integration test(s) failed"
        return 1
    fi
}

#============================================================================
# PHASE 7: Create Shared Document Directory
#============================================================================

setup_shared_documents() {
    log_phase "PHASE 7: Shared Document Setup"
    
    # Ensure document directory exists and is accessible
    mkdir -p "${DATA_DIR}/documents"/{inbox,processed,embeddings}
    chown -R "${PUID}:${PGID}" "${DATA_DIR}/documents"
    chmod -R 755 "${DATA_DIR}/documents"
    
    log_success "Shared document directory configured"
    log_info "  Path: ${DATA_DIR}/documents"
    log_info "  Place documents in: ${DATA_DIR}/documents/inbox"
}

#============================================================================
# PHASE 8: Optional - Tailscale Setup
#============================================================================

configure_tailscale() {
    if [ "$ENABLE_TAILSCALE" != "true" ] || [ -z "${TAILSCALE_AUTH_KEY:-}" ]; then
        return 0
    fi
    
    log_phase "PHASE 8: Tailscale Configuration"
    
    log_info "Connecting to Tailscale network..."
    docker exec tailscale tailscale up --authkey="$TAILSCALE_AUTH_KEY" --advertise-exit-node --advertise-tags=tag:ai-platform
    
    log_success "Tailscale configured"
    log_info "Tailscale status:"
    docker exec tailscale tailscale status
}

#============================================================================
# MAIN EXECUTION
#============================================================================

main() {
    echo ""
    echo -e "${GREEN}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—${NC}"
    echo -e "${GREEN}â•‘     AI PLATFORM - POST-DEPLOYMENT CONFIGURATION          â•‘${NC}"
    echo -e "${GREEN}â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo ""
    
    initialize_databases
    configure_litellm
    configure_ollama
    configure_dify
    configure_vector_db
    test_integrations
    setup_shared_documents
    configure_tailscale
    
    echo ""
    log_phase "CONFIGURATION COMPLETE"
    echo ""
    log_success "All services configured and tested"
    echo ""
    echo -e "${BLUE}Access URLs:${NC}"
    [ "$ENABLE_OPENWEBUI" = "true" ] && echo "  Open WebUI:   http://localhost:8080"
    [ "$ENABLE_LITELLM" = "true" ] && echo "  LiteLLM:      http://localhost:8010"
    [ "$ENABLE_DIFY" = "true" ] && echo "  Dify:         http://localhost:3000"
    [ "$ENABLE_N8N" = "true" ] && echo "  n8n:          http://localhost:5678"
    [ "$ENABLE_FLOWISE" = "true" ] && echo "  Flowise:      http://localhost:3001"
    [ "$ENABLE_ANYTHINGLLM" = "true" ] && echo "  AnythingLLM:  http://localhost:3002"
    echo ""
    echo -e "${YELLOW}Next Steps:${NC}"
    echo "  1. Access services via URLs above"
    echo "  2. Place documents in: ${DATA_DIR}/documents/inbox"
    echo "  3. Run ./4-add-service.sh to add more services"
    echo ""
}

main "$@"
```

### Phase 4: Fix postgres init.sql (30 minutes)

**Update `generate_postgres_init()` in Script 1:**

```bash
generate_postgres_init() {
    log_phase "PHASE 16: Generating Database Initialization"
    
    if [ "${SETUP_PHASES[postgres_init]}" -eq 1 ]; then
        log_info "Postgres init already generated - skipping"
        return 0
    fi
    
    mkdir -p "${CONFIG_DIR}/postgres"
    
    cat > "${CONFIG_DIR}/postgres/init.sql" <<'EOF'
-- AI Platform Database Initialization
-- This runs on first PostgreSQL startup only

-- Create extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";
CREATE EXTENSION IF NOT EXISTS "vector";

-- Create databases (will skip if exist)
SELECT 'CREATE DATABASE litellm' WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = 'litellm')\gexec
SELECT 'CREATE DATABASE dify' WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = 'dify')\gexec
SELECT 'CREATE DATABASE n8n' WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = 'n8n')\gexec
SELECT 'CREATE DATABASE flowise' WHERE NOT EXISTS (SELECT FROM pg_database WHERE datname = 'flowise')\gexec

-- Note: User 'aiplatform' already exists from POSTGRES_USER env var
-- Grant permissions are automatic for the database owner
EOF
    
    chmod 644 "${CONFIG_DIR}/postgres/init.sql"
    chown "${REAL_UID}:${REAL_GID}" "${CONFIG_DIR}/postgres/init.sql"
    
    log_success "Database initialization script generated"
    
    save_state "postgres_init"
}
```

---

## Implementation Timeline

### Day 1 (6 hours)
- **Hours 1-4:** Implement complete compose generation in Script 1
  - Add all service definition functions
  - Add volume path variables to .env
  - Update directory creation
- **Hours 5-6:** Test Script 1 generates valid compose file
  - Verify all selected services are in compose
  - Verify volumes are properly defined
  - Verify healthchecks are present

### Day 2 (6 hours)
- **Hours 1-2:** Implement health checks in Script 2
  - Add wait_for_healthy() function
  - Update deploy_group() with error handling
- **Hours 3-4:** Implement Script 3 configuration
  - Database initialization
  - Service configuration
  - Integration testing
- **Hours 5-6:** End-to-end test
  - Run full Script 0 â†’ 1 â†’ 2 â†’ 3 sequence
  - Verify all 13 services deploy
  - Fix any remaining issues

### Day 3 (Optional - Polish)
- Clean up logging
- Add progress indicators
- Document any manual steps
- Create troubleshooting guide

---

## Testing Checklist

### After Script 1
```bash
# Verify outputs exist
[ -f /mnt/data/ai-platform/deployment/.secrets/.env ] && echo "âœ“ .env exists"
[ -f /mnt/data/ai-platform/deployment/stack/docker-compose.yml ] && echo "âœ“ compose exists"

# Verify compose has services
grep -q "postgres:" /mnt/data/ai-platform/deployment/stack/docker-compose.yml && echo "âœ“ postgres defined"
grep -q "redis:" /mnt/data/ai-platform/deployment/stack/docker-compose.yml && echo "âœ“ redis defined"
grep -q "ollama:" /mnt/data/ai-platform/deployment/stack/docker-compose.yml && echo "âœ“ ollama defined"

# Verify directories exist
ls -la /mnt/data/ai-platform/data/
```

### After Script 2
```bash
# Verify services running
docker ps --format "{{.Names}}" | grep -E "postgres|redis|ollama|litellm"

# Check health
docker ps --format "table {{.Names}}\t{{.Status}}"

# Test endpoints
curl -f http://localhost:5432 2>&1 | grep -q "postgres" && echo "âœ“ postgres"
curl -f http://localhost:11434 && echo "âœ“ ollama"
curl -f http://localhost:8010/health && echo "âœ“ litellm"
```

### After Script 3
```bash
# Verify databases created
docker exec postgres psql -U aiplatform -l | grep -E "litellm|dify|n8n|flowise"

# Test integrations
docker exec litellm curl -s http://ollama:11434/ && echo "âœ“ litellmâ†’ollama"
docker exec dify-api curl -s http://qdrant:6333/ && echo "âœ“ difyâ†’qdrant"

# Check document directory
ls -la /mnt/data/ai-platform/data/documents/
```

---

## Windsurf Implementation Brief

### Project Context
AI Platform automation suite deploying 13 services (Postgres, Redis, Ollama, LiteLLM, Open WebUI, Dify stack, n8n, Flowise, AnythingLLM, Qdrant, monitoring) via 5 bash scripts. Currently 8/13 services work, 5 fail. Data stored on `/mnt/data` EBS volume.

### Current Issues
1. **Script 1** generates empty docker-compose skeleton, but Script 2 expects full service definitions
2. **Script 1** doesn't include volume paths in .env, causing mount failures
3. **Script 2** has no error handling or health checks
4. **Script 3** is incomplete (~100 lines vs 400+ needed)
5. **Missing:** Database initialization, Celery broker for Dify, proper service dependencies

### Refactoring Objectives
1. **Minimal changes** - Fix only what's broken, don't rebuild architecture
2. **Complete compose in Script 1** - Generate all service definitions based on user selections
3. **Robust Script 2** - Add health checks, error handling, retry logic
4. **Functional Script 3** - Database init, service config, integration tests
5. **End-to-end working** - All 5 scripts execute successfully in sequence

### Implementation Plan

**Phase 1: Script 1 Fixes (4 hours)**
- Location: `scripts/1-setup-system.sh` lines 1650-1750
- Tasks:
  1. Replace `generate_docker_compose()` function with complete implementation
  2. Add service definition functions: `add_postgres_service()`, `add_redis_service()`, etc.
  3. Update `generate_env_file()` to include volume path variables
  4. Update `create_directory_structure()` to create all service data directories
  5. Update `generate_postgres_init()` with proper database creation SQL
- Verification: docker-compose.yml validates with `docker compose config`

**Phase 2: Script 2 Fixes (2 hours)**
- Location: `scripts/2-deploy-services.sh` lines 50-150
- Tasks:
  1. Add `wait_for_healthy()` function for health checking
  2. Replace `deploy_group()` with error-handled version
  3. Add `display_service_info()` for user feedback
  4. Add dependency verification before deployment
- Verification: Script exits with error code if any service fails, shows clear error messages

**Phase 3: Script 3 Implementation (4 hours)**
- Location: `scripts/3-configure-services.sh` (complete rewrite)
- Tasks:
  1. Add database initialization (create litellm, dify, n8n, flowise databases)
  2. Add LiteLLM configuration and testing
  3. Add Ollama model pulling
  4. Add Dify database migration
  5. Add integration testing suite
  6. Add shared document directory setup
- Verification: All integration tests pass, services can communicate

**Phase 4: Testing (2 hours)**
- Tasks:
  1. Fresh install test: `./0-cleanup.sh && ./1-setup-system.sh && ./2-deploy-services.sh && ./3-configure-services.sh`
  2. Verify all 13 services running: `docker ps | wc -l` should show 13
  3. Test each service endpoint responds
  4. Test service integrations work (litellmâ†’ollama, difyâ†’qdrant, etc)
  5. Document any manual steps needed

### Key Files to Modify

1. **scripts/1-setup-system.sh**
   - Lines 1650-1750: `generate_docker_compose()` - REPLACE entirely
   - Lines 950-1050: `generate_env_file()` - ADD volume paths section
   - Lines 750-850: `create_directory_structure()` - ADD service directories
   - Lines 1750-1850: `generate_postgres_init()` - UPDATE with database creation

2. **scripts/2-deploy-services.sh**
   - Lines 50-100: ADD `wait_for_healthy()` function
   - Lines 100-150: REPLACE `deploy_group()` function
   - Lines 150-200: ADD `display_service_info()` function

3. **scripts/3-configure-services.sh**
   - COMPLETE REWRITE - replace all 100 lines with 400+ line implementation

### Code Patterns to Follow

**Error Handling Pattern:**
```bash
if ! command_that_might_fail; then
    log_error "Clear error message"
    docker logs service_name --tail 20  # Show relevant logs
    return 1  # Exit with error
fi
```

**Health Check Pattern:**
```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:PORT/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 30s
```

**Service Definition Pattern:**
```bash
add_SERVICE_service() {
    cat >> "$COMPOSE_FILE" <<'EOF'
  service-name:
    image: org/image:tag
    container_name: service-name
    restart: unless-stopped
    user: "${PUID}:${PGID}"
    depends_on:
      dependency:
        condition: service_healthy
    environment:
      - VAR=${ENV_VAR}
    volumes:
      - volume_name:/container/path
    networks:
      - ai-platform-internal
    ports:
      - "HOST:CONTAINER"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:PORT/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "ai-platform.service=service-name"
      - "ai-platform.type=category"
EOF
}
```

### Testing Commands

```bash
# After each phase, verify:

# Phase 1 (Script 1)
docker compose -f /mnt/data/ai-platform/deployment/stack/docker-compose.yml config

# Phase 2 (Script 2)
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
docker compose logs --tail 20

# Phase 3 (Script 3)
docker exec postgres psql -U aiplatform -l
docker exec litellm curl -s http://ollama:11434/
```

### Success Criteria
- âœ… Script 1 generates valid docker-compose.yml with all 13 services
- âœ… Script 2 deploys all 13 services with health verification
- âœ… Script 3 completes all configuration and tests pass
- âœ… All services accessible via documented ports
- âœ… Service integrations work (verified by Script 3 tests)
- âœ… Documentation updated with actual deployment results

### Constraints
- **NO architecture changes** - Keep 5-script design, /mnt/data paths, network layout
- **NO additional dependencies** - Use only what's already defined
- **NO breaking changes** - Script 0 and Script 4 remain unchanged
- **Maintain compatibility** - .env format, compose file location, directory structure

### Deliverables
1. Modified `1-setup-system.sh` with complete compose generation
2. Modified `2-deploy-services.sh` with health checks and error handling
3. Rewritten `3-configure-services.sh` with full implementation
4. Updated README with actual deployment steps and verification commands
5. Test results showing all 13 services healthy and integrated
